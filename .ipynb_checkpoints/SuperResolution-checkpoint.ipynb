{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dszZp3-0TlDX"
   },
   "source": [
    "# Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\n",
    "\n",
    "In this notebook we reproduce some results of the Super Resolution paper [1] in PyTorch.\n",
    "\n",
    "[1] Ledig, C., Theis, L., Husz√°r, F., Caballero, J., Cunningham, A., Acosta, A., ... & Shi, W. (2017). Photo-realistic single image super-resolution using a generative adversarial network. In _Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4681-4690)_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mi7a5iu6vHg6"
   },
   "source": [
    "### Pre-processing: Loading datasets\n",
    "In a first step we download all the required datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14398,
     "status": "ok",
     "timestamp": 1584371697260,
     "user": {
      "displayName": "Lars Peschke",
      "photoUrl": "",
      "userId": "02724369657141719952"
     },
     "user_tz": -60
    },
    "id": "IB7wrWhfTkwh",
    "outputId": "8ce5c414-cfc7-464f-ebf9-2794985e8c0e",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url_91 = (\"https://drive.google.com/uc?export=download&id=1eVfd2Snh5bCl0ulMsRE4ker_p-o1M_lm\")\n",
    "url_set5 = (\"https://drive.google.com/uc?export=download&id=1Cr4puJ1UpkXrGpzdpqZLNhZiZ2vaimoi\")\n",
    "url_set14 = (\"https://drive.google.com/uc?export=download&id=1PQus6Glc3VsfVIywG6MAMBBBZVyyF_gB\")\n",
    "\n",
    "\n",
    "# Download data from Google drive and store as zip.\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, \"wb\") as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)\n",
    "\n",
    "\n",
    "download_url(url_91, \"./91.zip\")\n",
    "download_url(url_set5, \"./set5.zip\")\n",
    "download_url(url_set14, \"./set14.zip\")\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"91.zip\", \"r\") as zipObj:\n",
    "    zipObj.extractall(\"./train_data\")\n",
    "\n",
    "with ZipFile(\"set5.zip\", \"r\") as zipObj:\n",
    "    zipObj.extractall(\"./test_data\")\n",
    "\n",
    "with ZipFile(\"set14.zip\", \"r\") as zipObj:\n",
    "    zipObj.extractall(\"./test_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing: Prepare trainingset\n",
    "We load in the training set using our custom loader. This loader also up/downscales the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from os import listdir\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "\n",
    "class SuperResolutionDataset(Dataset):\n",
    "    def __init__(self, root_dir, upscale_factor, use_gpu=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.upscale_factor = upscale_factor\n",
    "        self.images = [\n",
    "            f\n",
    "            for f in listdir(self.root_dir)\n",
    "            if f.endswith(\".bmp\") or f.endswith(\".jpg\")\n",
    "        ]\n",
    "        self.data = list()\n",
    "        for image_name in self.images:\n",
    "            self.data.append(self.get_data_from_image(image_name))\n",
    "\n",
    "        if use_gpu:\n",
    "            for i in range(len(self.data)):\n",
    "                self.data[i] = (self.data[i][0].cuda(), self.data[i][1].cuda())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "\n",
    "    def get_data_from_image(self, image_name):\n",
    "        image = io.imread(self.root_dir + \"/\" + image_name)\n",
    "\n",
    "        h, w = len(image), len(image[0])\n",
    "        cropped_h = h - (h % self.upscale_factor)\n",
    "        cropped_w = w - (w % self.upscale_factor)\n",
    "\n",
    "        target_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.CenterCrop([cropped_h, cropped_w]),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        input_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.CenterCrop([cropped_h, cropped_w]),\n",
    "                transforms.Resize(\n",
    "                    [\n",
    "                        int(cropped_h // self.upscale_factor),\n",
    "                        int(cropped_w // self.upscale_factor),\n",
    "                    ],\n",
    "                    PIL.Image.BICUBIC,\n",
    "                ),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        target_image = target_transform(image)\n",
    "        input_image = input_transform(image)\n",
    "\n",
    "        return input_image, target_image\n",
    "\n",
    "    def imshow_input(self, idx):\n",
    "        img, _ = self.__getitem__(idx)\n",
    "        img = torchvision.utils.make_grid(img)\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()\n",
    "\n",
    "    def imshow_target(self, idx):\n",
    "        _, img = self.__getitem__(idx)\n",
    "        img = torchvision.utils.make_grid(img)\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SuperResolution.ipynb",
   "provenance": [
    {
     "file_id": "/v2/external/notebooks/mlcc/first_steps_with_tensor_flow.ipynb",
     "timestamp": 1553209469878
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
