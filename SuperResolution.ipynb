{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SuperResolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dszZp3-0TlDX"
      },
      "source": [
        "# Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network\n",
        "\n",
        "In this notebook we reproduce some results of the Super Resolution paper [1] in PyTorch.\n",
        "\n",
        "[1] Ledig, C., Theis, L., Husz√°r, F., Caballero, J., Cunningham, A., Acosta, A., ... & Shi, W. (2017). Photo-realistic single image super-resolution using a generative adversarial network. In _Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 4681-4690)_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mi7a5iu6vHg6"
      },
      "source": [
        "## Pre-processing: Loading datasets\n",
        "In a first step we download all the required datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IB7wrWhfTkwh",
        "pycharm": {
          "is_executing": true
        },
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "url_91 = (\"https://drive.google.com/uc?export=download&id=1eVfd2Snh5bCl0ulMsRE4ker_p-o1M_lm\")\n",
        "url_set5 = (\"https://drive.google.com/uc?export=download&id=1Cr4puJ1UpkXrGpzdpqZLNhZiZ2vaimoi\")\n",
        "url_set14 = (\"https://drive.google.com/uc?export=download&id=1PQus6Glc3VsfVIywG6MAMBBBZVyyF_gB\")\n",
        "url_BSD300 = (\"https://github.com/jorisquist/DLSuperResolutionProject/raw/master/BSD300.zip\")\n",
        "url_BSD500 = (\"https://github.com/jorisquist/DLSuperResolutionProject/raw/master/BSD500.zip\")\n",
        "url_SuperTexture = (\"https://github.com/jorisquist/DLSuperResolutionProject/raw/master/SuperTexture.zip\")\n",
        "\n",
        "\n",
        "# Download data from Google drive and store as zip.\n",
        "def download_url(url, save_path, chunk_size=128):\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(save_path, \"wb\") as fd:\n",
        "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "            fd.write(chunk)\n",
        "\n",
        "\n",
        "download_url(url_91, \"./91.zip\")\n",
        "download_url(url_set5, \"./set5.zip\")\n",
        "download_url(url_set14, \"./set14.zip\")\n",
        "download_url(url_BSD300, \"./BSD300.zip\")\n",
        "download_url(url_BSD500, \"./BSD500.zip\")\n",
        "download_url(url_SuperTexture, \"./SuperTexture.zip\")\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(\"91.zip\", \"r\") as zipObj:\n",
        "    zipObj.extractall(\"./train_data\")\n",
        "\n",
        "with ZipFile(\"set5.zip\", \"r\") as zipObj:\n",
        "    zipObj.extractall(\"./test_data\")\n",
        "\n",
        "with ZipFile(\"set14.zip\", \"r\") as zipObj:\n",
        "    zipObj.extractall(\"./test_data\")\n",
        "\n",
        "with ZipFile(\"BSD300.zip\", \"r\") as zipObj:\n",
        "    zipObj.extractall(\"./test_data\")\n",
        "\n",
        "with ZipFile(\"BSD500.zip\", \"r\") as zipObj:\n",
        "    zipObj.extractall(\"./test_data\")\n",
        "\n",
        "with ZipFile(\"SuperTexture.zip\", \"r\") as zipObj:\n",
        "    zipObj.extractall(\"./test_data\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKD73Y5EBLHC",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing: Prepare trainingset\n",
        "We load in the training set using our custom loader. \n",
        "* The loader first crops the image, so that both dimensions are a multiple of the upscaling factor. \n",
        "* It uses bicubic downscaling to downscale a copy of the image.\n",
        "* It splits up the images into smaller subimages.\n",
        "* If the loader is in training mode, it will also perform the inverse of the deconvolution layer on the target images, this way that has to be done only once for every image so that the network doens't have to do it during training.\n",
        "* If necessary it will move all the training data to the memory of the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "RAAvHmo_BLHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage import io\n",
        "from os import listdir\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "\n",
        "\n",
        "class SuperResolutionDataset(Dataset):\n",
        "    def __init__(self, root_dir, upscale_factor, use_gpu=False, testing=False):\n",
        "        self.testing = testing \n",
        "        self.use_gpu = use_gpu\n",
        "        self.root_dir = root_dir\n",
        "        self.upscale_factor = upscale_factor\n",
        "        self.images = [\n",
        "            f\n",
        "            for f in listdir(self.root_dir)\n",
        "            if f.endswith(\".bmp\") or f.endswith(\".jpg\")\n",
        "        ]\n",
        "        self.data = list()\n",
        "        for image_name in self.images:\n",
        "            self.data = self.data + self.get_data_from_image(image_name)\n",
        "            \n",
        "        if use_gpu:\n",
        "            for i in range(len(self.data)):\n",
        "                self.data[i] = (self.data[i][0].cuda(), self.data[i][1].cuda())\n",
        "                \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.data[item]\n",
        "\n",
        "    def get_data_from_image(self, image_name):\n",
        "        image = io.imread(self.root_dir + \"/\" + image_name)\n",
        "\n",
        "        h, w = len(image), len(image[0])\n",
        "        cropped_h = h - (h % self.upscale_factor)\n",
        "        cropped_w = w - (w % self.upscale_factor)\n",
        "\n",
        "        target_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.CenterCrop([cropped_h, cropped_w]),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        input_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.CenterCrop([cropped_h, cropped_w]),\n",
        "            transforms.Resize(\n",
        "                [\n",
        "                    int(cropped_h // self.upscale_factor),\n",
        "                    int(cropped_w // self.upscale_factor),\n",
        "                ],\n",
        "                PIL.Image.BICUBIC,\n",
        "            ),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "\n",
        "        input_tensor = input_transform(image)\n",
        "        target_tensor = target_transform(image)\n",
        "\n",
        "\n",
        "        if self.testing:\n",
        "          data = list()\n",
        "          data.append((input_tensor, target_tensor))\n",
        "          return data\n",
        "\n",
        "        else:\n",
        "          target_size = 17*self.upscale_factor # patch size\n",
        "          target_stride = 17*self.upscale_factor # patch stride\n",
        "          target_patches = target_tensor.unfold(1, target_size, target_stride).unfold(2, target_size, target_stride)\n",
        "\n",
        "          input_patches = input_tensor.unfold(1, 17, 17).unfold(2, 17, 17)\n",
        "          \n",
        "          data = list()\n",
        "          # target_image = patches[:, 0, 0, :, :]\n",
        "          for i in range(input_patches.shape[1]):\n",
        "            for j in range(input_patches.shape[2]):\n",
        "\n",
        "              # During training we can skip the deconvolution layer if we do a reverse deconvolution on the targets\n",
        "              if not self.testing:\n",
        "                target = target_patches[:, i, j, :, :]\n",
        "                target = target.unsqueeze(0)\n",
        "                target = self.inverse_deconvolution(target, self.upscale_factor)\n",
        "                target = target.squeeze()\n",
        "\n",
        "              data.append((input_patches[:, i, j, :, :], target))\n",
        "\n",
        "          return data\n",
        "\n",
        "    def inverse_deconvolution(self, x, r):\n",
        "      [B, C, H, W] = list(x.size())\n",
        "      x = x.reshape(B, C, H//r, r, W//r, r)\n",
        "      x = x.permute(0, 1, 3, 5, 2, 4)\n",
        "      x = x.reshape(B, C*(r**2), H//r, W//r)\n",
        "      return x\n",
        "\n",
        "    def imshow(self, img):\n",
        "        img = torchvision.utils.make_grid(img)\n",
        "        npimg = img.numpy()\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "        plt.show()\n",
        "\n",
        "    def imshow_input(self, idx):\n",
        "        img, _ = self.__getitem__(idx)\n",
        "        img = torchvision.utils.make_grid(img)\n",
        "        npimg = img.numpy()\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "        plt.show()\n",
        "\n",
        "    def imshow_target(self, idx):\n",
        "        _, img = self.__getitem__(idx)\n",
        "        img = torchvision.utils.make_grid(img)\n",
        "        npimg = img.numpy()\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "        plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12AlbJGwBLHL",
        "colab_type": "text"
      },
      "source": [
        "The goal of this Deep Learning network is to upscale the image resolution. Therefore for our training set we first downscale the input. In the example below you see the input image for different upscale factors (4 and 3 respectively) whereas the target image is the image we want to retrieve in the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "LqAVTkQXBLHN",
        "colab_type": "code",
        "outputId": "e1471f2c-ef15-4bb6-8ac8-c2b0ae5978e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "trainExample4 = SuperResolutionDataset(\"train_data/Set91\", 4)\n",
        "print(\"Input image (Up-scale factor 4): \")\n",
        "trainExample4.imshow_input(0)\n",
        "\n",
        "trainExample3 = SuperResolutionDataset(\"train_data/Set91\", 3)\n",
        "print(\"Input image (Up-scale factor 3): \")\n",
        "trainExample3.imshow_input(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input image (Up-scale factor 4): \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAATdElEQVR4nO3de4xcZ3nH8e8zl92d2bW9dlxCElskQRAJUCmWQUAphaYNSYowlfjDqLThIiHaQqGiRaFIBfUvbqVXBEohkLZRoIVQIpSUuFxaITWG4DpXB+Kkuazj+Jr4trszuztP/5jjaLLM2Pucc2a88P4+0mpnZ9533vecM8+eMzPnOY+5OyLyi69yricgIqOhYBdJhIJdJBEKdpFEKNhFElEb5WBTjXHfsHYq1McsPk61Wg2173Q64TEqlfj/yTx98qyAPON4cB0stBfDYywsxPtg8W3jHl9n7VY71L5Wi73GAKq1eLh1OrFvy46dmmW21e67AkYa7BvWTvHB7W8I9Rkbi6/UtevWhdrPz82Fx2g0Gzn6NMN9qMQ3UbM5Ge6z0JoNtT/0+MHwGE/sPxru45X5cJ+lxXiwP/bI46H266c3hMeYPu+8cJ/ZVmz5v3T7DwY+psN4kUQo2EUSUSjYzexKM/uJme01s2vLmpSIlC93sJtZFfgscBXwIuCtZvaisiYmIuUqsmd/BbDX3R929zbwFWBbOdMSkbIVCfaLgN6PMGey+57FzN5tZnea2Z0n5+KfrIpIOYb+AZ27X+fuW91961RjYtjDicgARYJ9H7C55+9N2X0isgoVCfYfAS8ws0vMbAzYDtxSzrREpGy5z6Bz90Uzey/wbaAKXO/u95U2MxEpVaHTZd39VuDWkuYiIkM00nPjK5UKk421wU45Ei6CSRq16lh4jHptPNyHHHkg9fH4JmrNxr/1mJ+PJYLMBxM0ALwWXwHRBB2AI0dPhPssRZfH4u+A62Px19njDz0Uat9uD96OOl1WJBEKdpFEKNhFEqFgF0mEgl0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJxEgTYQCoxBIOKrV6eIjZ+VgiSLSoBEA1x7wqeaq75Ei4WFpcCPeZPRlLhHni4KHwGBPj8eSZYO0KAI49fTzcZ6IRS1KpN+Lbf//BJ8N9yqQ9u0giFOwiiShy3fjNZvY9M7vfzO4zs/eXOTERKVeR9+yLwAfdfZeZrQF+bGY73P3+kuYmIiXKvWd39/3uviu7fQLYQ5/rxovI6lDKe3Yzuxh4GbCzz2PPFIk4keNySSJSjsLBbmZTwNeBD7j7z3zn0VskYk1TRSJEzpWiVVzrdAP9Rne/uZwpicgwFPk03oAvAnvc/TPlTUlEhqHInv1Xgd8DfsPMdmc/V5c0LxEpWZGKMD8A4ud/isg5MdJz492dxaVWqI+R4xz0ajXUfnFxKTxGezFHxYdKvOBBayl+nvtiO95nZuaRUPuF2ZPhMTqt+LZ8+lj85PgLN28M96lYbG6Hn34qPMapU/FlsRL3pzpdViQRCnaRRCjYRRKhYBdJhIJdJBEKdpFEKNhFEqFgF0mEgl0kEQp2kUQo2EUSoWAXScRoi0SY0wkmg7Tn4gkX02vPC7Ufz1HwYaEdK6oA0OrE+ywtxRNu5mfjxRgOPfV0qP10oxke48kD8cISlbF4IkituiHc5+jBI6H2h48dDY8x1pgK96lWg9vSBrfXnl0kEQp2kUQo2EUSUcbVZatm9r9m9q0yJiQiw1HGnv39dAtEiMgqVvRS0puA3wa+UM50RGRYiu7Z/wb4EDDw+7TeijAnZ2PXnxOR8hS5bvwbgYPu/uMzteutCDPVHM87nIgUVPS68W8ys0eAr9C9fvy/lDIrESldkSquH3b3Te5+MbAd+K67v620mYlIqfQ9u0giSjk33t2/D3y/jOcSkeEYbSIMBpVYtZZmYyw8SqsVSzjpdOKJI068T7UWP5A6fDheeeTIoblwn4nxRqj9waPxec2140k9G9dPh/s8/OiBcJ9WO7bOTs7Hq+50Th0L99m8+fxQe6sMfo3pMF4kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBEKdpFEKNhFEqFgF0nEyBNhahZLbKkQrwjSXoolwrQW4wkajRwVUU6dOB7u89TReJ/jx+KJMKfmYuO0l+KJQOP1WLINwE9++mi4T3sxvg9re2ydddqxykYAUxPx10xrfjbU3juD56U9u0giFOwiiSh6KelpM/uamT1gZnvM7FVlTUxEylX0PfvfAv/h7m8xszEg/qZEREYid7Cb2TrgtcDbAdy9DcRrEovISBQ5jL8EOAR8Kav19gUzm1ze6NlFIuYLDCciRRQJ9hqwBficu78MOAVcu7zRs4tETBQYTkSKKBLsM8CMu+/M/v4a3eAXkVWoSJGIJ4HHzeyy7K7LgftLmZWIlK7op/HvA27MPol/GHhH8SmJyDAUCnZ33w1sLWkuIjJEOoNOJBEjTYQxA7NYYkt7Pp7UseCxxBa3WJUagMNPHQ73OXrkYLjPvpl4n6efiq+z2VYw4aYWT2pZMxlPOKIaT4RaarXCfTrBKkLTzbXhMdZOTYX71Gwp1P5Ma0t7dpFEKNhFEqFgF0mEgl0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBEjTYRxh0WPndi/FM+DYH4udq27xU5sTgBHjh4L99lz/8PhPu1gggbA4mK8WsnCwkKofd3jyUOzJ+PzqtXjL9FarR7vQ2x5xuqxykYAZvF9a60WTJ45Q1KX9uwiiVCwiySiaEWYPzGz+8zsXjO7ycx0+ViRVSp3sJvZRcAfA1vd/SVAFdhe1sREpFxFD+NrQMPManRLPz1RfEoiMgxFLiW9D/g08BiwHzjm7rcvb6eKMCKrQ5HD+PXANrploC4EJs3sbcvbqSKMyOpQ5DD+N4H/c/dD7r4A3Ay8upxpiUjZigT7Y8Arzaxp3UvGXg7sKWdaIlK2Iu/Zd9Kt77YLuCd7rutKmpeIlKxoRZiPAh8taS4iMkQjPTe+4x1awQv4nzp5KjzO3GzsfPJ9MwfCYzzxRLxPeyFeJMHxcJ+JZnyzTk9Mhtp3WvF8glo1Pq/GeDPcp9mMLQvA1GRsnPFa/KC40YgvSz24XcZ3PzDwMZ0uK5IIBbtIIhTsIolQsIskQsEukggFu0giFOwiiVCwiyRCwS6SCAW7SCIU7CKJULCLJGKkiTAL7QWemJkJ9WnNx4oXADw6czDU/tiR2fAYNcuR1NGMFxZoTsav7tNoxIskVKux//sTtfiyTK+ZDveZagaLJABr18bHmVgXTFKxeCLQWG08R5/Y9h8fHzyG9uwiiVCwiyRCwS6SiLMGu5ldb2YHzezenvs2mNkOM3sw+71+uNMUkaJWsmf/MnDlsvuuBb7j7i8AvpP9LSKr2FmD3d3/Gzi67O5twA3Z7RuAN5c8LxEpWd737Oe7+/7s9pPA+YMa9laEmctRa1xEylH4Azp3dxh8VcTeijCN8fh3syJSjrzBfsDMLgDIfsfOYhGRkcsb7LcA12S3rwG+Wc50RGRYVvLV203A/wCXmdmMmb0L+DjwW2b2IN2abx8f7jRFpKiznuDt7m8d8NDlJc9FRIZopIkw7XaLxx59NNRnfrYTHufkQqzqTG3cwmNM56i6smZNI9ynPhZPnuh04lVkJidjCScXXHRReIwLN20K92lMxKuo5Fh8xpuxbdOYim/LsRzJU51gFaF6fXASlE6XFUmEgl0kEQp2kUQo2EUSoWAXSYSCXSQRCnaRRCjYRRKhYBdJhIJdJBEKdpFEKNhFEjHSRBjDGAv+f9mwMX7h2kojljyxRDzZppqjT7Oeo4rKhg3hPlM5Kq9Mr98Yal+pxpOHWq1YghLA9Lq14T7rpvNc7DhWRaeWY1tO5LhS09LSfKh9pTY4vrRnF0mEgl0kEXmLRHzKzB4ws7vN7BtmFj9uFJGRylskYgfwEnf/ZeCnwIdLnpeIlCxXkQh3v93dT19C4w4gfgkSERmpMt6zvxO4bdCDvUUiWgvxmtYiUo5CwW5mHwEWgRsHtektEjFerxYZTkQKyP09u5m9HXgjcHlWFUZEVrFcwW5mVwIfAn7d3WfLnZKIDEPeIhH/AKwBdpjZbjP7/JDnKSIF5S0S8cUhzEVEhkhn0IkkYqSJMM3mJFu2vDzUp5YjeaAVzFExi//P88WFeJ9OPBGkORmviNJoTIT71GJ5IKxbf154jHot/nKrVuPf4OSpiDM1GavwMpajUs/iUjvcZ3LNZKh9tTJ4fWnPLpIIBbtIIhTsIolQsIskQsEukggFu0giFOwiiVCwiyRCwS6SCAW7SCIU7CKJULCLJGKkiTD1sTGe87znhfrMt+MJJ7XFWMJBey5WdQPALZ6gUbF4UkueRJBmY124z0QjlnCx9Mz1RlfOOvEqMlNr48tSqwazeoBOJ/Y6m5uLJ7XkSZ4xL+9SbtqziyRCwS6SiFwVYXoe+6CZuZnFqgKKyMjlrQiDmW0GrgAeK3lOIjIEuSrCZP6a7hVmdRlpkZ8Dud6zm9k2YJ+737WCts9UhDlxSledFjlXwl+9mVkT+HO6h/Bn5e7XAdcBXLrpAh0FiJwjefbszwcuAe4ys0foFnXcZWbPLXNiIlKu8J7d3e8BnnP67yzgt7r74RLnJSIly1sRRkR+zuStCNP7+MWlzUZEhmak58YD2FLsXN88ZwbXKrHztn08fi51eyl+bnh9PF68odmMF8mojcWXZ3wstqYrtfhnrfUcJbs7CznyFsI9AI9VFqnk+LRrrJbj1Rx9mZ1h4XW6rEgiFOwiiVCwiyRCwS6SCAW7SCIU7CKJULCLJELBLpIIBbtIIhTsIolQsIskQsEukojRJsK4s7QUS2yoV+LJA/VqbLFOzM/Fx6jH0y2sGi94Ua3Ek1pqlfjcoqvZPF7woZpj3zJejycPdTp5tk2sfWNqKjyG51hnnaWl2BhneEx7dpFEKNhFEpG7SISZvc/MHjCz+8zsk8ObooiUIVeRCDN7PbANeKm7vxj4dPlTE5Ey5S0S8QfAx929lbU5OIS5iUiJ8r5nfyHwa2a208z+y8xePqhhb5GI4yoSIXLO5A32GrABeCXwZ8C/mlnf7xXc/Tp33+ruW9dOxuuTi0g58gb7DHCzd/0Q6ACq5CqyiuUN9n8HXg9gZi8ExgAViRBZxc56qllWJOJ1wEYzmwE+ClwPXJ99HdcGrnF31XETWcWKFIl4W8lzEZEh0hl0IomwUR59m9kh4NE+D23k3L7n1/ga/xdl/Oe5+y/1e2CkwT6Imd3p7ls1vsbX+MOjw3iRRCjYRRKxWoL9Oo2v8TX+cK2K9+wiMnyrZc8uIkOmYBdJxEiD3cyuNLOfmNleM7u2z+PjZvbV7PGdZnZxiWNvNrPvmdn92dV13t+nzevM7JiZ7c5+/qKs8bPnf8TM7sme+84+j5uZ/V22/Heb2ZYSx76sZ7l2m9lxM/vAsjalLn+/qxyZ2QYz22FmD2a/1w/oe03W5kEzu6bE8T+VXWHpbjP7hplND+h7xm1VYPyPmdm+nnV89YC+Z4yVXNx9JD9AFXgIuJRu4sxdwIuWtflD4PPZ7e3AV0sc/wJgS3Z7DfDTPuO/DvjWENfBI8DGMzx+NXAbYHTTh3cOcVs8SfcEjKEtP/BaYAtwb899nwSuzW5fC3yiT78NwMPZ7/XZ7fUljX8FUMtuf6Lf+CvZVgXG/xjwpyvYPmeMlTw/o9yzvwLY6+4Pu3sb+ArdS1v12gbckN3+GnD5oDz5KHff7+67stsngD3ARWU8d4m2Af/kXXcA02Z2wRDGuRx4yN37nc1YGu9/laPebXwD8OY+Xd8A7HD3o+7+FLCDZZdGyzu+u9/u7ovZn3cAm6LPW2T8FVpJrISNMtgvAh7v+XuGnw22Z9pkG+QYcF7ZE8neHrwM2Nnn4VeZ2V1mdpuZvbjkoR243cx+bGbv7vP4StZRGbYDNw14bJjLD3C+u+/Pbj8JnN+nzajWwzvpHkn1c7ZtVcR7s7cR1w94GzOU5U/uAzozmwK+DnzA3Y8ve3gX3UPblwJ/Tzdvv0yvcfctwFXAH5nZa0t+/rMyszHgTcC/9Xl42Mv/LN49Zj0n3/2a2UeAReDGAU2Gta0+Bzwf+BVgP/BXJT3vWY0y2PcBm3v+3pTd17eNmdWAdcCRsiZgZnW6gX6ju9+8/HF3P+7uJ7PbtwJ1MyvtCjzuvi/7fRD4Bt3DtV4rWUdFXQXscvcDfeY31OXPHDj91iT73e9ipUNdD2b2duCNwO9m/3B+xgq2VS7ufsDdl9y9A/zjgOcdyvKPMth/BLzAzC7J9i7bgVuWtbkFOP3J61uA7w7aGFHZe/8vAnvc/TMD2jz39GcEZvYKuuunlH82ZjZpZmtO36b7QdG9y5rdAvx+9qn8K4FjPYe8ZXkrAw7hh7n8PXq38TXAN/u0+TZwhZmtzw5zr8juK8zMrgQ+BLzJ3fteAXWF2yrv+L2fwfzOgOddSazEFf2EL/jp5NV0PwV/CPhIdt9f0l3xABN0Dy/3Aj8ELi1x7NfQPWS8G9id/VwNvAd4T9bmvcB9dD/9vAN4dYnjX5o9713ZGKeXv3d8Az6brZ97gK0lr/9JusG7rue+oS0/3X8q+4EFuu8730X3M5jvAA8C/wlsyNpuBb7Q0/ed2etgL/COEsffS/f98OnXwOlvfy4Ebj3Ttipp/H/Otu3ddAP4guXjD4qVoj86XVYkEcl9QCeSKgW7SCIU7CKJULCLJELBLpIIBbtIIhTsIon4fyUMky0n7P6ZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Input image (Up-scale factor 3): \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "ApjK2cmFBLHT",
        "colab_type": "code",
        "outputId": "cab0dfe7-36fb-491d-aeae-8882aaae3cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "print(\"Target image: \")\n",
        "trainExample3.imshow_target(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target image: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYr4OXxQBLHY",
        "colab_type": "text"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "ZnrN7VNRBLHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class SuperResolutionNet(nn.Module):\n",
        "    def __init__(self, r, activation=nn.Identity()):\n",
        "        super().__init__()\n",
        "        self.r = r\n",
        "        self.activation = activation\n",
        "\n",
        "        self.deconvolution = nn.PixelShuffle(self.r)\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Conv2d(3, 64, 5, padding=2),\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.Conv2d(64, 32, 3, padding=1),\n",
        "        ])\n",
        "\n",
        "        self.last_layer = nn.Conv2d(32, self.r * self.r * 3, 3, padding=1)\n",
        "\n",
        "        # self.params = list(self.layers.parameters())\n",
        "\n",
        "        self.l = len(self.layers) - 1  # The number of hidden layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = self.activation(layer(x))\n",
        "\n",
        "        x = self.last_layer(x)  # Don't use the activation on the last convolutional layer\n",
        "\n",
        "        if not self.training:\n",
        "          x = self.deconvolution(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIRe7RhFBLHg",
        "colab_type": "text"
      },
      "source": [
        "## Training Network\n",
        "Function to train a certain network with a certain data loader and hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfFaDMHRBLHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "\n",
        "from torch import optim\n",
        "from . import SuperResolutionNet\n",
        "\n",
        "def mse_to_psnr(mse):\n",
        "    return 10 * math.log10(1. / mse)\n",
        "\n",
        "def train(net, use_gpu, train_loader, r,\n",
        "          learning_rate=0.01,\n",
        "          max_epochs_without_improvement=100,\n",
        "          max_epochs=30000,\n",
        "          print_output=True,\n",
        "          momentum=0.9,\n",
        "          learning_rate_factor=0.99,\n",
        "          learning_rate_abs=0.00001,\n",
        "          beta1=0.9,\n",
        "          beta2=0.999):\n",
        "\n",
        "    # Decide to use GPU or not.\n",
        "    if use_gpu:\n",
        "        net = net.cuda()\n",
        "        if print_output:\n",
        "          print('Running on gpu')\n",
        "\n",
        "    # Set loss function and optimizer.\n",
        "    loss_function = nn.MSELoss()\n",
        "\n",
        "    optimizer = optim.Adam(\n",
        "    [\n",
        "        {\"params\": net.layers.parameters()},\n",
        "        {\"params\": net.last_layer.parameters(), \"lr\": learning_rate/10},\n",
        "    ],\n",
        "    lr=learning_rate,\n",
        ")\n",
        "\n",
        "    # Save computer name to use when storing network\n",
        "    computer_name = \"unknown\"\n",
        "    try:\n",
        "      computer_name = os.environ['COMPUTERNAME']\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    # Initialize loss.\n",
        "    lowest_loss = (0, float('inf'))\n",
        "    previous_loss = float('inf')\n",
        "    highest_psnr = - float('inf')\n",
        "\n",
        "    begin_time = time.time()\n",
        "    minimum_psnr_to_save = 20\n",
        "\n",
        "    # Start training.\n",
        "    for epoch in range(max_epochs):\n",
        "        train_loss = []\n",
        "\n",
        "        # Train and propagate through network.\n",
        "        net.train()\n",
        "        for input, target in train_loader:\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = net(input)\n",
        "            loss = loss_function(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        mean_train_loss = np.mean(train_loss)\n",
        "        mean_psnr = mse_to_psnr(mean_train_loss)\n",
        "\n",
        "        if previous_loss - mean_train_loss < 0:\n",
        "          old_learning_rate = optimizer.param_groups[0]['lr']\n",
        "          optimizer.param_groups[0]['lr']\n",
        "          new_learning_rate = max(0.0001, learning_rate_factor * old_learning_rate - learning_rate_abs)\n",
        "          optimizer.param_groups[0]['lr'] = new_learning_rate\n",
        "\n",
        "          # Learning rate of the last layer should be 10 times lower\n",
        "          optimizer.param_groups[1]['lr'] = new_learning_rate/10\n",
        "\n",
        "\n",
        "        previous_loss = mean_train_loss\n",
        "          \n",
        "\n",
        "        # Update the lowest loss if necessary.\n",
        "        if mean_train_loss < lowest_loss[1]:\n",
        "            #print(f\"Epoch: {epoch: >3} Training Loss: {mean_train_loss:.6f} Mean PSNR: {mean_psnr:.2f} in {time.time() - begin_time:.2f}s #\")\n",
        "            lowest_loss = (epoch, mean_train_loss)\n",
        "            highest_psnr = mean_psnr\n",
        "          \n",
        "\n",
        "            #If the psnr is above some threshold save this new best network.\n",
        "            if highest_psnr > minimum_psnr_to_save:\n",
        "                torch.save(net, f'SuperResulutionNet_best_of_run-{computer_name}')\n",
        "\n",
        "        if epoch % 10 == 0 and print_output:\n",
        "          \n",
        "            print(\n",
        "              f\"Epoch: {epoch: >3} in {str(datetime.timedelta(seconds=int(time.time() - begin_time)))}, best epoch so far: Epoch: {lowest_loss[0]: >3} Training Loss: {lowest_loss[1]:.6f} Mean PSNR: {highest_psnr:.2f}, lr={ optimizer.param_groups[0]['lr']:.5f}\")\n",
        "\n",
        "\n",
        "        # If we didn't improve for some amount of epoch, lets stop.\n",
        "        if epoch > lowest_loss[0] + max_epochs_without_improvement:\n",
        "            if print_output:\n",
        "                print(f\"No improvement for the last {max_epochs_without_improvement} epochs, so stopping training...\")\n",
        "            break\n",
        "\n",
        "    net.eval()\n",
        "    if highest_psnr >= minimum_psnr_to_save:\n",
        "        network_name = f'SuperResulutionNet_r-{r}_psnr-{int(round(highest_psnr * 100))}__mse-{int(round(lowest_loss[1] * 10000))}-{computer_name}'\n",
        "        old_file = os.path.join(\".\", f'SuperResulutionNet_best_of_run-{computer_name}')\n",
        "        new_file = os.path.join(\".\", network_name)\n",
        "        if print_output:\n",
        "            print(f'Saving best epoch ({lowest_loss[0]}) with loss: {lowest_loss[1]} and psnr: {highest_psnr} as:')\n",
        "            print(network_name)\n",
        "        os.rename(old_file, new_file)\n",
        "    elif print_output:\n",
        "        print(\"Not high enough psnr to save the network...\")\n",
        "\n",
        "    return lowest_loss[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1CywEXwxBLHo",
        "colab_type": "code",
        "outputId": "dcd358af-ac28-4f64-8ecc-0d97ee4a5f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "# Batch size.\n",
        "bs = 16\n",
        "\n",
        "# Upscale factor.\n",
        "r = 3\n",
        "\n",
        "# Amount of epochs.\n",
        "epochs = 20\n",
        "\n",
        "# Getting image data\n",
        "transform = transforms.Compose([transforms.ToTensor()])  # ,\n",
        "\n",
        "# Load the training data.\n",
        "training_set = SuperResolutionDataset(\"train_data/Set91\", r, use_gpu=use_gpu)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(training_set, batch_size=bs, shuffle=True)\n",
        "\n",
        "# Initialize the network.\n",
        "net = SuperResolutionNet(r, activation=nn.ReLU())\n",
        "\n",
        "train(net, use_gpu, train_loader, r)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  50 in 0:00:10, best epoch so far: Epoch:  50 Training Loss: 0.006712 Mean PSNR: 21.73, lr=0.01000\n",
            "Epoch:  60 in 0:00:12, best epoch so far: Epoch:  60 Training Loss: 0.006247 Mean PSNR: 22.04, lr=0.01000\n",
            "Epoch:  70 in 0:00:14, best epoch so far: Epoch:  70 Training Loss: 0.005872 Mean PSNR: 22.31, lr=0.01000\n",
            "Epoch:  80 in 0:00:16, best epoch so far: Epoch:  80 Training Loss: 0.005582 Mean PSNR: 22.53, lr=0.01000\n",
            "Epoch:  90 in 0:00:18, best epoch so far: Epoch:  90 Training Loss: 0.005317 Mean PSNR: 22.74, lr=0.01000\n",
            "Epoch: 100 in 0:00:20, best epoch so far: Epoch: 100 Training Loss: 0.005090 Mean PSNR: 22.93, lr=0.01000\n",
            "Epoch: 110 in 0:00:22, best epoch so far: Epoch: 110 Training Loss: 0.004880 Mean PSNR: 23.12, lr=0.00999\n",
            "Epoch: 120 in 0:00:24, best epoch so far: Epoch: 120 Training Loss: 0.004698 Mean PSNR: 23.28, lr=0.00999\n",
            "Epoch: 130 in 0:00:26, best epoch so far: Epoch: 130 Training Loss: 0.004534 Mean PSNR: 23.43, lr=0.00998\n",
            "Epoch: 140 in 0:00:28, best epoch so far: Epoch: 139 Training Loss: 0.004413 Mean PSNR: 23.55, lr=0.00996\n",
            "Epoch: 150 in 0:00:30, best epoch so far: Epoch: 150 Training Loss: 0.004277 Mean PSNR: 23.69, lr=0.00994\n",
            "Epoch: 160 in 0:00:33, best epoch so far: Epoch: 159 Training Loss: 0.004171 Mean PSNR: 23.80, lr=0.00990\n",
            "Epoch: 170 in 0:00:35, best epoch so far: Epoch: 170 Training Loss: 0.004076 Mean PSNR: 23.90, lr=0.00990\n",
            "Epoch: 180 in 0:00:37, best epoch so far: Epoch: 180 Training Loss: 0.003988 Mean PSNR: 23.99, lr=0.00988\n",
            "Epoch: 190 in 0:00:39, best epoch so far: Epoch: 190 Training Loss: 0.003904 Mean PSNR: 24.08, lr=0.00985\n",
            "Epoch: 200 in 0:00:41, best epoch so far: Epoch: 200 Training Loss: 0.003828 Mean PSNR: 24.17, lr=0.00984\n",
            "Epoch: 210 in 0:00:43, best epoch so far: Epoch: 210 Training Loss: 0.003763 Mean PSNR: 24.24, lr=0.00983\n",
            "Epoch: 220 in 0:00:45, best epoch so far: Epoch: 220 Training Loss: 0.003704 Mean PSNR: 24.31, lr=0.00981\n",
            "Epoch: 230 in 0:00:47, best epoch so far: Epoch: 230 Training Loss: 0.003645 Mean PSNR: 24.38, lr=0.00976\n",
            "Epoch: 240 in 0:00:49, best epoch so far: Epoch: 240 Training Loss: 0.003597 Mean PSNR: 24.44, lr=0.00975\n",
            "Epoch: 250 in 0:00:51, best epoch so far: Epoch: 250 Training Loss: 0.003544 Mean PSNR: 24.50, lr=0.00974\n",
            "Epoch: 260 in 0:00:53, best epoch so far: Epoch: 260 Training Loss: 0.003500 Mean PSNR: 24.56, lr=0.00973\n",
            "Epoch: 270 in 0:00:55, best epoch so far: Epoch: 270 Training Loss: 0.003457 Mean PSNR: 24.61, lr=0.00972\n",
            "Epoch: 280 in 0:00:57, best epoch so far: Epoch: 279 Training Loss: 0.003416 Mean PSNR: 24.66, lr=0.00970\n",
            "Epoch: 290 in 0:00:59, best epoch so far: Epoch: 290 Training Loss: 0.003379 Mean PSNR: 24.71, lr=0.00968\n",
            "Epoch: 300 in 0:01:01, best epoch so far: Epoch: 300 Training Loss: 0.003348 Mean PSNR: 24.75, lr=0.00965\n",
            "Epoch: 310 in 0:01:03, best epoch so far: Epoch: 310 Training Loss: 0.003304 Mean PSNR: 24.81, lr=0.00962\n",
            "Epoch: 320 in 0:01:05, best epoch so far: Epoch: 320 Training Loss: 0.003276 Mean PSNR: 24.85, lr=0.00959\n",
            "Epoch: 330 in 0:01:07, best epoch so far: Epoch: 330 Training Loss: 0.003248 Mean PSNR: 24.88, lr=0.00954\n",
            "Epoch: 340 in 0:01:10, best epoch so far: Epoch: 340 Training Loss: 0.003213 Mean PSNR: 24.93, lr=0.00951\n",
            "Epoch: 350 in 0:01:12, best epoch so far: Epoch: 350 Training Loss: 0.003184 Mean PSNR: 24.97, lr=0.00948\n",
            "Epoch: 360 in 0:01:14, best epoch so far: Epoch: 359 Training Loss: 0.003162 Mean PSNR: 25.00, lr=0.00945\n",
            "Epoch: 370 in 0:01:16, best epoch so far: Epoch: 369 Training Loss: 0.003132 Mean PSNR: 25.04, lr=0.00940\n",
            "Epoch: 380 in 0:01:18, best epoch so far: Epoch: 380 Training Loss: 0.003105 Mean PSNR: 25.08, lr=0.00937\n",
            "Epoch: 390 in 0:01:20, best epoch so far: Epoch: 390 Training Loss: 0.003086 Mean PSNR: 25.11, lr=0.00934\n",
            "Epoch: 400 in 0:01:22, best epoch so far: Epoch: 398 Training Loss: 0.003068 Mean PSNR: 25.13, lr=0.00930\n",
            "Epoch: 410 in 0:01:24, best epoch so far: Epoch: 410 Training Loss: 0.003050 Mean PSNR: 25.16, lr=0.00925\n",
            "Epoch: 420 in 0:01:26, best epoch so far: Epoch: 420 Training Loss: 0.003026 Mean PSNR: 25.19, lr=0.00922\n",
            "Epoch: 430 in 0:01:28, best epoch so far: Epoch: 430 Training Loss: 0.003010 Mean PSNR: 25.21, lr=0.00919\n",
            "Epoch: 440 in 0:01:30, best epoch so far: Epoch: 438 Training Loss: 0.002992 Mean PSNR: 25.24, lr=0.00914\n",
            "Epoch: 450 in 0:01:32, best epoch so far: Epoch: 450 Training Loss: 0.002972 Mean PSNR: 25.27, lr=0.00911\n",
            "Epoch: 460 in 0:01:34, best epoch so far: Epoch: 460 Training Loss: 0.002951 Mean PSNR: 25.30, lr=0.00906\n",
            "Epoch: 470 in 0:01:36, best epoch so far: Epoch: 470 Training Loss: 0.002939 Mean PSNR: 25.32, lr=0.00904\n",
            "Epoch: 480 in 0:01:38, best epoch so far: Epoch: 479 Training Loss: 0.002926 Mean PSNR: 25.34, lr=0.00900\n",
            "Epoch: 490 in 0:01:40, best epoch so far: Epoch: 488 Training Loss: 0.002914 Mean PSNR: 25.36, lr=0.00897\n",
            "Epoch: 500 in 0:01:42, best epoch so far: Epoch: 496 Training Loss: 0.002898 Mean PSNR: 25.38, lr=0.00892\n",
            "Epoch: 510 in 0:01:44, best epoch so far: Epoch: 510 Training Loss: 0.002887 Mean PSNR: 25.40, lr=0.00889\n",
            "Epoch: 520 in 0:01:46, best epoch so far: Epoch: 517 Training Loss: 0.002870 Mean PSNR: 25.42, lr=0.00884\n",
            "Epoch: 530 in 0:01:48, best epoch so far: Epoch: 530 Training Loss: 0.002855 Mean PSNR: 25.44, lr=0.00880\n",
            "Epoch: 540 in 0:01:50, best epoch so far: Epoch: 537 Training Loss: 0.002846 Mean PSNR: 25.46, lr=0.00875\n",
            "Epoch: 550 in 0:01:52, best epoch so far: Epoch: 550 Training Loss: 0.002830 Mean PSNR: 25.48, lr=0.00871\n",
            "Epoch: 560 in 0:01:54, best epoch so far: Epoch: 558 Training Loss: 0.002825 Mean PSNR: 25.49, lr=0.00865\n",
            "Epoch: 570 in 0:01:56, best epoch so far: Epoch: 568 Training Loss: 0.002814 Mean PSNR: 25.51, lr=0.00861\n",
            "Epoch: 580 in 0:01:58, best epoch so far: Epoch: 578 Training Loss: 0.002800 Mean PSNR: 25.53, lr=0.00856\n",
            "Epoch: 590 in 0:02:00, best epoch so far: Epoch: 590 Training Loss: 0.002790 Mean PSNR: 25.54, lr=0.00854\n",
            "Epoch: 600 in 0:02:02, best epoch so far: Epoch: 598 Training Loss: 0.002785 Mean PSNR: 25.55, lr=0.00849\n",
            "Epoch: 610 in 0:02:04, best epoch so far: Epoch: 605 Training Loss: 0.002775 Mean PSNR: 25.57, lr=0.00843\n",
            "Epoch: 620 in 0:02:06, best epoch so far: Epoch: 620 Training Loss: 0.002767 Mean PSNR: 25.58, lr=0.00839\n",
            "Epoch: 630 in 0:02:09, best epoch so far: Epoch: 629 Training Loss: 0.002755 Mean PSNR: 25.60, lr=0.00835\n",
            "Epoch: 640 in 0:02:11, best epoch so far: Epoch: 638 Training Loss: 0.002747 Mean PSNR: 25.61, lr=0.00831\n",
            "Epoch: 650 in 0:02:13, best epoch so far: Epoch: 648 Training Loss: 0.002740 Mean PSNR: 25.62, lr=0.00825\n",
            "Epoch: 660 in 0:02:15, best epoch so far: Epoch: 655 Training Loss: 0.002734 Mean PSNR: 25.63, lr=0.00820\n",
            "Epoch: 670 in 0:02:17, best epoch so far: Epoch: 666 Training Loss: 0.002728 Mean PSNR: 25.64, lr=0.00816\n",
            "Epoch: 680 in 0:02:19, best epoch so far: Epoch: 679 Training Loss: 0.002714 Mean PSNR: 25.66, lr=0.00812\n",
            "Epoch: 690 in 0:02:21, best epoch so far: Epoch: 690 Training Loss: 0.002709 Mean PSNR: 25.67, lr=0.00808\n",
            "Epoch: 700 in 0:02:23, best epoch so far: Epoch: 698 Training Loss: 0.002704 Mean PSNR: 25.68, lr=0.00804\n",
            "Epoch: 710 in 0:02:25, best epoch so far: Epoch: 710 Training Loss: 0.002694 Mean PSNR: 25.70, lr=0.00800\n",
            "Epoch: 720 in 0:02:27, best epoch so far: Epoch: 719 Training Loss: 0.002689 Mean PSNR: 25.70, lr=0.00796\n",
            "Epoch: 730 in 0:02:29, best epoch so far: Epoch: 719 Training Loss: 0.002689 Mean PSNR: 25.70, lr=0.00791\n",
            "Epoch: 740 in 0:02:31, best epoch so far: Epoch: 740 Training Loss: 0.002676 Mean PSNR: 25.73, lr=0.00788\n",
            "Epoch: 750 in 0:02:33, best epoch so far: Epoch: 747 Training Loss: 0.002672 Mean PSNR: 25.73, lr=0.00782\n",
            "Epoch: 760 in 0:02:35, best epoch so far: Epoch: 755 Training Loss: 0.002667 Mean PSNR: 25.74, lr=0.00778\n",
            "Epoch: 770 in 0:02:37, best epoch so far: Epoch: 762 Training Loss: 0.002663 Mean PSNR: 25.75, lr=0.00773\n",
            "Epoch: 780 in 0:02:39, best epoch so far: Epoch: 777 Training Loss: 0.002657 Mean PSNR: 25.76, lr=0.00769\n",
            "Epoch: 790 in 0:02:41, best epoch so far: Epoch: 785 Training Loss: 0.002653 Mean PSNR: 25.76, lr=0.00765\n",
            "Epoch: 800 in 0:02:43, best epoch so far: Epoch: 798 Training Loss: 0.002644 Mean PSNR: 25.78, lr=0.00760\n",
            "Epoch: 810 in 0:02:45, best epoch so far: Epoch: 808 Training Loss: 0.002643 Mean PSNR: 25.78, lr=0.00757\n",
            "Epoch: 820 in 0:02:47, best epoch so far: Epoch: 817 Training Loss: 0.002641 Mean PSNR: 25.78, lr=0.00751\n",
            "Epoch: 830 in 0:02:49, best epoch so far: Epoch: 826 Training Loss: 0.002634 Mean PSNR: 25.79, lr=0.00746\n",
            "Epoch: 840 in 0:02:51, best epoch so far: Epoch: 838 Training Loss: 0.002631 Mean PSNR: 25.80, lr=0.00742\n",
            "Epoch: 850 in 0:02:53, best epoch so far: Epoch: 850 Training Loss: 0.002626 Mean PSNR: 25.81, lr=0.00737\n",
            "Epoch: 860 in 0:02:55, best epoch so far: Epoch: 851 Training Loss: 0.002621 Mean PSNR: 25.82, lr=0.00732\n",
            "Epoch: 870 in 0:02:57, best epoch so far: Epoch: 866 Training Loss: 0.002618 Mean PSNR: 25.82, lr=0.00728\n",
            "Epoch: 880 in 0:02:59, best epoch so far: Epoch: 880 Training Loss: 0.002616 Mean PSNR: 25.82, lr=0.00724\n",
            "Epoch: 890 in 0:03:01, best epoch so far: Epoch: 882 Training Loss: 0.002609 Mean PSNR: 25.84, lr=0.00718\n",
            "Epoch: 900 in 0:03:04, best epoch so far: Epoch: 899 Training Loss: 0.002603 Mean PSNR: 25.85, lr=0.00713\n",
            "Epoch: 910 in 0:03:06, best epoch so far: Epoch: 906 Training Loss: 0.002601 Mean PSNR: 25.85, lr=0.00708\n",
            "Epoch: 920 in 0:03:08, best epoch so far: Epoch: 919 Training Loss: 0.002597 Mean PSNR: 25.86, lr=0.00702\n",
            "Epoch: 930 in 0:03:10, best epoch so far: Epoch: 919 Training Loss: 0.002597 Mean PSNR: 25.86, lr=0.00696\n",
            "Epoch: 940 in 0:03:12, best epoch so far: Epoch: 940 Training Loss: 0.002591 Mean PSNR: 25.87, lr=0.00692\n",
            "Epoch: 950 in 0:03:14, best epoch so far: Epoch: 946 Training Loss: 0.002588 Mean PSNR: 25.87, lr=0.00687\n",
            "Epoch: 960 in 0:03:16, best epoch so far: Epoch: 958 Training Loss: 0.002585 Mean PSNR: 25.88, lr=0.00683\n",
            "Epoch: 970 in 0:03:18, best epoch so far: Epoch: 968 Training Loss: 0.002579 Mean PSNR: 25.89, lr=0.00677\n",
            "Epoch: 980 in 0:03:20, best epoch so far: Epoch: 975 Training Loss: 0.002575 Mean PSNR: 25.89, lr=0.00674\n",
            "Epoch: 990 in 0:03:22, best epoch so far: Epoch: 981 Training Loss: 0.002574 Mean PSNR: 25.89, lr=0.00668\n",
            "Epoch: 1000 in 0:03:24, best epoch so far: Epoch: 992 Training Loss: 0.002571 Mean PSNR: 25.90, lr=0.00664\n",
            "Epoch: 1010 in 0:03:26, best epoch so far: Epoch: 1006 Training Loss: 0.002566 Mean PSNR: 25.91, lr=0.00661\n",
            "Epoch: 1020 in 0:03:28, best epoch so far: Epoch: 1012 Training Loss: 0.002565 Mean PSNR: 25.91, lr=0.00655\n",
            "Epoch: 1030 in 0:03:30, best epoch so far: Epoch: 1022 Training Loss: 0.002564 Mean PSNR: 25.91, lr=0.00649\n",
            "Epoch: 1040 in 0:03:32, best epoch so far: Epoch: 1037 Training Loss: 0.002560 Mean PSNR: 25.92, lr=0.00644\n",
            "Epoch: 1050 in 0:03:34, best epoch so far: Epoch: 1042 Training Loss: 0.002559 Mean PSNR: 25.92, lr=0.00639\n",
            "Epoch: 1060 in 0:03:36, best epoch so far: Epoch: 1054 Training Loss: 0.002555 Mean PSNR: 25.93, lr=0.00634\n",
            "Epoch: 1070 in 0:03:38, best epoch so far: Epoch: 1054 Training Loss: 0.002555 Mean PSNR: 25.93, lr=0.00630\n",
            "Epoch: 1080 in 0:03:40, best epoch so far: Epoch: 1080 Training Loss: 0.002551 Mean PSNR: 25.93, lr=0.00625\n",
            "Epoch: 1090 in 0:03:42, best epoch so far: Epoch: 1089 Training Loss: 0.002547 Mean PSNR: 25.94, lr=0.00619\n",
            "Epoch: 1100 in 0:03:44, best epoch so far: Epoch: 1093 Training Loss: 0.002544 Mean PSNR: 25.94, lr=0.00615\n",
            "Epoch: 1110 in 0:03:46, best epoch so far: Epoch: 1093 Training Loss: 0.002544 Mean PSNR: 25.94, lr=0.00612\n",
            "Epoch: 1120 in 0:03:48, best epoch so far: Epoch: 1117 Training Loss: 0.002541 Mean PSNR: 25.95, lr=0.00608\n",
            "Epoch: 1130 in 0:03:50, best epoch so far: Epoch: 1125 Training Loss: 0.002538 Mean PSNR: 25.96, lr=0.00603\n",
            "Epoch: 1140 in 0:03:52, best epoch so far: Epoch: 1140 Training Loss: 0.002536 Mean PSNR: 25.96, lr=0.00599\n",
            "Epoch: 1150 in 0:03:54, best epoch so far: Epoch: 1146 Training Loss: 0.002533 Mean PSNR: 25.96, lr=0.00594\n",
            "Epoch: 1160 in 0:03:56, best epoch so far: Epoch: 1157 Training Loss: 0.002531 Mean PSNR: 25.97, lr=0.00588\n",
            "Epoch: 1170 in 0:03:58, best epoch so far: Epoch: 1166 Training Loss: 0.002531 Mean PSNR: 25.97, lr=0.00582\n",
            "Epoch: 1180 in 0:04:00, best epoch so far: Epoch: 1180 Training Loss: 0.002525 Mean PSNR: 25.98, lr=0.00578\n",
            "Epoch: 1190 in 0:04:02, best epoch so far: Epoch: 1187 Training Loss: 0.002523 Mean PSNR: 25.98, lr=0.00572\n",
            "Epoch: 1200 in 0:04:04, best epoch so far: Epoch: 1191 Training Loss: 0.002523 Mean PSNR: 25.98, lr=0.00567\n",
            "Epoch: 1210 in 0:04:06, best epoch so far: Epoch: 1203 Training Loss: 0.002523 Mean PSNR: 25.98, lr=0.00562\n",
            "Epoch: 1220 in 0:04:08, best epoch so far: Epoch: 1220 Training Loss: 0.002520 Mean PSNR: 25.99, lr=0.00558\n",
            "Epoch: 1230 in 0:04:10, best epoch so far: Epoch: 1226 Training Loss: 0.002519 Mean PSNR: 25.99, lr=0.00553\n",
            "Epoch: 1240 in 0:04:12, best epoch so far: Epoch: 1237 Training Loss: 0.002515 Mean PSNR: 26.00, lr=0.00548\n",
            "Epoch: 1250 in 0:04:14, best epoch so far: Epoch: 1237 Training Loss: 0.002515 Mean PSNR: 26.00, lr=0.00544\n",
            "Epoch: 1260 in 0:04:16, best epoch so far: Epoch: 1255 Training Loss: 0.002514 Mean PSNR: 26.00, lr=0.00538\n",
            "Epoch: 1270 in 0:04:18, best epoch so far: Epoch: 1265 Training Loss: 0.002512 Mean PSNR: 26.00, lr=0.00535\n",
            "Epoch: 1280 in 0:04:20, best epoch so far: Epoch: 1279 Training Loss: 0.002511 Mean PSNR: 26.00, lr=0.00530\n",
            "Epoch: 1290 in 0:04:22, best epoch so far: Epoch: 1287 Training Loss: 0.002508 Mean PSNR: 26.01, lr=0.00524\n",
            "Epoch: 1300 in 0:04:25, best epoch so far: Epoch: 1296 Training Loss: 0.002507 Mean PSNR: 26.01, lr=0.00519\n",
            "Epoch: 1310 in 0:04:27, best epoch so far: Epoch: 1296 Training Loss: 0.002507 Mean PSNR: 26.01, lr=0.00513\n",
            "Epoch: 1320 in 0:04:29, best epoch so far: Epoch: 1320 Training Loss: 0.002501 Mean PSNR: 26.02, lr=0.00510\n",
            "Epoch: 1330 in 0:04:31, best epoch so far: Epoch: 1320 Training Loss: 0.002501 Mean PSNR: 26.02, lr=0.00504\n",
            "Epoch: 1340 in 0:04:33, best epoch so far: Epoch: 1332 Training Loss: 0.002500 Mean PSNR: 26.02, lr=0.00498\n",
            "Epoch: 1350 in 0:04:35, best epoch so far: Epoch: 1347 Training Loss: 0.002500 Mean PSNR: 26.02, lr=0.00493\n",
            "Epoch: 1360 in 0:04:37, best epoch so far: Epoch: 1355 Training Loss: 0.002497 Mean PSNR: 26.03, lr=0.00488\n",
            "Epoch: 1370 in 0:04:39, best epoch so far: Epoch: 1370 Training Loss: 0.002495 Mean PSNR: 26.03, lr=0.00485\n",
            "Epoch: 1380 in 0:04:41, best epoch so far: Epoch: 1380 Training Loss: 0.002493 Mean PSNR: 26.03, lr=0.00480\n",
            "Epoch: 1390 in 0:04:43, best epoch so far: Epoch: 1390 Training Loss: 0.002490 Mean PSNR: 26.04, lr=0.00475\n",
            "Epoch: 1400 in 0:04:45, best epoch so far: Epoch: 1398 Training Loss: 0.002489 Mean PSNR: 26.04, lr=0.00470\n",
            "Epoch: 1410 in 0:04:47, best epoch so far: Epoch: 1398 Training Loss: 0.002489 Mean PSNR: 26.04, lr=0.00466\n",
            "Epoch: 1420 in 0:04:49, best epoch so far: Epoch: 1417 Training Loss: 0.002486 Mean PSNR: 26.04, lr=0.00461\n",
            "Epoch: 1430 in 0:04:51, best epoch so far: Epoch: 1417 Training Loss: 0.002486 Mean PSNR: 26.04, lr=0.00456\n",
            "Epoch: 1440 in 0:04:54, best epoch so far: Epoch: 1417 Training Loss: 0.002486 Mean PSNR: 26.04, lr=0.00453\n",
            "Epoch: 1450 in 0:04:56, best epoch so far: Epoch: 1417 Training Loss: 0.002486 Mean PSNR: 26.04, lr=0.00447\n",
            "Epoch: 1460 in 0:04:57, best epoch so far: Epoch: 1417 Training Loss: 0.002486 Mean PSNR: 26.04, lr=0.00444\n",
            "Epoch: 1470 in 0:04:59, best epoch so far: Epoch: 1468 Training Loss: 0.002482 Mean PSNR: 26.05, lr=0.00440\n",
            "Epoch: 1480 in 0:05:02, best epoch so far: Epoch: 1472 Training Loss: 0.002481 Mean PSNR: 26.05, lr=0.00437\n",
            "Epoch: 1490 in 0:05:04, best epoch so far: Epoch: 1490 Training Loss: 0.002481 Mean PSNR: 26.05, lr=0.00433\n",
            "Epoch: 1500 in 0:05:06, best epoch so far: Epoch: 1490 Training Loss: 0.002481 Mean PSNR: 26.05, lr=0.00427\n",
            "Epoch: 1510 in 0:05:08, best epoch so far: Epoch: 1506 Training Loss: 0.002477 Mean PSNR: 26.06, lr=0.00423\n",
            "Epoch: 1520 in 0:05:10, best epoch so far: Epoch: 1518 Training Loss: 0.002476 Mean PSNR: 26.06, lr=0.00418\n",
            "Epoch: 1530 in 0:05:12, best epoch so far: Epoch: 1518 Training Loss: 0.002476 Mean PSNR: 26.06, lr=0.00413\n",
            "Epoch: 1540 in 0:05:14, best epoch so far: Epoch: 1537 Training Loss: 0.002473 Mean PSNR: 26.07, lr=0.00408\n",
            "Epoch: 1550 in 0:05:16, best epoch so far: Epoch: 1537 Training Loss: 0.002473 Mean PSNR: 26.07, lr=0.00403\n",
            "Epoch: 1560 in 0:05:18, best epoch so far: Epoch: 1537 Training Loss: 0.002473 Mean PSNR: 26.07, lr=0.00398\n",
            "Epoch: 1570 in 0:05:20, best epoch so far: Epoch: 1537 Training Loss: 0.002473 Mean PSNR: 26.07, lr=0.00394\n",
            "Epoch: 1580 in 0:05:22, best epoch so far: Epoch: 1574 Training Loss: 0.002469 Mean PSNR: 26.07, lr=0.00388\n",
            "Epoch: 1590 in 0:05:24, best epoch so far: Epoch: 1574 Training Loss: 0.002469 Mean PSNR: 26.07, lr=0.00384\n",
            "Epoch: 1600 in 0:05:26, best epoch so far: Epoch: 1574 Training Loss: 0.002469 Mean PSNR: 26.07, lr=0.00381\n",
            "Epoch: 1610 in 0:05:28, best epoch so far: Epoch: 1605 Training Loss: 0.002466 Mean PSNR: 26.08, lr=0.00378\n",
            "Epoch: 1620 in 0:05:30, best epoch so far: Epoch: 1605 Training Loss: 0.002466 Mean PSNR: 26.08, lr=0.00373\n",
            "Epoch: 1630 in 0:05:32, best epoch so far: Epoch: 1630 Training Loss: 0.002466 Mean PSNR: 26.08, lr=0.00369\n",
            "Epoch: 1640 in 0:05:35, best epoch so far: Epoch: 1638 Training Loss: 0.002463 Mean PSNR: 26.08, lr=0.00363\n",
            "Epoch: 1650 in 0:05:37, best epoch so far: Epoch: 1638 Training Loss: 0.002463 Mean PSNR: 26.08, lr=0.00359\n",
            "Epoch: 1660 in 0:05:39, best epoch so far: Epoch: 1659 Training Loss: 0.002463 Mean PSNR: 26.09, lr=0.00355\n",
            "Epoch: 1670 in 0:05:41, best epoch so far: Epoch: 1663 Training Loss: 0.002461 Mean PSNR: 26.09, lr=0.00351\n",
            "Epoch: 1680 in 0:05:43, best epoch so far: Epoch: 1663 Training Loss: 0.002461 Mean PSNR: 26.09, lr=0.00344\n",
            "Epoch: 1690 in 0:05:45, best epoch so far: Epoch: 1685 Training Loss: 0.002461 Mean PSNR: 26.09, lr=0.00339\n",
            "Epoch: 1700 in 0:05:47, best epoch so far: Epoch: 1694 Training Loss: 0.002460 Mean PSNR: 26.09, lr=0.00333\n",
            "Epoch: 1710 in 0:05:49, best epoch so far: Epoch: 1706 Training Loss: 0.002458 Mean PSNR: 26.09, lr=0.00328\n",
            "Epoch: 1720 in 0:05:51, best epoch so far: Epoch: 1706 Training Loss: 0.002458 Mean PSNR: 26.09, lr=0.00324\n",
            "Epoch: 1730 in 0:05:53, best epoch so far: Epoch: 1706 Training Loss: 0.002458 Mean PSNR: 26.09, lr=0.00319\n",
            "Epoch: 1740 in 0:05:55, best epoch so far: Epoch: 1706 Training Loss: 0.002458 Mean PSNR: 26.09, lr=0.00314\n",
            "Epoch: 1750 in 0:05:57, best epoch so far: Epoch: 1744 Training Loss: 0.002456 Mean PSNR: 26.10, lr=0.00308\n",
            "Epoch: 1760 in 0:05:59, best epoch so far: Epoch: 1744 Training Loss: 0.002456 Mean PSNR: 26.10, lr=0.00304\n",
            "Epoch: 1770 in 0:06:01, best epoch so far: Epoch: 1767 Training Loss: 0.002455 Mean PSNR: 26.10, lr=0.00299\n",
            "Epoch: 1780 in 0:06:03, best epoch so far: Epoch: 1767 Training Loss: 0.002455 Mean PSNR: 26.10, lr=0.00292\n",
            "Epoch: 1790 in 0:06:05, best epoch so far: Epoch: 1789 Training Loss: 0.002454 Mean PSNR: 26.10, lr=0.00287\n",
            "Epoch: 1800 in 0:06:07, best epoch so far: Epoch: 1797 Training Loss: 0.002453 Mean PSNR: 26.10, lr=0.00281\n",
            "Epoch: 1810 in 0:06:09, best epoch so far: Epoch: 1806 Training Loss: 0.002452 Mean PSNR: 26.11, lr=0.00276\n",
            "Epoch: 1820 in 0:06:11, best epoch so far: Epoch: 1815 Training Loss: 0.002451 Mean PSNR: 26.11, lr=0.00272\n",
            "Epoch: 1830 in 0:06:13, best epoch so far: Epoch: 1815 Training Loss: 0.002451 Mean PSNR: 26.11, lr=0.00266\n",
            "Epoch: 1840 in 0:06:15, best epoch so far: Epoch: 1815 Training Loss: 0.002451 Mean PSNR: 26.11, lr=0.00261\n",
            "Epoch: 1850 in 0:06:17, best epoch so far: Epoch: 1815 Training Loss: 0.002451 Mean PSNR: 26.11, lr=0.00256\n",
            "Epoch: 1860 in 0:06:19, best epoch so far: Epoch: 1852 Training Loss: 0.002450 Mean PSNR: 26.11, lr=0.00249\n",
            "Epoch: 1870 in 0:06:21, best epoch so far: Epoch: 1852 Training Loss: 0.002450 Mean PSNR: 26.11, lr=0.00245\n",
            "Epoch: 1880 in 0:06:23, best epoch so far: Epoch: 1880 Training Loss: 0.002448 Mean PSNR: 26.11, lr=0.00242\n",
            "Epoch: 1890 in 0:06:25, best epoch so far: Epoch: 1890 Training Loss: 0.002445 Mean PSNR: 26.12, lr=0.00238\n",
            "Epoch: 1900 in 0:06:27, best epoch so far: Epoch: 1890 Training Loss: 0.002445 Mean PSNR: 26.12, lr=0.00233\n",
            "Epoch: 1910 in 0:06:29, best epoch so far: Epoch: 1890 Training Loss: 0.002445 Mean PSNR: 26.12, lr=0.00226\n",
            "Epoch: 1920 in 0:06:31, best epoch so far: Epoch: 1890 Training Loss: 0.002445 Mean PSNR: 26.12, lr=0.00223\n",
            "Epoch: 1930 in 0:06:33, best epoch so far: Epoch: 1890 Training Loss: 0.002445 Mean PSNR: 26.12, lr=0.00218\n",
            "Epoch: 1940 in 0:06:35, best epoch so far: Epoch: 1936 Training Loss: 0.002445 Mean PSNR: 26.12, lr=0.00212\n",
            "Epoch: 1950 in 0:06:37, best epoch so far: Epoch: 1936 Training Loss: 0.002445 Mean PSNR: 26.12, lr=0.00207\n",
            "Epoch: 1960 in 0:06:39, best epoch so far: Epoch: 1954 Training Loss: 0.002444 Mean PSNR: 26.12, lr=0.00202\n",
            "Epoch: 1970 in 0:06:41, best epoch so far: Epoch: 1966 Training Loss: 0.002443 Mean PSNR: 26.12, lr=0.00196\n",
            "Epoch: 1980 in 0:06:43, best epoch so far: Epoch: 1966 Training Loss: 0.002443 Mean PSNR: 26.12, lr=0.00191\n",
            "Epoch: 1990 in 0:06:45, best epoch so far: Epoch: 1985 Training Loss: 0.002442 Mean PSNR: 26.12, lr=0.00186\n",
            "Epoch: 2000 in 0:06:47, best epoch so far: Epoch: 1985 Training Loss: 0.002442 Mean PSNR: 26.12, lr=0.00180\n",
            "Epoch: 2010 in 0:06:50, best epoch so far: Epoch: 1985 Training Loss: 0.002442 Mean PSNR: 26.12, lr=0.00176\n",
            "Epoch: 2020 in 0:06:52, best epoch so far: Epoch: 1985 Training Loss: 0.002442 Mean PSNR: 26.12, lr=0.00171\n",
            "Epoch: 2030 in 0:06:54, best epoch so far: Epoch: 1985 Training Loss: 0.002442 Mean PSNR: 26.12, lr=0.00166\n",
            "Epoch: 2040 in 0:06:56, best epoch so far: Epoch: 2039 Training Loss: 0.002442 Mean PSNR: 26.12, lr=0.00161\n",
            "Epoch: 2050 in 0:06:58, best epoch so far: Epoch: 2047 Training Loss: 0.002440 Mean PSNR: 26.13, lr=0.00155\n",
            "Epoch: 2060 in 0:07:00, best epoch so far: Epoch: 2057 Training Loss: 0.002439 Mean PSNR: 26.13, lr=0.00149\n",
            "Epoch: 2070 in 0:07:02, best epoch so far: Epoch: 2057 Training Loss: 0.002439 Mean PSNR: 26.13, lr=0.00144\n",
            "Epoch: 2080 in 0:07:04, best epoch so far: Epoch: 2057 Training Loss: 0.002439 Mean PSNR: 26.13, lr=0.00136\n",
            "Epoch: 2090 in 0:07:06, best epoch so far: Epoch: 2057 Training Loss: 0.002439 Mean PSNR: 26.13, lr=0.00131\n",
            "Epoch: 2100 in 0:07:08, best epoch so far: Epoch: 2057 Training Loss: 0.002439 Mean PSNR: 26.13, lr=0.00127\n",
            "Epoch: 2110 in 0:07:10, best epoch so far: Epoch: 2105 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00121\n",
            "Epoch: 2120 in 0:07:12, best epoch so far: Epoch: 2105 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00115\n",
            "Epoch: 2130 in 0:07:14, best epoch so far: Epoch: 2105 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00110\n",
            "Epoch: 2140 in 0:07:16, best epoch so far: Epoch: 2105 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00104\n",
            "Epoch: 2150 in 0:07:18, best epoch so far: Epoch: 2105 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00099\n",
            "Epoch: 2160 in 0:07:20, best epoch so far: Epoch: 2105 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00095\n",
            "Epoch: 2170 in 0:07:22, best epoch so far: Epoch: 2161 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00090\n",
            "Epoch: 2180 in 0:07:24, best epoch so far: Epoch: 2161 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00085\n",
            "Epoch: 2190 in 0:07:26, best epoch so far: Epoch: 2161 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00082\n",
            "Epoch: 2200 in 0:07:28, best epoch so far: Epoch: 2161 Training Loss: 0.002436 Mean PSNR: 26.13, lr=0.00078\n",
            "Epoch: 2210 in 0:07:30, best epoch so far: Epoch: 2209 Training Loss: 0.002435 Mean PSNR: 26.13, lr=0.00073\n",
            "Epoch: 2220 in 0:07:32, best epoch so far: Epoch: 2209 Training Loss: 0.002435 Mean PSNR: 26.13, lr=0.00068\n",
            "Epoch: 2230 in 0:07:34, best epoch so far: Epoch: 2221 Training Loss: 0.002435 Mean PSNR: 26.13, lr=0.00064\n",
            "Epoch: 2240 in 0:07:36, best epoch so far: Epoch: 2221 Training Loss: 0.002435 Mean PSNR: 26.13, lr=0.00059\n",
            "Epoch: 2250 in 0:07:38, best epoch so far: Epoch: 2221 Training Loss: 0.002435 Mean PSNR: 26.13, lr=0.00054\n",
            "Epoch: 2260 in 0:07:40, best epoch so far: Epoch: 2260 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00050\n",
            "Epoch: 2270 in 0:07:42, best epoch so far: Epoch: 2260 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00045\n",
            "Epoch: 2280 in 0:07:44, best epoch so far: Epoch: 2260 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00040\n",
            "Epoch: 2290 in 0:07:46, best epoch so far: Epoch: 2285 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00035\n",
            "Epoch: 2300 in 0:07:48, best epoch so far: Epoch: 2285 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00030\n",
            "Epoch: 2310 in 0:07:50, best epoch so far: Epoch: 2285 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00026\n",
            "Epoch: 2320 in 0:07:52, best epoch so far: Epoch: 2285 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00021\n",
            "Epoch: 2330 in 0:07:55, best epoch so far: Epoch: 2285 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00016\n",
            "Epoch: 2340 in 0:07:57, best epoch so far: Epoch: 2285 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2350 in 0:07:59, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2360 in 0:08:01, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2370 in 0:08:03, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2380 in 0:08:05, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2390 in 0:08:07, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2400 in 0:08:09, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2410 in 0:08:11, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2420 in 0:08:13, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2430 in 0:08:15, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "Epoch: 2440 in 0:08:17, best epoch so far: Epoch: 2344 Training Loss: 0.002434 Mean PSNR: 26.14, lr=0.00010\n",
            "No improvement for the last 100 epochs, so stopping training...\n",
            "Saving best epoch (2344) with loss: 0.002433761823900008 and psnr: 26.13721925541946 as:\n",
            "SuperResulutionNet_r-3_psnr-2614__mse-24-unknown\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002433761823900008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 291
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI5xM65NBLHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQUNCaCnBLH0",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "_lIPhVkgBLH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from os import listdir\n",
        "\n",
        "# from SuperResolutionDataset import SuperResolutionDataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.figure()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "def evaluate_by_name(network_name):\n",
        "    net = torch.load(network_name)\n",
        "    evaluate(net)\n",
        "\n",
        "def mse_to_psnr(mse):\n",
        "    return 10 * math.log10(1. / mse)\n",
        "    \n",
        "def evaluate(net):\n",
        "    r = net.r\n",
        "    print(f\"r: {r}\")\n",
        "    net.eval()\n",
        "\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "\n",
        "    test_set_paths = [\"test_data/\" + f for f in listdir(\"test_data\")]\n",
        "#     test_set_paths = [\"test_data/Custom\"]\n",
        "\n",
        "    all_psnr = []\n",
        "    for path in test_set_paths:\n",
        "        psnr = []\n",
        "        test_set = SuperResolutionDataset(path, r, use_gpu=use_gpu, testing=True)\n",
        "\n",
        "\n",
        "        test_loader = torch.utils.data.DataLoader(test_set,\n",
        "                                                  batch_size=1,\n",
        "                                                  shuffle=True,\n",
        "                                                  num_workers=0)\n",
        "\n",
        "\n",
        "        for input, target in iter(test_loader):\n",
        "            if use_gpu:\n",
        "                input = input.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "            if input.size()[1] == 1:\n",
        "                input = input.repeat(1, 3, 1, 1)\n",
        "\n",
        "            output = net(input)\n",
        "\n",
        "\n",
        "            if use_gpu:\n",
        "                input = input.cpu()\n",
        "                output = output.cpu()\n",
        "                target = target.cpu()\n",
        "\n",
        "\n",
        "            bicubic = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize([int(r * input.size()[2]),\n",
        "                                   int(r * input.size()[3])],\n",
        "                                  PIL.Image.BICUBIC),\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "            bicubic_upscaled = bicubic(input[0])\n",
        "\n",
        "            nearest_neighbour = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.Resize([int(r * input.size()[2]),\n",
        "                                   int(r * input.size()[3])],\n",
        "                                  PIL.Image.NEAREST),\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "\n",
        "            input = nearest_neighbour(input[0])\n",
        "            # output = torch.clamp(output.detach(), 0, 1)\n",
        "\n",
        "            if target.size()[1] == 1:\n",
        "                target = target.repeat(1, 3, 1, 1)\n",
        "\n",
        "            mse_loss = nn.MSELoss()(output, target).item()\n",
        "            psnr.append(mse_to_psnr(mse_loss))\n",
        "\n",
        "            images = [input, target[0], output.detach()[0], bicubic_upscaled]\n",
        "\n",
        "        print(f\"{path} - avarage psnr: {np.mean(psnr)}\")\n",
        "        all_psnr += psnr\n",
        "\n",
        "    avarage_psnr = np.mean(all_psnr)\n",
        "    print(f\"Average: {avarage_psnr}\")\n",
        "    return avarage_psnr\n",
        "    # plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "Eiknsr52BLH8",
        "colab_type": "code",
        "outputId": "85bb772c-bacb-4bb8-9f11-6655bf9f63d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "evaluate(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2d9f7dcb2817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35BnbNXBd6w9",
        "colab_type": "code",
        "outputId": "cedd9898-fc7c-4462-dcb0-029144cc506c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "evaluate(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r: 3\n",
            "test_data/BSD500 - avarage psnr: 26.494012059518397, psnr of average mse: 25.2864189330735\n",
            "test_data/Set5 - avarage psnr: 29.21752743513349, psnr of average mse: 27.90425606306598\n",
            "test_data/BSD300 - avarage psnr: 26.609591910011968, psnr of average mse: 25.31428614449313\n",
            "test_data/Set14 - avarage psnr: 26.28821186034873, psnr of average mse: 25.303261110726737\n",
            "test_data/SuperTexture - avarage psnr: 24.472527774841037, psnr of average mse: 22.293787861574557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TefdFawqBLIF",
        "colab_type": "code",
        "outputId": "5c871863-62a7-482b-969f-9db0adb56f5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "evaluate_by_name('SuperResulutionNet_r-3_psnr-2711__mse-19-unknown')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "r: 3\n",
            "test_data/BSD500 - avarage psnr: 26.88596828888392\n",
            "test_data/Set5 - avarage psnr: 30.211699116205416\n",
            "test_data/BSD300 - avarage psnr: 26.993744734640842\n",
            "test_data/Set14 - avarage psnr: 26.906319210110365\n",
            "test_data/SuperTexture - avarage psnr: 24.833150222299732\n",
            "Average: 26.645196816324138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LYkaXfBBLIK",
        "colab_type": "text"
      },
      "source": [
        "### Finding Hyperparameters\n",
        "We use the AX framework to find the best hyperparameters for the network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMeNmrySIuC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install ax-platform "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi2z0_YJBLIK",
        "colab_type": "code",
        "outputId": "cf22d45f-9462-4d3c-e73b-6a53329554df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from ax import optimize\n",
        "\n",
        "def train_evaluate(parameters):\n",
        "    use_gpu = torch.cuda.is_available()\n",
        "    bs = 32\n",
        "    r = 3\n",
        "\n",
        "    training_set = SuperResolutionDataset('train_data/Set91', r, use_gpu=use_gpu)\n",
        "    # training_set = SuperResolutionDataset('test_data/BSD500', r, use_gpu=use_gpu)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        training_set, batch_size=bs, shuffle=True, num_workers=0\n",
        "    )\n",
        "\n",
        "    # Initialize the network.\n",
        "    net = SuperResolutionNet(r, activation=nn.ReLU())\n",
        "\n",
        "    return train(net, use_gpu, train_loader, r,\n",
        "                 learning_rate_factor=parameters['learning_rate_factor'],\n",
        "                 learning_rate_abs=parameters['learning_rate_abs'],\n",
        "                 print_output=False)\n",
        "\n",
        "\n",
        "best_parameters, best_values, experiment, model = optimize(\n",
        "        parameters=[\n",
        "            # {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-6, 0.4], \"log_scale\": True},\n",
        "            # {\"name\": \"beta1\", \"type\": \"range\", \"bounds\": [0.5, 0.9]},\n",
        "            # {\"name\": \"beta2\", \"type\": \"range\", \"bounds\": [0.9, 0.999]},\n",
        "            {\"name\": \"learning_rate_factor\", \"type\": \"range\", \"bounds\": [0.5, 1.]},\n",
        "            {\"name\": \"learning_rate_abs\", \"type\": \"range\", \"bounds\": [0., 0.0001]}\n",
        "        ],\n",
        "\n",
        "        # Booth function\n",
        "        evaluation_function=train_evaluate,\n",
        "        objective_name='training-error',\n",
        "        minimize=True,\n",
        "    )\n",
        "\n",
        "print(best_parameters, best_values, experiment, model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO 04-19 09:49:55] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+GPEI', steps=[Sobol for 5 arms, GPEI for subsequent arms], generated 0 arm(s) so far). Iterations after 5 will take longer to generate due to model-fitting.\n",
            "[INFO 04-19 09:49:55] ax.service.managed_loop: Started full optimization with 20 steps.\n",
            "[INFO 04-19 09:49:55] ax.service.managed_loop: Running optimization trial 1...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 10:04:05] ax.service.managed_loop: Running optimization trial 2...\n",
            "[INFO 04-19 10:10:51] ax.service.managed_loop: Running optimization trial 3...\n",
            "[INFO 04-19 10:29:32] ax.service.managed_loop: Running optimization trial 4...\n",
            "[INFO 04-19 10:39:40] ax.service.managed_loop: Running optimization trial 5...\n",
            "[INFO 04-19 10:44:05] ax.service.managed_loop: Running optimization trial 6...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 10:53:59] ax.service.managed_loop: Running optimization trial 7...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 10:56:45] ax.service.managed_loop: Running optimization trial 8...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 11:07:14] ax.service.managed_loop: Running optimization trial 9...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 11:14:03] ax.service.managed_loop: Running optimization trial 10...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 11:23:09] ax.service.managed_loop: Running optimization trial 11...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 11:29:38] ax.service.managed_loop: Running optimization trial 12...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 11:37:46] ax.service.managed_loop: Running optimization trial 13...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 11:45:13] ax.service.managed_loop: Running optimization trial 14...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 11:51:38] ax.service.managed_loop: Running optimization trial 15...\n",
            "[INFO 04-19 12:10:35] ax.service.managed_loop: Running optimization trial 16...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 12:21:32] ax.service.managed_loop: Running optimization trial 17...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 12:30:05] ax.service.managed_loop: Running optimization trial 18...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 12:39:36] ax.service.managed_loop: Running optimization trial 19...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n",
            "[INFO 04-19 12:54:43] ax.service.managed_loop: Running optimization trial 20...\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'learning_rate_factor': 0.8625203989490371, 'learning_rate_abs': 7.313388371934669e-05} ({'training-error': 0.001945242824845678}, {'training-error': {'training-error': 4.218599979086151e-13}}) SimpleExperiment(None) <ax.modelbridge.torch.TorchModelBridge object at 0x7f54b00fc7b8>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH4xNZimBLIQ",
        "colab_type": "code",
        "outputId": "35a3826a-572e-4671-a010-ecb96f6d982f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
        "from ax.plot.contour import plot_contour\n",
        "\n",
        "\n",
        "render(plot_contour(model=model, param_x='learning_rate_factor', param_y='learning_rate_abs', metric_name='training-error'))\n",
        "# render(plot_contour(model=model, param_x='lr', param_y='beta1', metric_name='training-error'))\n",
        "# render(plot_contour(model=model, param_x='beta1', param_y='beta2', metric_name='training-error'))\n",
        "# render(plot_contour(model=model, param_x='lr', param_y='beta2', metric_name='training-error'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"ecf6d648-1a97-4818-8388-df8819b0348b\" class=\"plotly-graph-div\" style=\"height:450px; width:950px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"ecf6d648-1a97-4818-8388-df8819b0348b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'ecf6d648-1a97-4818-8388-df8819b0348b',\n",
              "                        [{\"autocolorscale\": false, \"autocontour\": true, \"colorbar\": {\"tickfont\": {\"size\": 8}, \"ticksuffix\": \"\", \"x\": 0.45, \"y\": 0.5}, \"colorscale\": [[0.0, \"rgb(247,252,253)\"], [0.125, \"rgb(229,245,249)\"], [0.25, \"rgb(204,236,230)\"], [0.375, \"rgb(153,216,201)\"], [0.5, \"rgb(102,194,164)\"], [0.625, \"rgb(65,174,118)\"], [0.75, \"rgb(35,139,69)\"], [0.875, \"rgb(0,109,44)\"], [1.0, \"rgb(0,68,27)\"]], \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"x+y+z\", \"ncontours\": 25, \"type\": \"contour\", \"x\": [0.5, 0.5102040816326531, 0.5204081632653061, 0.5306122448979592, 0.5408163265306123, 0.5510204081632653, 0.5612244897959183, 0.5714285714285714, 0.5816326530612245, 0.5918367346938775, 0.6020408163265306, 0.6122448979591837, 0.6224489795918368, 0.6326530612244898, 0.6428571428571428, 0.6530612244897959, 0.6632653061224489, 0.673469387755102, 0.6836734693877551, 0.6938775510204082, 0.7040816326530612, 0.7142857142857143, 0.7244897959183674, 0.7346938775510203, 0.7448979591836735, 0.7551020408163265, 0.7653061224489796, 0.7755102040816326, 0.7857142857142857, 0.7959183673469388, 0.8061224489795917, 0.8163265306122449, 0.8265306122448979, 0.8367346938775511, 0.846938775510204, 0.8571428571428571, 0.8673469387755102, 0.8775510204081632, 0.8877551020408163, 0.8979591836734693, 0.9081632653061225, 0.9183673469387754, 0.9285714285714286, 0.9387755102040816, 0.9489795918367346, 0.9591836734693877, 0.9693877551020408, 0.9795918367346939, 0.9897959183673469, 1.0], \"xaxis\": \"x\", \"y\": [0.0, 2.0408163265306125e-06, 4.081632653061225e-06, 6.122448979591837e-06, 8.16326530612245e-06, 1.0204081632653063e-05, 1.2244897959183674e-05, 1.4285714285714287e-05, 1.63265306122449e-05, 1.836734693877551e-05, 2.0408163265306126e-05, 2.2448979591836737e-05, 2.448979591836735e-05, 2.6530612244897963e-05, 2.8571428571428574e-05, 3.061224489795919e-05, 3.26530612244898e-05, 3.469387755102041e-05, 3.673469387755102e-05, 3.877551020408164e-05, 4.081632653061225e-05, 4.285714285714286e-05, 4.4897959183673474e-05, 4.6938775510204086e-05, 4.89795918367347e-05, 5.1020408163265315e-05, 5.3061224489795926e-05, 5.510204081632654e-05, 5.714285714285715e-05, 5.918367346938776e-05, 6.122448979591838e-05, 6.326530612244899e-05, 6.53061224489796e-05, 6.734693877551021e-05, 6.938775510204082e-05, 7.142857142857143e-05, 7.346938775510205e-05, 7.551020408163266e-05, 7.755102040816328e-05, 7.959183673469389e-05, 8.16326530612245e-05, 8.367346938775511e-05, 8.571428571428573e-05, 8.775510204081634e-05, 8.979591836734695e-05, 9.183673469387756e-05, 9.387755102040817e-05, 9.591836734693878e-05, 9.79591836734694e-05, 0.0001], \"yaxis\": \"y\", \"z\": [[0.003795281825400234, 0.0037854280216983813, 0.0037738621581060506, 0.0037603162495481743, 0.003744498378502322, 0.003726094307372199, 0.003704770184243862, 0.0036801765460074518, 0.003651953828992058, 0.003619739594738583, 0.003583177664129862, 0.0035419293230770227, 0.003495686713102357, 0.00344418844584443, 0.0033872373768803737, 0.0033247203364255356, 0.0032566294377568026, 0.0031830843644124317, 0.003104354770845093, 0.0030208816156238358, 0.002933295879937848, 0.0028424327069875724, 0.002749338532642383, 0.0026552682740425635, 0.002561669127149924, 0.0024701470648882044, 0.0023824118909961224, 0.002300197074588053, 0.0022251523778792047, 0.002158711951004618, 0.0021019498461027014, 0.0020554484145624548, 0.002019215584940917, 0.001992681194251402, 0.0019747766688019636, 0.0019640747837005607, 0.0019589575061137524, 0.0019577892747289346, 0.001959087260890495, 0.001961690900566195, 0.0019649289242221687, 0.001968677299700631, 0.0019732472243719286, 0.0019792528543281754, 0.0019875015089643325, 0.0019989069638729597, 0.0020144252846660392, 0.002035006114664526, 0.002061534743465559, 0.0020947093181785904], [0.003804116516348148, 0.0037960386907266146, 0.0037863834019147974, 0.003774872990532619, 0.0037612013477194943, 0.0037450349443028472, 0.0037260149800544978, 0.003703760886732489, 0.0036778754314805715, 0.0036479516716533297, 0.003613582004688032, 0.003574369533000895, 0.0035299419191413117, 0.00347996783514223, 0.003424176006367311, 0.003362376708327744, 0.0032944853893948425, 0.0032205478582455547, 0.003140766188478912, 0.0030555241515960144, 0.002965410592044181, 0.0028712387036072522, 0.002774058654544448, 0.0026751604391414734, 0.0025760632080985813, 0.002478486665421298, 0.002384299479238238, 0.002295439250714808, 0.0022137990568972658, 0.002141078666773379, 0.002078608104840327, 0.002027172127504572, 0.001986890589647766, 0.0019572100346434453, 0.0019370131835476638, 0.0019247996131262417, 0.0019188847431140322, 0.0019175895778785314, 0.0019194162554442631, 0.0019232139682968975, 0.001928321869464118, 0.0019346063832925953, 0.0019423593223295114, 0.0019521546851728065, 0.0019647172247443923, 0.0019808119328201955, 0.002001160692363874, 0.0020263912786934674, 0.0020570099405841317, 0.002093351538126718], [0.003813420054684765, 0.003807402443585941, 0.0037999881669436106, 0.0037908939026772637, 0.0037798032441586165, 0.0037663670314041094, 0.0037502048088241405, 0.0037309076726216774, 0.0037080427914416353, 0.0036811598965952887, 0.0036498000391767247, 0.003613506895816664, 0.0035718408669600057, 0.0035243961449054353, 0.0034708208263615117, 0.0034108399987546685, 0.0033442815341622563, 0.003271104073773741, 0.0031914263751386543, 0.003105556822259869, 0.003014021465209656, 0.0029175884634102148, 0.00281728625721366, 0.002714412185911881, 0.0026105276018579117, 0.0025074347888930258, 0.002407130167401529, 0.0023117273790933235, 0.0022233430830023875, 0.0021439385968779878, 0.0020751158459991286, 0.0020178891986991003, 0.001972509825285195, 0.0019384505273274382, 0.0019145634390987192, 0.0018993126905952123, 0.0018910017932119447, 0.0018879728815301149, 0.0018887803573938737, 0.0018923408905331856, 0.0018980398302921198, 0.0019057490937288953, 0.0019157440668499805, 0.0019285654946009875, 0.0019448700781839541, 0.0019652891200173644, 0.0019903087215731525, 0.002020190829033288, 0.0020549577305447836, 0.0020944454380939477], [0.003822821866904652, 0.003819132395570345, 0.003814275411814602, 0.00380796662725518, 0.00379988400683763, 0.00378966728858542, 0.003776918613370948, 0.003761204556139215, 0.0037420598790977987, 0.0037189933496634877, 0.003691495977135295, 0.0036590520167022996, 0.003621153060838431, 0.003577315478581565, 0.0035271013639308997, 0.0034701430064803555, 0.003406170691607269, 0.0033350433665298436, 0.0032567813672668483, 0.0031715999884442602, 0.00307994219565881, 0.002982508235365471, 0.0028802792990249284, 0.0027745317546130563, 0.0026668377716340804, 0.002559047425286995, 0.0024532465427704454, 0.0023516835996421318, 0.002256657824261525, 0.0021703593322655924, 0.0020946514325589287, 0.0020307949620874165, 0.0019791919529808847, 0.00193935957569626, 0.0019101613107176739, 0.0018900888833003485, 0.0018775023048888217, 0.001870826960868924, 0.0018687166720996054, 0.00187018249623166, 0.0018746720135550433, 0.0018820767506228498, 0.001892662642643548, 0.001906944413247747, 0.0019255306369837257, 0.0019489580594641014, 0.001977531804235249, 0.002011200961320873, 0.002049527471323679, 0.0020918329863870207], [0.0038318697609518197, 0.0038307488052956957, 0.0038287387515054112, 0.0038255596382891143, 0.0038208891626968196, 0.003814361278301404, 0.0038055658611129244, 0.003794049760970034, 0.0037793195946661897, 0.003760846670255208, 0.0037380744552995065, 0.0037104290092755585, 0.0036773327843014373, 0.0036382221494942477, 0.0035925689017925573, 0.003539905878186834, 0.0034798565691027336, 0.0034121683396008476, 0.003336748486616343, 0.0032537018942748264, 0.003163368499782544, 0.0030663581614123895, 0.0029635798459972133, 0.0028562613470480367, 0.0027459550229583973, 0.002634524311080784, 0.002524105007195614, 0.0024170344474351052, 0.0023157406993273696, 0.002222582531176799, 0.002139629124915642, 0.0020683663529877244, 0.0020093651094660763, 0.0019622405435278543, 0.0019259550824468697, 0.0018991163147032335, 0.0018802129135414957, 0.0018678035854415673, 0.001860667614086802, 0.0018579165203642337, 0.0018590577523194245, 0.0018639993509757774, 0.001872993065750752, 0.0018865253656940473, 0.0019051707634617564, 0.0019294202753799856, 0.0019594991838079653, 0.0019952033491071985, 0.0020358233639472, 0.0020802949849871902], [0.0038400300529741875, 0.003841678386257273, 0.003842764735499603, 0.0038430192311385515, 0.0038421252273953127, 0.0038397168742922297, 0.003835377686822002, 0.0038286404520740886, 0.0038189888636897882, 0.0038058613183151123, 0.0037886573461514503, 0.003766747170880304, 0.0037394848946381443, 0.0037062257704524406, 0.003666347944364219, 0.003619278907140053, 0.0035645266748302283, 0.0035017154030571266, 0.0034306247197585056, 0.0033512315296736327, 0.0032637524055719124, 0.0031686839529281945, 0.0030668377459303993, 0.002959365621866159, 0.0028477703269621435, 0.0027338957553475116, 0.002619890310003197, 0.0025081361912859305, 0.0024011365820106275, 0.002301351598602842, 0.0022109724295781294, 0.00213162453963292, 0.002064059000672161, 0.00200811033021161, 0.001962960983348389, 0.0019274285364788458, 0.0019001958145667052, 0.0018799925407809927, 0.0018657362508805316, 0.0018566334693680317, 0.0018522369054336132, 0.0018524534771501423, 0.0018575019911962443, 0.0018678250462017681, 0.0018839629957522514, 0.0019063982441333675, 0.0019353799975410663, 0.001970750646101642, 0.0020118296630449277, 0.0020574929077439965], [0.003846690851285783, 0.0038512571701061833, 0.0038556351111262164, 0.003859570970664063, 0.0038627600828483825, 0.003864843268935339, 0.0038654041829475827, 0.003863967912850535, 0.003860001255278295, 0.0038529151400073774, 0.0038420697335894687, 0.003826782793339551, 0.0038063418641135476, 0.003780020898683011, 0.0037471018221854066, 0.0037069014328472063, 0.0036588038131323045, 0.0036022980952338805, 0.0035370209626870014, 0.0034628026635903815, 0.0033797145614938694, 0.0032881153772433506, 0.0031886923207992976, 0.0030824923381056624, 0.0029709377765372983, 0.0028558199672131415, 0.002739263566272369, 0.002623653977343589, 0.0025115197745248247, 0.0024053620347424614, 0.0023074252530169226, 0.002219423580787805, 0.002142306613932555, 0.0020762182723909396, 0.0020206678323463345, 0.0019747702118363317, 0.0019374624277017677, 0.0019076784259681452, 0.0018844842722229157, 0.0018671752597828545, 0.0018553337073199704, 0.0018488454746996214, 0.00184787506992142, 0.0018528022239276925, 0.0018641251690320096, 0.0018823371616072068, 0.001907784445033134, 0.0019405185772342212, 0.0019801703840743564, 0.0020259217271352214], [0.0038511689177551838, 0.0038587374313465103, 0.003866533687032791, 0.0038743263368551844, 0.0038818292118814055, 0.0038886965632400333, 0.0038945190675970113, 0.003898820968668097, 0.003901058794918303, 0.0039006221647130083, 0.003896837260120688, 0.003888973613299672, 0.003876254895761508, 0.003857874417550947, 0.003833016012370412, 0.0038008808823889162, 0.003760720774372799, 0.0037118775250464444, 0.0036538285169621047, 0.003586236902321054, 0.003509004572822065, 0.003422324796920312, 0.0033267302658369913, 0.00322313107958634, 0.003112836089942032, 0.002997550138450899, 0.002879339219225412, 0.002760555611103856, 0.002643715924276932, 0.0025313280845930377, 0.0024256726817608308, 0.0023285685090542914, 0.0022411917955137174, 0.0021640288877216884, 0.0020969733484282587, 0.002039500707971633, 0.0019908526574103575, 0.0019501987946892083, 0.0019167671866697428, 0.001889942054416463, 0.0018693277362826781, 0.0018547782539358787, 0.0018463929385988242, 0.0018444804555439837, 0.001849495474429609, 0.001861953788227044, 0.0018823327949195993, 0.0019109636446293357, 0.0019479120209434067, 0.0019928104038573298], [0.003852720430355704, 0.0038632990769944097, 0.003874558295680607, 0.0038862951797822187, 0.0038982485343609513, 0.003910092837328374, 0.0039214328031244305, 0.003931798925825418, 0.003940644455630664, 0.003947344345720487, 0.003951196792878886, 0.003951428080093039, 0.0039472015042052114, 0.0039376312233966445, 0.00392180186827829, 0.0038987946993971575, 0.003867720927419359, 0.003827762497010874, 0.00377822012449016, 0.0037185676294580207, 0.0036485105852544853, 0.0035680460402448154, 0.003477518594444911, 0.003377666588276775, 0.0032696507833183492, 0.0031550569656990397, 0.0030358637112799843, 0.00291436753881012, 0.0027930605508964326, 0.0026744618608884633, 0.0025609160430035732, 0.0024543906575367333, 0.0023563225954601565, 0.002267558480903092, 0.002188397843674658, 0.002118707587930223, 0.0020580648859776854, 0.0020058981079020604, 0.0019616105979582263, 0.0019246808561096803, 0.0018947362949725834, 0.0018715993363138932, 0.001855305929809503, 0.0018460980348196888, 0.0018443929267454005, 0.0018507327454780776, 0.0018657161271518207, 0.0018899063497625705, 0.0019236881151491908, 0.0019669947467296127], [0.003850555840294434, 0.0038640657587499898, 0.0038787381912468817, 0.003894404416214606, 0.00391083439254524, 0.003927729385845228, 0.003944715008649133, 0.003961335049484244, 0.003977046549080828, 0.00399121667476559, 0.004003122045065984, 0.004011951262698866, 0.004016811518948671, 0.004016740224251092, 0.0040107226793512744, 0.003997716799406213, 0.003976685798248667, 0.0039466394768601105, 0.0039066842728325965, 0.0038560814465161113, 0.003794311647424716, 0.0037211426036120165, 0.0036366948662231962, 0.003541498597899846, 0.0034365326409376232, 0.003323236010998812, 0.0032034821209994003, 0.0030795081025179116, 0.0029537962626055205, 0.002828912680552575, 0.0027073193438998232, 0.002591188892759503, 0.0024822584356973894, 0.002381752441018404, 0.0022903836587905117, 0.002208417886422271, 0.0021357769649762194, 0.002072156127430522, 0.002017139143241137, 0.0019703013391587643, 0.0019312948089058308, 0.0018999126300818356, 0.001876130580919167, 0.001860126031047744, 0.0018522740914555097, 0.0018531198206699492, 0.0018633203723260692, 0.0018835391001523665, 0.0019142527851761769, 0.001955432204616416], [0.0038438588533520213, 0.003860125779093901, 0.0038780570090585385, 0.003897523164615644, 0.003918330971955596, 0.0039402145161917005, 0.003962826700285301, 0.003985731275272747, 0.004008395895221573, 0.004030186749317172, 0.004050365435318906, 0.004068088862832451, 0.004082413108102103, 0.004092302275983236, 0.004096643543016479, 0.004094269629850635, 0.00408398993728453, 0.004064631413567618, 0.004035089815514211, 0.003994391279752995, 0.003941762929688073, 0.003876709539233228, 0.0037990910791674305, 0.0037091934789894067, 0.003607782583501416, 0.003496129775766907, 0.0033759979746995476, 0.0032495795748387563, 0.003119383917840955, 0.0029880808871576526, 0.0028583178318700793, 0.0027325362481253773, 0.0026128181270885357, 0.0025007862096669223, 0.002397568708751166, 0.0023038237094453757, 0.00221980826164292, 0.0021454743237805628, 0.0020805758481319556, 0.0020247750798617695, 0.0019777396111765, 0.0019392243354940724, 0.0019091342004923907, 0.0018875645101827218, 0.001874815074886476, 0.0018713719396185686, 0.0018778447745770636, 0.0018948399899217346, 0.0019227490692657009, 0.001961473661312189], [0.0038318093701827944, 0.0038505576382187106, 0.003871481155351777, 0.003894494222374238, 0.00391944511405487, 0.003946105940376805, 0.003974162491336489, 0.004003204419484173, 0.004032716201727427, 0.0040620694226890216, 0.004090517039051558, 0.00411719042051022, 0.004141100119183824, 0.004161141492577194, 0.0041761064849305096, 0.004184703035164288, 0.004185583685056933, 0.004177384941004386, 0.004158778695609626, 0.004128536404130632, 0.004085605571224162, 0.004029196278699348, 0.003958872901582606, 0.003874642953045561, 0.00377703166716362, 0.0036671284361401504, 0.003546590904484955, 0.003417595688879973, 0.003282731910227243, 0.0031448441607033403, 0.0030068427374824827, 0.0028715074440266754, 0.0027413137035712486, 0.002618304767951799, 0.0025040231141923316, 0.0023995018344980922, 0.002305307148024992, 0.002221618106615759, 0.0021483286379445953, 0.002085158573679942, 0.0020317626748118387, 0.001987828923385313, 0.0019531589900504353, 0.0019277244685729634, 0.0019116918669224911, 0.0019054073023368097, 0.0019093291665384865, 0.0019238975842012737, 0.001949343439688752, 0.001985480041590217], [0.003813609999436198, 0.003834459810780755, 0.003857993195903675, 0.0038841714414471653, 0.003912888077610291, 0.003943957337672226, 0.003977102377561886, 0.004011943597690285, 0.004047987494115003, 0.004084616563854617, 0.004121080904738603, 0.004156492289665823, 0.004189821664662768, 0.004219901223628083, 0.004245432448379025, 0.004265001757804437, 0.004277105652994896, 0.004280187414925361, 0.004272687402805343, 0.004253108651432913, 0.004220098545218281, 0.0041725455754430775, 0.00410968730938139, 0.004031221651913086, 0.003937408673061437, 0.003829145894910753, 0.003707997990095087, 0.00357616459645619, 0.003436378590452255, 0.003291740451695329, 0.0031455084447965507, 0.0030008743749994427, 0.0028607572079781983, 0.002727641497957017, 0.002603476866810216, 0.00248964263010633, 0.0023869715104472868, 0.002295819984072619, 0.002216170189166412, 0.0021477484439908607, 0.0020901469942958884, 0.0020429375751567984, 0.002005767021336262, 0.001978426089827555, 0.0019608827933922713, 0.001953271387566081, 0.001955829394998511, 0.0019687813052867266, 0.001992183638920184, 0.0020257718282859936], [0.003788515519166002, 0.003810984059382557, 0.003836629478400244, 0.0038654621647304117, 0.0038974233429794015, 0.003932372126189607, 0.0039700721120222975, 0.004010177859172845, 0.004052221660933014, 0.004095601123181348, 0.004139568160743988, 0.004183220158403513, 0.004225494212365172, 0.004265165586555394, 0.004300851794692431, 0.0043310240546943456, 0.0043540282419515615, 0.004368117849417545, 0.004371501755179262, 0.004362409636865579, 0.00433917738216616, 0.00430035341530657, 0.00424482396891848, 0.004171950510352475, 0.004081705783946794, 0.003974787420782098, 0.0038526827067603044, 0.0037176590802334595, 0.003572665369937726, 0.0034211474710130986, 0.003266802616152936, 0.00311331036457953, 0.0029640810902154605, 0.002822054987606324, 0.002689571082405721, 0.002568311527137422, 0.002459315031505648, 0.002363046001763858, 0.002279502663319294, 0.0022083471024781274, 0.002149041556679548, 0.0021009773364087246, 0.0020635847370231116, 0.0020364138583872132, 0.0020191775365406076, 0.002011749369250282, 0.0020141136105869865, 0.0020262715239775177, 0.002048121549594455, 0.002079344984252068], [0.003755864418369865, 0.0037793712999582667, 0.003806520872834318, 0.003837373463419946, 0.0038719190456852452, 0.0039100628724905275, 0.003951610448841525, 0.0039962521906891256, 0.004043548189134883, 0.004092913579925471, 0.004143605109154447, 0.004194709600343136, 0.004245135182337897, 0.00429360635159509, 0.004338664236580601, 0.004378673822420966, 0.004411840386442827, 0.00443623797440164, 0.004449853356907954, 0.004450649414081916, 0.004436652037564924, 0.004406063926131054, 0.004357406291173913, 0.0042896844073290665, 0.004202564199559761, 0.004096535030816999, 0.00397302213518319, 0.0038344083521787255, 0.0036839369856460765, 0.003525496005201021, 0.003363316584390918, 0.003201639892364188, 0.0030444073931238454, 0.0028950159957259296, 0.002756159742427948, 0.002629761757194488, 0.0025169872228363063, 0.002418320626585405, 0.002333687481593473, 0.002262600842757181, 0.0022043148509320667, 0.0021579701609675526, 0.0021227187121021724, 0.0020978176194136984, 0.002082684241043106, 0.002076907431972169, 0.002080214655933545, 0.0020924017562178017, 0.002113241201299489, 0.002142392462940947], [0.0037151114173612255, 0.0037389887525732723, 0.003766935171130045, 0.0037990604946509035, 0.003835403106469573, 0.0038759141266403443, 0.003920440743074867, 0.003968709070115574, 0.004020306980501922, 0.00407466742562399, 0.004131052829147866, 0.004188541225024694, 0.004246014934497142, 0.00430215276576033, 0.00435542700513517, 0.00440410687994431, 0.004446270735503111, 0.004479829894611261, 0.004502568045360822, 0.004512200965122617, 0.004506462250088667, 0.0044832210496364025, 0.0044406367034413655, 0.004377350993778653, 0.004292709017225355, 0.004186982443468796, 0.004061546558427559, 0.003918947255800176, 0.0037628057086867596, 0.0035975540964961654, 0.00342805238099297, 0.003259168135112733, 0.003095396473593855, 0.002940570204054063, 0.002797680842397431, 0.002668808811063033, 0.0025551474040916974, 0.002457098336672481, 0.002374414892038246, 0.0023063700716347635, 0.0022519302547126144, 0.002209918505778104, 0.002179155081256874, 0.002158565640540526, 0.0021472504328972587, 0.0021445109578165644, 0.002149834985507429, 0.002162846610328193, 0.0021832343569022613, 0.0022106751244757613], [0.0036658596607778596, 0.003689366863119382, 0.003717319382571023, 0.003749874919007806, 0.0037871186455308804, 0.003829045858709918, 0.0038755436098487613, 0.0039263717437719005, 0.003981143850882344, 0.004039308698169936, 0.004100132750747915, 0.0041626844437401235, 0.004225820942595463, 0.00428817827470597, 0.004348165967655704, 0.004403967730544329, 0.004453550302007927, 0.0044946833934083755, 0.004524974700627177, 0.00454192524390353, 0.004543011761761356, 0.004525804300725286, 0.004488127833657008, 0.004428274998776246, 0.004345269141355889, 0.004239156514706076, 0.004111269422295548, 0.003964361734326833, 0.003802518937524922, 0.003630821213955693, 0.0034548433205632495, 0.0032801225811312468, 0.00311170075063953, 0.0029537942416732236, 0.002809605907643116, 0.002681266829750105, 0.0025698838969684754, 0.0024756640632273303, 0.002398086349930403, 0.002336096034857493, 0.002288300371016928, 0.00225315022662197, 0.0022290963362944062, 0.0022147121406195054, 0.002208777804246728, 0.0022103226686985443, 0.00221862684704448, 0.0022331871530265625, 0.002253657445790889, 0.002279777259939245], [0.003607891117608686, 0.003630234291096036, 0.0036573399292220837, 0.0036894110258981973, 0.0037265768928158535, 0.0037688741773307414, 0.0038162266824958773, 0.003868424504689094, 0.00392510309883016, 0.003985722937510325, 0.004049550449820085, 0.004115640926255812, 0.004182824093245092, 0.004249693143272035, 0.004314598208457728, 0.004375645637963948, 0.0044307050257925105, 0.0044774267704715525, 0.004513274063748306, 0.004535574636508604, 0.004541599370688848, 0.004528677009164955, 0.00449435645676869, 0.004436629639374119, 0.004354225347595938, 0.004246968561186455, 0.004116151434654541, 0.003964774921916607, 0.0037974747793025187, 0.003620075017512926, 0.0034389246425421045, 0.0032602333307643018, 0.003089538468143231, 0.0029313487183098186, 0.002788961920151876, 0.0026644330871468335, 0.0025586582810878983, 0.0024715373223134123, 0.002402180812258634, 0.0023491329837095937, 0.002310589341223584, 0.0022845949897346823, 0.0022692147635701666, 0.0022626694619406165, 0.0022634341968522653, 0.0022702961296229857, 0.0022823708619940115, 0.002299080125254436, 0.0023200978842712826, 0.0023452762443564572], [0.0035411936218596425, 0.0035615491457721515, 0.0035869186151293257, 0.003617547055975693, 0.0036536046000483916, 0.0036951657270678047, 0.003742187102153388, 0.0037944846515360806, 0.0038517106466973506, 0.003913331629702714, 0.003978608003916743, 0.004046576053348595, 0.004116033087811474, 0.004185526408489614, 0.004253346924590956, 0.00431752859204616, 0.004375855435125473, 0.004425878776651886, 0.004464948457366199, 0.004490263291805223, 0.004498947834434778, 0.004488164804554199, 0.004455275362718603, 0.004398062867456655, 0.004315038945114027, 0.0042058480898987, 0.004071751177702202, 0.003916026618014642, 0.00374393716820454, 0.003562114321419344, 0.003377681943306657, 0.003197460584777353, 0.00302737859368083, 0.0028721065025987965, 0.0027348957428385613, 0.002617586328802396, 0.002520738910865098, 0.0024438446559808054, 0.00238557160348991, 0.0023440160552964224, 0.002316938739514231, 0.0023019749602195385, 0.002296814058416192, 0.0022993460233431476, 0.002307772918853876, 0.002320681619782813, 0.002337074177116519, 0.0023563544759870056, 0.002378274897343262, 0.002402852888773216], [0.0034659829508599488, 0.0034835246268543224, 0.0035062622316208714, 0.0035344792138407416, 0.003568382974430625, 0.0036080821711672794, 0.0036535623482666004, 0.003704660703775157, 0.0037610409942559772, 0.003822169662800617, 0.0038872942389234907, 0.003955424914186406, 0.004025320010803789, 0.0040954759347165935, 0.00416412225212638, 0.004229222839958578, 0.004288484685261008, 0.004339376853200748, 0.0043791633894075, 0.004404955449774731, 0.004413789763511594, 0.00440274268869628, 0.004369091755721246, 0.004310539989630178, 0.0042255229062625795, 0.004113624188775207, 0.003976126754746711, 0.0038166102900888646, 0.0036410051369271603, 0.003456724740069488, 0.0032715678246788217, 0.0030928300573955605, 0.002926679691469592, 0.0027777916347776297, 0.002649216026154244, 0.0025424376403480314, 0.0024575683050744148, 0.002393612256630962, 0.002348753911981291, 0.0023206338353305997, 0.002306595458669218, 0.002303897855401601, 0.002309896650239264, 0.002322196144533806, 0.0023387724557102567, 0.0023580624188663424, 0.002379009444104103, 0.0024010585775855273, 0.002424099790823533, 0.0024483686946229774], [0.003382718361109695, 0.00339664728033711, 0.0034158837640081347, 0.0034407460328579912, 0.003471475403622198, 0.0035082115081622703, 0.0035509654577138856, 0.0035995919760636796, 0.0036537618158514664, 0.00371293591535679, 0.003776342690069844, 0.0038429595898550615, 0.003911499680752383, 0.003980403692441823, 0.004047837887252815, 0.004111698389245383, 0.0041696233169874536, 0.004219015169526636, 0.004257077355878668, 0.004280870461608641, 0.004287395760118301, 0.004273715589377773, 0.004237122580928796, 0.004175372521141071, 0.004086999245723004, 0.003971735213715035, 0.003831069663457456, 0.00366893865721706, 0.003491849411157254, 0.0033078021983406983, 0.003125069370638615, 0.0029512392855676945, 0.0027925479147371066, 0.0026535065109046544, 0.0025368060365401875, 0.0024434432804065925, 0.00237298919851455, 0.002323918377591304, 0.0022939369780286276, 0.0022802736789994805, 0.0022799228666362725, 0.0022898455501838854, 0.002307140104454556, 0.0023291932812588147, 0.0023538142097811105, 0.0023793433350973, 0.002404719172857236, 0.002429484446865085, 0.002453723207927919, 0.0024779382842039627], [0.003292110070080823, 0.003301686192531526, 0.003316613351129275, 0.0033372410499210563, 0.003363841687885502, 0.0033965836110057997, 0.003435501560964468, 0.0034804657863113657, 0.003531151547663152, 0.003587011011003863, 0.003647249452324311, 0.003710807263521587, 0.0037763485831134695, 0.0038422567431022374, 0.003906636425914179, 0.003967322672386068, 0.004021897727841142, 0.004067718081701491, 0.004101955811926149, 0.004121660360717047, 0.004123849048244345, 0.004105636912513875, 0.004064418803524958, 0.003998119055412591, 0.003905526592531812, 0.0037867358214543198, 0.0036437074637180496, 0.003480836181114457, 0.0033049372831465483, 0.0031242907764282165, 0.0029474039060031457, 0.002781963739158086, 0.002634095718250323, 0.0025079731018307107, 0.0024057678681337997, 0.0023278674741845883, 0.002273240534644117, 0.0022398380342979855, 0.0022249536116671414, 0.002225511329341982, 0.0022382836845962046, 0.0022600607989964254, 0.0022877960593622663, 0.0023187479201292297, 0.002350624709352261, 0.002381721125208463, 0.0024110169249323844, 0.002438201378252225, 0.002463602134771173, 0.002488029514576111], [0.0031951172696416284, 0.003199691580391447, 0.0032095973625656873, 0.003225212093172718, 0.003246837037575713, 0.003274668193137979, 0.003308763842280835, 0.003349010222138921, 0.0033950875718954466, 0.003446439321103051, 0.003502247160706813, 0.0035614140682458076, 0.0036225562138729444, 0.0036840035152890765, 0.003743807968423503, 0.003799759089857531, 0.003849406888810418, 0.0038900945424905943, 0.0039190051302880145, 0.003933229205229165, 0.003929862537860066, 0.0039061459662676234, 0.003859661738309342, 0.0037886025225446307, 0.0036921287094733657, 0.003570819908598255, 0.003427179816084505, 0.003266005377067594, 0.00309425213168967, 0.002920233229267038, 0.0027524612560294254, 0.0025985264716143317, 0.00246425788312286, 0.0023533042003577326, 0.0022671535842702, 0.002205480004305922, 0.002166633631929632, 0.0021481149626407727, 0.002146946637405416, 0.002159927848502055, 0.0021837981026361724, 0.002215351713669796, 0.002251542460219208, 0.0022896074921345353, 0.002327222957341766, 0.0023626787411801476, 0.002395027338435871, 0.002424140381769454, 0.002450626934590054, 0.0024756295355079193], [0.0030929353770627827, 0.0030919813621237318, 0.003096284132422003, 0.003106245772539852, 0.0031221945789487227, 0.0031443541916242475, 0.0031728082394076144, 0.0032074621717366604, 0.003248005156627717, 0.0032938758917060293, 0.003344236355064245, 0.0033979565431473844, 0.0034536113045064536, 0.0035094883166311708, 0.0035636050619264063, 0.003613732870938598, 0.003657427595470256, 0.0036920687735233115, 0.0037149118072513677, 0.003723160454548822, 0.0037140697398459393, 0.003685092077277986, 0.00363408145707317, 0.003559570419161396, 0.0034611279678655148, 0.003339783051923591, 0.0031984389726745655, 0.0030421059305443298, 0.0028777244823916166, 0.0027134744768105, 0.002557698931729277, 0.002417724259275758, 0.0022989046131864184, 0.002204171181558194, 0.002134167849867228, 0.0020877907268893, 0.0020628322770650707, 0.0020565106818826043, 0.0020658102847185555, 0.002087658960429547, 0.0021190054855673088, 0.0021568597843215384, 0.0021983454348208204, 0.0022407987870310757, 0.0022819332383495743, 0.0023200616315921835, 0.0023543204787228426, 0.0023847820526351924, 0.0024123575996336404, 0.002438520727328531], [0.002986971401672986, 0.002980114407962351, 0.0029783949768724255, 0.002982235885378522, 0.002991990362622886, 0.003007910058189321, 0.00303010708646484, 0.0030585117615991708, 0.003092829500976487, 0.003132502204821656, 0.0031766801748213257, 0.0032242093178220677, 0.003273635088309388, 0.003323220956761204, 0.0033709771447022665, 0.003414695775508175, 0.0034519908565001068, 0.003480344542559315, 0.00349716419332428, 0.0034998575796104966, 0.0034859361916133543, 0.0034531587618385822, 0.0033997280309637965, 0.0033245513070927508, 0.0032275649400426093, 0.0031100970592257307, 0.002975196115021163, 0.0028277963782801603, 0.0026745672642065703, 0.002523341126953896, 0.0023821229579771615, 0.0022578419334381523, 0.002155226586845269, 0.002076310183659569, 0.0020207693518035875, 0.0019867526199461817, 0.0019716888343026236, 0.001972812051732437, 0.001987398413799148, 0.002012815770946894, 0.002046490669266921, 0.0020858688814655306, 0.002128417870245106, 0.002171701483516652, 0.002213547161263568, 0.0022523130428242794, 0.0022872111002689606, 0.0023185126794965276, 0.002347426387440771, 0.002375711653414489], [0.0028788066237214354, 0.002865849352355872, 0.0028578791532947625, 0.0028553343602764326, 0.0028585897451278695, 0.002867924419586678, 0.0028834821148849355, 0.00290522493919211, 0.002932884372032012, 0.0029659165725741264, 0.0030034712769657123, 0.0030443821093951652, 0.0030871804445360405, 0.003130128292025903, 0.003171262379914252, 0.0032084428614199537, 0.0032394038242770703, 0.003261806748027005, 0.0032733012456240477, 0.0032715998222087248, 0.003254575164751863, 0.0032203895154857736, 0.003167665210933259, 0.0030957017425021585, 0.003004734859342073, 0.002896214261936841, 0.0027730483971052425, 0.0026397352280487876, 0.002502278742176506, 0.0023677847046338807, 0.0022436313687255616, 0.0021361882757531085, 0.002049430016506623, 0.0019843453011605633, 0.001939627930787958, 0.0019129053536943753, 0.0019016439125288164, 0.0019035411739726682, 0.001916569263479946, 0.001938860860244304, 0.0019685666898134925, 0.002003754469995937, 0.002042382696323406, 0.002082365591671627, 0.002121741863547904, 0.0021589635234521946, 0.002193307932607372, 0.00222522354003577, 0.002256162805980394, 0.002288051892112783], [0.0027701464364952863, 0.0027510883059745517, 0.0027368515804867487, 0.0027278831733758184, 0.002724573504171561, 0.002727225860616662, 0.0027360164880483916, 0.0027509453020344793, 0.002771780360463789, 0.0027980047398237463, 0.0028287799702093057, 0.0028629396857594927, 0.0028990170656275813, 0.002935296973837112, 0.0029698789276136196, 0.0030007409491294773, 0.0030258008109845043, 0.0030429760400422206, 0.0030502467857182317, 0.003045727012827265, 0.003027749967628922, 0.002994973506107904, 0.0029465092064982906, 0.0028820753840003957, 0.002802167330633979, 0.0027082282793595494, 0.002602793546580831, 0.002489570942483008, 0.0023734111110741713, 0.0022600959256060477, 0.0021558015202394745, 0.0020659881188726296, 0.00199372507597635, 0.0019388866279833094, 0.0018994305867307377, 0.0018730281319900388, 0.0018578258679353248, 0.001852536056414225, 0.0018562310338185266, 0.0018680764514678655, 0.0018871159891615057, 0.0019121496689304825, 0.0019417147990702373, 0.001974168099303426, 0.0020078701836455867, 0.002041483738052083, 0.0020744088775112466, 0.0021072190498495095, 0.0021414509624140747, 0.002178992490655342], [0.0026627584750737524, 0.002637805932792905, 0.0026175128986247417, 0.0026023258307726425, 0.0025926414618893433, 0.002588779292163022, 0.0025909437667349486, 0.0025991742198786414, 0.0026132834837309816, 0.0026327936214423572, 0.002656889387230539, 0.00268441456846559, 0.0027139180676565887, 0.002743730903184021, 0.0027720502997566052, 0.0027970182354419503, 0.00281679209620402, 0.002829609846858685, 0.0028338535182214266, 0.0028281147048988043, 0.002811264842164553, 0.002782531336773127, 0.0027415780188694496, 0.0026885848479167337, 0.0026243179023904026, 0.0025501780262689533, 0.002468217716508324, 0.0023811225996593828, 0.002292161493836435, 0.0022050973941721364, 0.0021239753982551903, 0.002052497682232597, 0.0019924830422891992, 0.0019428907573305872, 0.0019017334079452356, 0.001867662805368015, 0.0018402669278608519, 0.0018197839167812544, 0.0018066833351950634, 0.0018013119418269316, 0.0018036676403392704, 0.0018133068851137635, 0.0018293700615353964, 0.0018507075802872892, 0.0018760979511200466, 0.0019045618663294608, 0.0019357660024475285, 0.0019703285998835295, 0.002009632784707702, 0.0020552966482553186], [0.0025584023195134673, 0.002527966686870146, 0.0025020536313807803, 0.0024810985644024494, 0.002465491761694903, 0.0024555552114553544, 0.0024515091748985415, 0.0024534249005916347, 0.0024611608357971034, 0.0024742862362998144, 0.002492017453502369, 0.002513214677689051, 0.002536454234357811, 0.0025601354112273576, 0.002582584143551886, 0.002602142885626604, 0.0026172480432966904, 0.0026264986024308813, 0.0026287190398020348, 0.0026230181660987562, 0.0026088434943778013, 0.002586027997441989, 0.0025548227547171013, 0.0025159054439320722, 0.0024703521536724956, 0.0024195609597016735, 0.0023651234589257037, 0.0023086577806692727, 0.002251641825285263, 0.0021953045504996506, 0.0021406029206882515, 0.0020881351659444063, 0.0020376368279224275, 0.0019879339512221066, 0.001938352890621936, 0.0018895186943216895, 0.0018430812882532371, 0.0018011274067661954, 0.0017656552413020713, 0.00173821796435899, 0.0017197457669111816, 0.0017105223261018392, 0.0017102820806220468, 0.001718398015034543, 0.001734138719027258, 0.0017569761761605468, 0.001786889807907019, 0.0018245110856758527, 0.0018709447601444613, 0.0019273554197436265], [0.002458757102655915, 0.0024234368871889115, 0.0023925487919948425, 0.002366506123016975, 0.002345677749618201, 0.0023303696127998344, 0.0023207967798324998, 0.0023170418284645666, 0.002318994606413912, 0.002326269450131999, 0.00233811752434267, 0.0023534192278572945, 0.002370792743323865, 0.0023887290594100026, 0.0024057079087964955, 0.0024202942166066913, 0.002431219795048487, 0.0024374539012930424, 0.002438264527137977, 0.002433270120114952, 0.0024224787040621073, 0.002406307974291593, 0.0023855759992429085, 0.0023614482299672114, 0.00233532395882444, 0.002308646706613914, 0.0022826321326303357, 0.0022579286893252273, 0.002234263987178787, 0.0022101823100545578, 0.0021830377985737103, 0.0021494710984198257, 0.002106599601418454, 0.002053511378929218, 0.0019917156639952974, 0.0019244337839803842, 0.0018556727273289345, 0.0017894711338896502, 0.0017293682713452852, 0.0016780973188881255, 0.00163748365046835, 0.001608508450742465, 0.0015914896243123754, 0.0015863353018007425, 0.0015928305431090893, 0.0016109126858434733, 0.0016408658701041767, 0.0016833402693836794, 0.0017391468511016495, 0.0018089086170148543], [0.0023653565280684187, 0.002325903151745113, 0.0022908562952807464, 0.002260596491219476, 0.002235455666665529, 0.002215702959135092, 0.0022015219958611107, 0.002192975184382403, 0.0021899497008498266, 0.0021920789061977697, 0.002198642284253223, 0.0022085531600517304, 0.002220497644826969, 0.0022330825625570755, 0.002244956846344063, 0.0022549121405367745, 0.0022619672198718192, 0.0022654389931608134, 0.0022650007789507664, 0.002260726058989825, 0.002253112876804143, 0.0022430803651779354, 0.002231924645934838, 0.002221216997564733, 0.0022126238429335267, 0.0022076280356722053, 0.0022071383391297212, 0.0022109962562366398, 0.002217438159743308, 0.0022226618959837008, 0.0022208001865982687, 0.002204844737076368, 0.002169274477084949, 0.002113267443558559, 0.0020403008706119533, 0.001955942090437998, 0.0018663921362988406, 0.0017775746743838787, 0.001694556940671713, 0.0016212575707693535, 0.001560405020958354, 0.0015136832522855887, 0.0014819937251984334, 0.0014657711526124603, 0.0014652959364793606, 0.0014809405081440189, 0.0015132788750736924, 0.0015630046323810444, 0.0016306675985308023, 0.0017163311866602838], [0.0022795423978847046, 0.0022368121264248397, 0.002198539087028827, 0.002165060544461272, 0.0021366556507829166, 0.00211353512568387, 0.002095823136160446, 0.002083526569994113, 0.0020764862169691317, 0.002074305246400555, 0.0020762713957410113, 0.002081360047024871, 0.0020883559549429815, 0.002095999724819956, 0.002103113181701392, 0.002108703109818908, 0.002112046981975346, 0.002112762659436466, 0.0021108618508601023, 0.002106784550503677, 0.0021014086311525533, 0.0020960251761751414, 0.0020922660519414682, 0.002091965953389146, 0.0020969374982958053, 0.002108636699392442, 0.00212770133316856, 0.0021533654324240527, 0.002182808877189052, 0.0022106266380897254, 0.0022288323587855547, 0.002228107992600614, 0.0022010930875756445, 0.0021462856971451796, 0.0020676623280369007, 0.0019720968332922182, 0.001867493037583546, 0.0017615119935748668, 0.0016607557916027966, 0.0015703833848345766, 0.0014940825065068771, 0.00143427463610352, 0.001392443066040354, 0.0013695054241976122, 0.0013661627456154114, 0.0013831475161356073, 0.001421288760450767, 0.0014813467090162471, 0.0015636584077106397, 0.001667741909334203], [0.0022024457573987313, 0.002157344805922409, 0.002116830609124611, 0.0020811859609501807, 0.002050620358350118, 0.0020252633335329866, 0.0020051506971421515, 0.0019901988247401844, 0.0019801631239268346, 0.0019745834775969136, 0.0019727415873878958, 0.0019736796065696702, 0.001976295644380188, 0.0019794725206414487, 0.0019822002305773094, 0.001983680188279471, 0.0019834104922084373, 0.0019812526528704758, 0.0019774786993156834, 0.0019727952698521812, 0.0019683385420350952, 0.0019656307326213615, 0.0019664855051979083, 0.0019728462580875378, 0.0019865385993134473, 0.002008917769096265, 0.0020403964496798167, 0.0020798556306880277, 0.0021239892451965954, 0.0021667556599721852, 0.0021993764892987724, 0.002211679971062282, 0.0021953090156623767, 0.002147154851947421, 0.002070024280030433, 0.001970917466484905, 0.0018588692875754344, 0.0017430948882425192, 0.0016317204595471973, 0.001531194136824027, 0.0014462207308821794, 0.001379986092946531, 0.0013345179099819564, 0.0013111046260758455, 0.0013107040348136593, 0.0013342458361580848, 0.0013827125349917422, 0.0014569178302960338, 0.0015570254211964578, 0.0016820272527482206], [0.0021349986180407648, 0.0020884303436530093, 0.002046651601599952, 0.0020098786254676253, 0.00197823372634742, 0.0019517428989152994, 0.0019303276353442333, 0.0019137868543230455, 0.0019017680985963655, 0.0018937354048875186, 0.001888954401058979, 0.0018865205297424253, 0.0018854372180546269, 0.0018847235325923327, 0.0018835252768492382, 0.001881214418719778, 0.0018774711043180023, 0.0018723459154561814, 0.001866299954101605, 0.0018602188307277091, 0.0018553945499754255, 0.0018534669681038235, 0.001856314204546506, 0.001865879540536027, 0.0018839216802576586, 0.001911677070289084, 0.001949429375623687, 0.001995995577155931, 0.0020481666177750856, 0.002100201492051455, 0.0021436477586668414, 0.002168203352612754, 0.0021644022559151508, 0.002127067372358734, 0.0020571062190700763, 0.0019609141589837843, 0.0018482556202253416, 0.0017297523841304971, 0.0016150079614449526, 0.0015117671506465439, 0.0014257815003984118, 0.0013609869468456453, 0.001319842433124025, 0.0013037834330798489, 0.0013137229767564579, 0.0013504781376973427, 0.001414951943263167, 0.0015079102543684498, 0.0016293451153317495, 0.001777726756314807], [0.0020779710356763036, 0.002030792381236377, 0.001988668385274367, 0.0019517367538454964, 0.0019200163996538403, 0.0018934111796262032, 0.001871709869332606, 0.0018545790704068295, 0.001841549996336325, 0.0018320067831931997, 0.001825190504956361, 0.0018202329877467188, 0.0018162238867399743, 0.0018123007013158311, 0.0018077455929112751, 0.0018020758083303176, 0.0017951196676282422, 0.001787073270428579, 0.001778533958076028, 0.0017705060563303263, 0.0017643732858788146, 0.001761830937878494, 0.0017647698448271343, 0.0017751038204318302, 0.0017945333346371115, 0.0018242417509470718, 0.0018645275465854023, 0.0019143867005453395, 0.001971070219239545, 0.002029638908439378, 0.0020825136678138696, 0.0021194077045840276, 0.0021294489115254987, 0.0021052170119468293, 0.002045585713585678, 0.0019561743604653045, 0.0018474638750016858, 0.001731537431533104, 0.0016194896570971523, 0.0015204077613233534, 0.0014411281144064187, 0.0013862613718871705, 0.0013584664098598186, 0.0013589568052768564, 0.0013881398913951303, 0.00144623420363141, 0.0015336462108724717, 0.0016508343136834712, 0.0017975315944847449, 0.001971656489252652], [0.0020320216789258246, 0.0019850119154411995, 0.0019433703069912326, 0.0019071455588203726, 0.001876240223559165, 0.0018504233512901622, 0.0018293413949522388, 0.0018125240323818657, 0.001799386122115127, 0.0017892320670647743, 0.0017812721628755691, 0.0017746593442572304, 0.0017685485448770736, 0.001762173170489257, 0.001754928606021599, 0.0017464524749386595, 0.0017366934257489772, 0.00172596222296089, 0.0017149599774294129, 0.0017047785938791435, 0.0016968683415003525, 0.0016929672081551867, 0.0016949866720805556, 0.0017048490693776183, 0.0017242732952375164, 0.0017545085023120285, 0.0017960194132672995, 0.0018481294564431693, 0.0019086220658478081, 0.0019732704341722676, 0.002035186663054988, 0.002084093588496274, 0.002107980873587325, 0.0020974834335226165, 0.0020494491140347084, 0.001968570717902129, 0.0018662005248394275, 0.0017562091341660558, 0.0016514501604997373, 0.001562621353793605, 0.0014977104036558188, 0.001461793782225818, 0.0014573206303210133, 0.0014847646337458726, 0.0015434550568208746, 0.001632411473110386, 0.0017509700889102272, 0.0018988079887181375, 0.002075098806486893, 0.0022771011056136633], [0.001997747148031104, 0.001951588113846318, 0.001911142626925686, 0.001876362286411473, 0.001847024525508327, 0.0018227573845598448, 0.0018030634220128332, 0.0017873386084030132, 0.0017748871595011369, 0.0017649374154424151, 0.0017566657522310818, 0.0017492343191583058, 0.0017418444846681051, 0.0017338030761944762, 0.0017245949762727951, 0.0017139542875347158, 0.0017019265265691768, 0.001688915130077563, 0.0016757063539457702, 0.0016634673166379935, 0.0016537125700547685, 0.0016482352148519564, 0.0016489991992275175, 0.0016579900622441931, 0.0016770219908655145, 0.0017074992728387188, 0.0017501286017341678, 0.0018045716996454117, 0.0018690089870461374, 0.001939549657948026, 0.0020094287853156833, 0.0020684691406241125, 0.0021045190530539102, 0.0021070833801038885, 0.002071145424115256, 0.0019999979912175927, 0.0019055413299274952, 0.0018039322742654245, 0.0017106488979215708, 0.001638468040119224, 0.0015964022317340417, 0.0015895040188345377, 0.0016193941306362253, 0.001685193801942396, 0.0017845899063075477, 0.0019148528405583537, 0.002073669001222283, 0.002259323174053099, 0.0024698016353777133, 0.002701418714861213], [0.0019757157043367836, 0.0019309807357755643, 0.0018923165980687428, 0.0018595723321247811, 0.0018323961261506767, 0.0018102754690886025, 0.001792574931205117, 0.0017785666565200968, 0.0017674548277200987, 0.0017583989303936822, 0.0017505416642658793, 0.0017430461838618553, 0.0017351446141627954, 0.001726196493630241, 0.001715752998071178, 0.0017036210346512883, 0.0016899204898067684, 0.0016751277572975428, 0.0016600990064671818, 0.0016460674926349701, 0.0016346104826520105, 0.0016275827063369885, 0.0016270141271862144, 0.0016349698255412586, 0.001653368567864853, 0.0016837535826879513, 0.001727002868120948, 0.0017829554224414782, 0.001849916464625627, 0.0019240148954809797, 0.0019985279300781572, 0.0020637279530881544, 0.0021081322377016556, 0.002121249613333389, 0.002096972699728603, 0.002036997583459093, 0.001953106820641891, 0.00186412348579889, 0.0017889482356055453, 0.0017424087838164722, 0.0017339664714340315, 0.0017679115806010694, 0.0018443470824724157, 0.0019604789842673645, 0.002111916366534971, 0.002293827563374661, 0.002501828381814978, 0.0027321983038774552, 0.0029811500623717797, 0.003243824455966257], [0.0019664726673070494, 0.001923621170707319, 0.001887184222882175, 0.0018569058105269909, 0.0018323064472624215, 0.0018127412509082535, 0.0017974504961973305, 0.0017855986972942846, 0.001776305080190178, 0.0017686707557978939, 0.001761808032145778, 0.0017548760689437269, 0.0017471250001453993, 0.0017379482396199836, 0.001726940404153549, 0.0017139563736716316, 0.0016991654763309641, 0.0016830936820652813, 0.00166664632798048, 0.0016511047104159897, 0.0016380918127600092, 0.0016295045876160187, 0.0016274112725848536, 0.0016339113514778154, 0.001650952846797223, 0.001680096821906048, 0.00172221282487757, 0.001777084487037707, 0.001842913337655278, 0.0019157634833437353, 0.001989140723146079, 0.0020541209112512155, 0.002100470416240463, 0.0021188099598495047, 0.0021034697065674636, 0.0020558329514262156, 0.0019879731091942752, 0.001920784037865487, 0.0018753889662031955, 0.0018676118789428384, 0.0019064518959770209, 0.0019947107531599565, 0.002130462235432337, 0.0023086666882795666, 0.002522641127480842, 0.002765274267769059, 0.003029867465557542, 0.0033103783362015177, 0.0036010301962508093, 0.0038957305048938763], [0.0019705056443731616, 0.0019298809308834974, 0.001895967942415476, 0.00186840771061767, 0.0018466033650654215, 0.0018297957021027864, 0.0018171225735074637, 0.0018076626312750151, 0.0018004686451534371, 0.0017945961489123806, 0.001789132519421031, 0.0017832303703834457, 0.001776147552083991, 0.001767294273660501, 0.0017562860349032519, 0.0017429991434343831, 0.0017276234670763585, 0.0017107048329109106, 0.0016931679429866232, 0.0016763111846299457, 0.001661767723679185, 0.0016514310047464108, 0.0016473444520160138, 0.0016515535810221378, 0.0016659148883381165, 0.001691851713811531, 0.001730045486778613, 0.0017800569918341174, 0.0018398982990295932, 0.0019056390403805884, 0.0019712350081389648, 0.0020288603983499606, 0.0020699949282018634, 0.0020873318802693995, 0.0020774125089689606, 0.0020438803335784675, 0.002000229916188232, 0.0019675440464719755, 0.001966866420898233, 0.0020132333445940964, 0.0021140158886781488, 0.0022699043961965327, 0.002476693234973762, 0.0027270398069390925, 0.0030119683820043538, 0.0033220580399773046, 0.003648248171956485, 0.003982182909790676, 0.004316144263475406, 0.00464283446821271], [0.0019881570407732285, 0.0019499859163696611, 0.0019187356173870492, 0.0018939566423058505, 0.0018749589771402937, 0.001860898218154351, 0.001850838358936853, 0.0018437972964049712, 0.0018387813031510826, 0.0018348139976905684, 0.001830964455267563, 0.0018263780527078687, 0.001820312460222151, 0.0018121799343579523, 0.0018015957091530109, 0.001788430598722371, 0.0017728634342709113, 0.0017554253283149131, 0.0017370240299780092, 0.0017189360801597132, 0.0017027595696378485, 0.001690327647441359, 0.001683586035123386, 0.0016844352484048693, 0.001694533844031424, 0.001715056924301921, 0.001746407754462307, 0.0017878943957815694, 0.0018374143410354136, 0.0018912423146697963, 0.0019440794856818828, 0.0019895614432569628, 0.002021394585107964, 0.002035192639593415, 0.002030937544363347, 0.0020156106901734394, 0.0020043956320874756, 0.0020178455522398163, 0.0020752098574075128, 0.0021889154243863577, 0.002363529815684398, 0.0025971708530524297, 0.0028833034579009782, 0.003212386657118154, 0.003573270347954028, 0.0039543113664539, 0.004344180111518708, 0.0047323436617345265, 0.0051092795885190065, 0.0054665566924441186], [0.002019468761586356, 0.00198386257574568, 0.001955253602226312, 0.0019331359131226737, 0.0019167656542112, 0.0019052493864853497, 0.0018976082221698416, 0.00189282462331465, 0.001889877805865086, 0.0018877728398242711, 0.0018855676853893333, 0.0018824015277679352, 0.0018775268862912709, 0.0018703471078548276, 0.0018604599781458628, 0.001847707033088067, 0.0018322259274961067, 0.0018144984433940102, 0.0017953791483186331, 0.0017760855823028166, 0.0017581397583072247, 0.0017432664032893674, 0.0017332584286325835, 0.0017298143617143391, 0.0017343469856488073, 0.001747762852880887, 0.00177022017815384, 0.0018008898082363517, 0.0018377724335701833, 0.0018776629654015673, 0.0019163890741668208, 0.001949464245491848, 0.0019732631012530175, 0.0019867275965159874, 0.001993399023137733, 0.0020031270479098926, 0.00203215236327487, 0.002100089613298312, 0.002223719430382285, 0.0024119777059149632, 0.002666214411033258, 0.0029819285887427915, 0.003350362045544053, 0.003759923643350643, 0.004197427391120696, 0.004649129702206097, 0.005101558756659043, 0.0055421437490145095, 0.005959676675190962, 0.006344654946318914], [0.0020639459021337776, 0.0020309157713621854, 0.002004802840966988, 0.0019850950148039906, 0.0019710386125321357, 0.0019617278704964457, 0.0019561711311729376, 0.001953339492360742, 0.0019522034964930238, 0.0019517626229273197, 0.0019510715388691504, 0.0019492662960103825, 0.0019455929483027134, 0.0019394404438938786, 0.0019303791264403084, 0.0019182056677207748, 0.0019029941550902174, 0.0018851489792154068, 0.0018654428870036582, 0.0018450085615408774, 0.0018252664048368132, 0.0018078066539130837, 0.0017942483060326806, 0.001786082243612022, 0.0017844996099808975, 0.0017902100034005164, 0.0018032642912421495, 0.001822913482255174, 0.0018475575319634116, 0.0018748622020630496, 0.0019021385754806337, 0.0019270732263356833, 0.0019488477532716548, 0.0019695691998569175, 0.00199571484089021, 0.0020389685915635, 0.0021155272771416446, 0.002243027458191597, 0.002435281831810541, 0.002698381004290035, 0.0030311295336858867, 0.003426808048920599, 0.0038746866087658307, 0.004361307100499299, 0.004871597279236132, 0.005389845994275525, 0.005900562693324188, 0.00638924471148436, 0.006843067322855058, 0.007251480851383564], [0.0021203867629837466, 0.0020898897377657445, 0.0020660866259798426, 0.0020484940145197397, 0.002036386961195938, 0.002028881848174388, 0.0020250030883685413, 0.0020237336507425707, 0.002024053387433622, 0.0020249693700730123, 0.002025541912992681, 0.002024909326645648, 0.0020223138537822953, 0.002017130750549062, 0.0020089021240462203, 0.0019973769515064053, 0.0019825586302003703, 0.0019647604910486083, 0.0019446584142744985, 0.0019232904201762027, 0.0019019676275007303, 0.0018821437861589047, 0.0018652783091068505, 0.0018526968184668007, 0.0018454511428337682, 0.0018441872844712985, 0.0018490401820379068, 0.001859587658670214, 0.0018749110614390398, 0.001893822217778722, 0.0019153171246597588, 0.001939294060890123, 0.0019675124392928133, 0.0020046533832433003, 0.002059168949175158, 0.0021434100693006708, 0.0022724257199427185, 0.0024610766957236224, 0.002720140775252182, 0.0030536336249103436, 0.0034587650287966143, 0.003927297246613658, 0.0044469936766715614, 0.005002853505520615, 0.005578167740810391, 0.006155463716901701, 0.006717397874650892, 0.007247646037287036, 0.007731809620206817, 0.008158283854367666], [0.0021870681512554287, 0.0021590274988331844, 0.002137351009380275, 0.0021215958766419617, 0.0021110887414286512, 0.0021049945654086364, 0.0021023788475823817, 0.002102257989498202, 0.002103638715996686, 0.002105549398798147, 0.002107066378541806, 0.002107338090440728, 0.0021056093935082733, 0.002101248141973003, 0.0020937757932145903, 0.002082903765527579, 0.0020685773802213486, 0.00205102958800143, 0.0020308433916557127, 0.002008963482606426, 0.0019865940159371075, 0.0019650689292172734, 0.0019457296643928075, 0.0019298105464482902, 0.0019183359884626305, 0.001912040379768058, 0.0019113299177651623, 0.0019163149350729471, 0.0019269491497014874, 0.0019433143250356922, 0.001966078278488961, 0.0019971223380706067, 0.002040272609648392, 0.0021019743056234484, 0.0021916325575068183, 0.0023212539386746733, 0.0025040627864661995, 0.002752091849651653, 0.0030734277645039785, 0.003470337302182309, 0.003938977451966301, 0.004470244391384672, 0.0050509779049776864, 0.00566511444730799, 0.0062947089692876115, 0.0069208691325964525, 0.007524677158785971, 0.008088176457345867, 0.008595471613182169, 0.00903389272093367], [0.0022620211852690778, 0.002236332974560885, 0.00221660889063515, 0.0022024478456263456, 0.002193236454287664, 0.0021882031633166585, 0.0021864722853945713, 0.002187111266010343, 0.0021891696394944577, 0.0021917108209183063, 0.0021938388995918928, 0.0021947228004344987, 0.002193620066419221, 0.002189902341459895, 0.002183084526118024, 0.002172859611124142, 0.002159141398079121, 0.002142117274034644, 0.00212230429889412, 0.002100555796156761, 0.0020779774863856166, 0.002055813883157884, 0.002035344511687204, 0.002017795980363049, 0.0020042756009661725, 0.0019957374204648635, 0.001992997315197678, 0.0019968187713416017, 0.0020080927747857294, 0.0020281301859294983, 0.002059068287192365, 0.002104359983008163, 0.0021692619330296674, 0.002261171455915541, 0.0023896008887065194, 0.0025655647871721757, 0.002800255046946801, 0.003103144388578672, 0.003480022467703773, 0.003931641391159481, 0.004453353126984562, 0.005035587222082136, 0.005664751000430825, 0.0063242253635440665, 0.006995321545342832, 0.007658195739610284, 0.008292782282428378, 0.008879833362185298, 0.009402153945116972, 0.009846051329713893], [0.0023432287406421736, 0.0023197690809167236, 0.002301832515385981, 0.0022890571231255472, 0.0022808899235927643, 0.0022766285359245115, 0.0022754661121719665, 0.0022765335355806305, 0.002278936275610069, 0.0022817857495416273, 0.0022842263976775145, 0.0022854602761150024, 0.002284771167341563, 0.0022815502508866724, 0.0022753254000007087, 0.002265796184255831, 0.002252876273505894, 0.0022367419374557202, 0.002217872869198305, 0.0021970524426491713, 0.0021753109308084813, 0.002153840387580778, 0.0021339136735800948, 0.0021168221790329794, 0.002103840484428703, 0.0020962275855971255, 0.0020952770300460546, 0.0021024295705439748, 0.0021194594606792636, 0.002148736630671945, 0.002193548953487566, 0.002258440007545907, 0.002349479840609292, 0.0024743475094241383, 0.002642082938221584, 0.002862390696251007, 0.003144478938003975, 0.0034955930815023266, 0.003919584605327581, 0.004415903710626104, 0.004979241060658888, 0.005599776079341479, 0.006263816805458535, 0.006954612947165026, 0.007653215051647101, 0.008339349058684898, 0.008992342489835168, 0.009592179273826008, 0.010120785297759475, 0.010563650520153478], [0.002428756737625148, 0.0024073894922338086, 0.002391086185144841, 0.0023795206813884426, 0.002372197449690492, 0.002368483538588866, 0.0023676451781213404, 0.002368884293088106, 0.0023713722365306593, 0.0023742799164078172, 0.0023768048015058068, 0.0023781960701274585, 0.002377779569735036, 0.002374984436970266, 0.0023693732326136295, 0.0023606770885552728, 0.002348835890898464, 0.0023340392060972113, 0.002316755499848067, 0.002297732158636513, 0.0022779602114679715, 0.002258618317664703, 0.002241017709234306, 0.002226563883282899, 0.0022167452048087524, 0.0022131567807237235, 0.00221756755411884, 0.0022320369213580512, 0.0022590822381682806, 0.0023018886287684637, 0.0023645364534929806, 0.0024522001115486625, 0.002571248084203293, 0.0027291563952421996, 0.0029341492083003445, 0.003194516462343927, 0.0035176374378876533, 0.003908846499170652, 0.004370365895576227, 0.0049005395325721545, 0.005493508915774708, 0.006139329849151455, 0.006824422002072313, 0.007532217989007847, 0.00824391660973992, 0.008939305246004876, 0.009597671218031706, 0.010198863042227918, 0.01072459248918174, 0.011160092090106842], [0.0025168356989893562, 0.002497419841340748, 0.0024826082761984264, 0.0024721075372392595, 0.0024654756028261253, 0.0024621466323555496, 0.002461460632671539, 0.002462694593123467, 0.0024650927699342187, 0.002467895089135801, 0.002470363721715991, 0.0024718086488341555, 0.002471613494043548, 0.002469263083435258, 0.0024643740445967105, 0.002456729012190843, 0.0024463131444678265, 0.0024333482231907785, 0.0024183156973212596, 0.00240195975395516, 0.0023852685324762643, 0.002369441999216679, 0.0023558605058419954, 0.0023460669733070885, 0.0023417722423286877, 0.0023448902969933666, 0.002357607612562338, 0.002382487399985023, 0.0024226036385636917, 0.0024816905951905426, 0.002564280988080609, 0.002675791527354344, 0.0028225019322865486, 0.0030113689305255164, 0.003249628131832767, 0.0035441705251254333, 0.0039007359217999474, 0.00432302894541126, 0.0048119071149476875, 0.005364788275899196, 0.005975370767185299, 0.006633680183329584, 0.007326391594149424, 0.008037351205532433, 0.00874823548174168, 0.00943932145735426, 0.010090382374469135, 0.010681758825123745, 0.01119568466473027, 0.011617959805751765], [0.00260590558639139, 0.002588301514859206, 0.002574854971991653, 0.0025653026800694975, 0.0025592522993376395, 0.0025562018590684077, 0.0025555639438561506, 0.0025566921848248067, 0.002558908232558556, 0.002561528234593948, 0.0025638886526672057, 0.002565371889920216, 0.002565432591472451, 0.002563625584102125, 0.0025596361346184584, 0.0025533123555776163, 0.002544698005698206, 0.0025340618196043533, 0.002521917968059124, 0.0025090331961460217, 0.002496420491439689, 0.002485324786349374, 0.0024772098124664515, 0.002473755462599204, 0.0024768730325956468, 0.0024887429325567184, 0.0025118762224829003, 0.0025491971629623645, 0.0026041382525381082, 0.002680731694406805, 0.002783672408426944, 0.002918319221663036, 0.003090595718380631, 0.0033067545016982457, 0.0035729824012351733, 0.00389485129554947, 0.004276656417929903, 0.004720721152566082, 0.005226769655275131, 0.005791464113262973, 0.006408171548540245, 0.007066979306240178, 0.0077549387955002606, 0.008456498208156334, 0.009154089419763463, 0.009828855276341995, 0.010461531302496998, 0.011033521575775116, 0.011528218418988408, 0.011932559494972397]], \"zauto\": true, \"zmax\": 0.011932559494972397, \"zmin\": -0.011932559494972397}, {\"autocolorscale\": false, \"autocontour\": true, \"colorbar\": {\"tickfont\": {\"size\": 8}, \"ticksuffix\": \"\", \"x\": 1, \"y\": 0.5}, \"colorscale\": [[0.0, \"rgb(255,247,251)\"], [0.14285714285714285, \"rgb(236,231,242)\"], [0.2857142857142857, \"rgb(208,209,230)\"], [0.42857142857142855, \"rgb(166,189,219)\"], [0.5714285714285714, \"rgb(116,169,207)\"], [0.7142857142857143, \"rgb(54,144,192)\"], [0.8571428571428571, \"rgb(5,112,176)\"], [1.0, \"rgb(3,78,123)\"]], \"contours\": {\"coloring\": \"heatmap\"}, \"hoverinfo\": \"x+y+z\", \"ncontours\": 25, \"type\": \"contour\", \"x\": [0.5, 0.5102040816326531, 0.5204081632653061, 0.5306122448979592, 0.5408163265306123, 0.5510204081632653, 0.5612244897959183, 0.5714285714285714, 0.5816326530612245, 0.5918367346938775, 0.6020408163265306, 0.6122448979591837, 0.6224489795918368, 0.6326530612244898, 0.6428571428571428, 0.6530612244897959, 0.6632653061224489, 0.673469387755102, 0.6836734693877551, 0.6938775510204082, 0.7040816326530612, 0.7142857142857143, 0.7244897959183674, 0.7346938775510203, 0.7448979591836735, 0.7551020408163265, 0.7653061224489796, 0.7755102040816326, 0.7857142857142857, 0.7959183673469388, 0.8061224489795917, 0.8163265306122449, 0.8265306122448979, 0.8367346938775511, 0.846938775510204, 0.8571428571428571, 0.8673469387755102, 0.8775510204081632, 0.8877551020408163, 0.8979591836734693, 0.9081632653061225, 0.9183673469387754, 0.9285714285714286, 0.9387755102040816, 0.9489795918367346, 0.9591836734693877, 0.9693877551020408, 0.9795918367346939, 0.9897959183673469, 1.0], \"xaxis\": \"x2\", \"y\": [0.0, 2.0408163265306125e-06, 4.081632653061225e-06, 6.122448979591837e-06, 8.16326530612245e-06, 1.0204081632653063e-05, 1.2244897959183674e-05, 1.4285714285714287e-05, 1.63265306122449e-05, 1.836734693877551e-05, 2.0408163265306126e-05, 2.2448979591836737e-05, 2.448979591836735e-05, 2.6530612244897963e-05, 2.8571428571428574e-05, 3.061224489795919e-05, 3.26530612244898e-05, 3.469387755102041e-05, 3.673469387755102e-05, 3.877551020408164e-05, 4.081632653061225e-05, 4.285714285714286e-05, 4.4897959183673474e-05, 4.6938775510204086e-05, 4.89795918367347e-05, 5.1020408163265315e-05, 5.3061224489795926e-05, 5.510204081632654e-05, 5.714285714285715e-05, 5.918367346938776e-05, 6.122448979591838e-05, 6.326530612244899e-05, 6.53061224489796e-05, 6.734693877551021e-05, 6.938775510204082e-05, 7.142857142857143e-05, 7.346938775510205e-05, 7.551020408163266e-05, 7.755102040816328e-05, 7.959183673469389e-05, 8.16326530612245e-05, 8.367346938775511e-05, 8.571428571428573e-05, 8.775510204081634e-05, 8.979591836734695e-05, 9.183673469387756e-05, 9.387755102040817e-05, 9.591836734693878e-05, 9.79591836734694e-05, 0.0001], \"yaxis\": \"y2\", \"z\": [[0.0033479296089038092, 0.0033384445880540307, 0.0033273728766819635, 0.0033144626016882043, 0.0032994288716806366, 0.0032819515958484925, 0.0032616737454777473, 0.0032382002618559953, 0.003211097862820151, 0.00317989605865212, 0.003144089757812262, 0.003103143924977637, 0.0030565008478184103, 0.0030035906728426913, 0.0029438459793786616, 0.0028767212644322995, 0.0028017182921943966, 0.0027184182905009503, 0.002626521902534549, 0.0025258975417877276, 0.0024166382114169617, 0.0022991257005607712, 0.0021740989723427894, 0.002042719898102522, 0.0019066233902214622, 0.0017679294563451272, 0.001629181477589379, 0.001493160995729186, 0.0013625255318094804, 0.0012392471183278403, 0.0011239267739277447, 0.0010152194089996667, 0.0009097167523608984, 0.0008025265209609792, 0.000688441907457033, 0.0005632954944359005, 0.00042509245140746443, 0.00027474200491023766, 0.00011641611199731191, 4.236149622067199e-05, 0.00019122146019108423, 0.00031980945514457123, 0.0004194541047765952, 0.000483418561623148, 0.0005069853924253814, 0.00048749923331903165, 0.00042439662802527963, 0.00031924248232738335, 0.00017578155226055897, 6.495091049651292e-07], [0.0033423509266993037, 0.0033321793202131128, 0.0033203287231332547, 0.003306531598152125, 0.003290484533543151, 0.0032718456352603766, 0.0032502323044719516, 0.0032252195887853457, 0.003196339339879745, 0.003163080465552724, 0.0031248906329331212, 0.0030811798644233617, 0.0030313265710631837, 0.0029746866908508117, 0.002910606742011863, 0.0028384417607996253, 0.0027575792641049176, 0.0026674705475018276, 0.0025676707793039996, 0.0024578894459326714, 0.002338052681075252, 0.0022083787537098692, 0.002069467267743113, 0.0019224009701192422, 0.0017688555103013448, 0.0016112050920677778, 0.0014525970181014332, 0.0012969397816832882, 0.001148702627519444, 0.001012371829312566, 0.0008914241977265915, 0.0007869298682408238, 0.0006964575061464576, 0.0006143184366816687, 0.000533556072883485, 0.0004489853124717535, 0.00036070508933552873, 0.00027949345304822905, 0.00023543779254802473, 0.00026138023727197856, 0.00033809938842750784, 0.0004250202089286284, 0.000497714651216836, 0.0005430857127453755, 0.0005536457781404183, 0.0005254368189761041, 0.0004574036233652379, 0.00035157157852135854, 0.0002155933496055264, 9.859388990742757e-05], [0.003336163565040684, 0.0033252926625823667, 0.0033126602391644676, 0.0032979855981691603, 0.003280949762170009, 0.0032611925388035734, 0.003238309935564394, 0.00321185209388093, 0.0031813219491404667, 0.0031461748697246775, 0.003105819588032818, 0.0030596208136897604, 0.0030069040174830436, 0.0029469629975035225, 0.0028790709891048844, 0.0028024962590051617, 0.0027165233309544372, 0.0026204812243699116, 0.002513780346414106, 0.0023959599628219606, 0.002266748491884503, 0.0021261392454666158, 0.0019744847399720037, 0.0018126134305523906, 0.001641973851316229, 0.0014648127850553632, 0.0012843956600212777, 0.0011052749005863375, 0.0009335880005531731, 0.000777259903868543, 0.0006456366819536913, 0.0005474049814841277, 0.0004858810792658762, 0.00045482583039484496, 0.0004413545836029856, 0.0004344081967512718, 0.0004303890362312254, 0.000433217887672723, 0.00045000690320476996, 0.00048415364935316935, 0.0005308999091418516, 0.0005792882148926918, 0.0006170335437494042, 0.0006336771729714797, 0.0006216083662844351, 0.0005761830397894164, 0.0004957610591985968, 0.0003822834637165175, 0.0002449280408605417, 0.00013459072659485435], [0.003329220624744863, 0.0033176294306751218, 0.003304204953055665, 0.003288656153708623, 0.003270651817915636, 0.003249817429854532, 0.0032257324007544438, 0.003197927806276006, 0.003165884814927219, 0.0031290340225517484, 0.003086755953062796, 0.003038383047240392, 0.0029832035444085107, 0.002920467770723726, 0.002849397486240353, 0.002769199112738336, 0.0026790818649475127, 0.002578282035972311, 0.002466094938132635, 0.0023419162690385504, 0.002205294965299433, 0.0020559999592033537, 0.001894103783277533, 0.00172008699132046, 0.001534969716100821, 0.0013404825911154964, 0.0011393049844976883, 0.0009354428808703774, 0.0007349528380793039, 0.0005476430165395345, 0.00039153128966816573, 0.00030046665686575086, 0.00030382917066937537, 0.00036885244225107417, 0.0004462331378881093, 0.0005146111419488825, 0.0005694453986745762, 0.0006129864948684172, 0.0006494856106172672, 0.000682058221359632, 0.0007106781782573211, 0.0007318231262860378, 0.0007396335678608117, 0.0007276122553800567, 0.0006900201875517604, 0.0006227540212458858, 0.0005239092136029653, 0.00039451457061539293, 0.00024155244014243185, 0.00011291895858657393], [0.003321339491582271, 0.0033089943534900744, 0.003294755380521855, 0.0032783241446406155, 0.003259360640842999, 0.0032374801228354255, 0.003212250353328575, 0.003183189422855334, 0.003149764304008723, 0.003111390325672954, 0.003067431778692133, 0.0030172039059751334, 0.0029599765923363384, 0.002894980158406331, 0.002821413783667807, 0.0027384572387063933, 0.00264528679475786, 0.002541096392263496, 0.0024251253739586004, 0.0022966942963395572, 0.002155250488792867, 0.0020004250830602255, 0.0018321031291935138, 0.001650508091849815, 0.0014563014619355986, 0.0012506975493778326, 0.0010355934479646235, 0.0008137179420930412, 0.0005888280402078333, 0.0003661562132974226, 0.0001555921488874919, 8.631720776400224e-05, 0.00025304305188929705, 0.00040954676827630043, 0.0005406376888099199, 0.000645323887387377, 0.0007255129983799081, 0.0007845905983014175, 0.0008262953304629879, 0.0008535527266012317, 0.0008675341263095827, 0.0008672935561125755, 0.0008501011144547603, 0.0008122518262164133, 0.0007499886839502595, 0.0006602874278560089, 0.0005414437972434182, 0.00039358291517572563, 0.00021974071794484066, 5.101311629129309e-05], [0.0033122985107686197, 0.003299148509546958, 0.0032840552971947507, 0.003266715974705744, 0.003246785056045002, 0.003223871400359206, 0.0031975356917912628, 0.0031672886365312833, 0.0031325900475908377, 0.0030928489892121857, 0.003047425159992825, 0.0029956317135010234, 0.0029367397554848434, 0.0028699848266377755, 0.0027945757881729307, 0.002709706681929064, 0.002614572342542505, 0.0025083887972976063, 0.0023904197950449114, 0.0022600111494808436, 0.0021166349551855145, 0.0019599461478702626, 0.0017898544179197609, 0.001606615459955932, 0.0014109479492492472, 0.0012041897045566318, 0.0009885296099219128, 0.0007674378217300356, 0.0005468059938827269, 0.00033967877486768515, 0.0001956450083370088, 0.00024069657995393935, 0.0003927465304024468, 0.0005477661241447814, 0.000683414462116218, 0.0007943046583616405, 0.0008797559124812497, 0.0009411060703779042, 0.0009804643500642073, 0.0009997928617854418, 0.0010002257851625086, 0.0009817263114039196, 0.0009431385047237563, 0.0008825667623803739, 0.0007979266465830713, 0.0006875115250798161, 0.00055048522529811, 0.00038729795459488826, 0.0002002033679644691, 2.294804135897075e-05], [0.0033018341440115588, 0.0032878064052175447, 0.0032717969151322044, 0.0032535010791352563, 0.0032325709001793986, 0.00320861209366332, 0.003181181959718443, 0.0031497882229820982, 0.003113889040007141, 0.003072894360026521, 0.003026168811818269, 0.0029730362863842354, 0.002912786403069516, 0.0028446830990878683, 0.0027679756851071865, 0.0026819128811030406, 0.0025857606088813385, 0.002478824697694505, 0.0023604801959411616, 0.002230209741396804, 0.0020876545596867986, 0.0019326834417203052, 0.0017654882318161708, 0.0015867207847100856, 0.001397700847781037, 0.0012007601779730965, 0.0009998839352078634, 0.0008020795922597182, 0.0006206205069015784, 0.00048209946728344647, 0.0004294411562415173, 0.00048059414017552997, 0.0005935514493434363, 0.00072241857931761, 0.0008433783624161469, 0.0009459117958576201, 0.001025745854220899, 0.0010816741120678432, 0.0011139625138289675, 0.0011233748596335765, 0.0011105371979297052, 0.0010755909940251519, 0.0010181267579345945, 0.0009373582021244151, 0.0008324592543356334, 0.0007029804870698817, 0.0005493045168868076, 0.0003732729103231794, 0.00018075860532770795, 7.745065362285824e-05], [0.0032896386019192116, 0.0032746336183439393, 0.0032576188029130927, 0.0032382904899114873, 0.003216300717756596, 0.0031912545234589348, 0.003162708278082283, 0.0031301693439771076, 0.003093097316105841, 0.0030509070804295184, 0.003002973888809671, 0.002948640622473321, 0.0028872274089601006, 0.00281804378926221, 0.00274040372682477, 0.002653643940155564, 0.0025571463695744797, 0.00245036611871659, 0.0023328670393255122, 0.0022043684157433516, 0.0020648082503863198, 0.001914432039360753, 0.0017539218727867217, 0.0015845917683558384, 0.0014086966937269822, 0.0012299447168545108, 0.0010543749013632315, 0.0008918270988276976, 0.0007578872631714663, 0.0006738497655875944, 0.0006574875336362889, 0.0007059187805690383, 0.0007956799555468907, 0.0009008674451187849, 0.0010031840534813843, 0.001091747657025135, 0.0011606232781127298, 0.001206884720940303, 0.0012293356215336945, 0.0012276562222991222, 0.00120183870762922, 0.0011518597204561358, 0.0010775670115697686, 0.0009787499837060547, 0.0008553480192162445, 0.0007077459640543864, 0.0005371295820183635, 0.0003460100968939273, 0.00014090863460034731, 0.00010280736508059677], [0.0032753579387762776, 0.0032592448810541174, 0.0032411042754001296, 0.0032206359993606935, 0.003197494343120504, 0.0031712853525023223, 0.003141565557847167, 0.003107842475465006, 0.0030695772443444123, 0.0030261897177592165, 0.0029770662746496806, 0.002921570561042168, 0.002859057334131265, 0.0027888895837397897, 0.0027104591784299034, 0.002623211469118955, 0.0025266746426378175, 0.002420495241540134, 0.0023044822921557176, 0.0021786641253912532, 0.00204336457767177, 0.0018993093740266634, 0.0017477799623575245, 0.0015908418933067957, 0.0014316878788399286, 0.0012751442428455804, 0.0011283544842611668, 0.0010014387755110897, 0.0009072447082316516, 0.0008582717987014276, 0.0008600233971737342, 0.0009060028577256012, 0.0009808000500910452, 0.0010675504420953263, 0.0011525717884094077, 0.0012262763847337374, 0.0012824812035606497, 0.0013174501115224002, 0.001329071394307147, 0.0013162291316468357, 0.0012783573707427923, 0.0012151646062033461, 0.0011265170826616506, 0.001012462343852088, 0.000873364741919562, 0.0007101201383090886, 0.0005244270601458424, 0.0003191716189001952, 0.0001006436277925834, 0.00014024182891402164], [0.0032585906526119675, 0.0032412025010134862, 0.0032217799533446963, 0.0032000293583891305, 0.0031756094656289224, 0.0031481285223864544, 0.003117143141122869, 0.003082159469614088, 0.0030426371708671216, 0.002997996664296488, 0.0029476300028333877, 0.002890915675688038, 0.0028272375522662165, 0.002756008144114156, 0.0026766963916189657, 0.002588860325783718, 0.002492185277787826, 0.002386528905793088, 0.0022719753181975155, 0.0021489021855102333, 0.0020180671757824534, 0.0018807234826622994, 0.0017387783603740922, 0.0015950115143111147, 0.0014533649221032292, 0.0013192817394356451, 0.0011999620371890907, 0.0011041531962635758, 0.0010407812401850853, 0.0010159801288568597, 0.0010297448930402465, 0.0010750604121769728, 0.0011405104854118264, 0.001213967779768734, 0.0012849656115807985, 0.0013454618663661128, 0.0013897071447191197, 0.001413802545062914, 0.001415221660736418, 0.0013923977387106006, 0.0013444112652199315, 0.0012707920176102184, 0.0011714413363512614, 0.001046677270436001, 0.0008974151141786044, 0.0007255554699483134, 0.0005349497774145218, 0.0003353193671942119, 0.00017389470033055875, 0.00024009936830385954], [0.0032388869715926365, 0.0032200151506192715, 0.0031991142982668455, 0.003175901002873094, 0.003150041254338931, 0.00312114680787161, 0.003088773710606552, 0.003052423715632457, 0.0030115492845276468, 0.0029655628130876893, 0.0029138506147751994, 0.002855792078525268, 0.0027907843033619806, 0.0027182724277788287, 0.0026377858477891637, 0.002548980592312191, 0.002451688349502106, 0.002345973083523849, 0.002232196938558258, 0.0021110982799273873, 0.001983886247320966, 0.001852357658578646, 0.0017190418884055808, 0.0015873729116079687, 0.0014618644067178202, 0.0013482042238821947, 0.0012530707987580538, 0.0011833489786944379, 0.0011445071837133352, 0.0011385157938584459, 0.001162549219116599, 0.0012095482931106653, 0.001270232309532324, 0.0013351807052140643, 0.0013961145840848271, 0.00144636951432053, 0.001480886110058597, 0.0014959936032671827, 0.001489139681844261, 0.0014586414920818131, 0.0014034966583448879, 0.001323279457392348, 0.0012181456218777152, 0.0010889829347860188, 0.0009378000716305884, 0.000768644092645678, 0.000590107956067401, 0.0004237492438961256, 0.0003297633390016627, 0.0003898729276583068], [0.003215749239552592, 0.0031951373091540078, 0.003172516196179306, 0.003147618067010304, 0.0031201203603813937, 0.003089640713629783, 0.003055734413278852, 0.003017895339864823, 0.002975561360599477, 0.002928125045668154, 0.002874950456944847, 0.0028153966033357745, 0.0027488480026880077, 0.002674752666174124, 0.0025926677559448817, 0.0025023131864322793, 0.0024036335667898512, 0.002296869133267995, 0.0021826366868996526, 0.0020620219294458183, 0.0019366845828792112, 0.0018089761190577685, 0.0016820638897039495, 0.0015600386865442472, 0.001447945030389598, 0.0013516074267962213, 0.001277056921067048, 0.0012294034054177773, 0.0012113238596301269, 0.0012218666586771806, 0.0012563870308944121, 0.0013076962933129459, 0.0013676677625285346, 0.0014285123420699462, 0.0014834633877725237, 0.0015269999456751203, 0.0015548168688482324, 0.0015636897853304691, 0.0015513168189403592, 0.0015161817563178457, 0.0014574685463242152, 0.00137505531732909, 0.0012696260573707603, 0.0011429702200038549, 0.0009986296063279581, 0.0008432949648253845, 0.0006899645436159499, 0.0005645693937801871, 0.0005112871588568891, 0.0005643850273100661], [0.0031886341366919066, 0.0031659700277400196, 0.003141334106782645, 0.0031144819380193515, 0.0030851091555083566, 0.0030528440131932497, 0.003017242740414762, 0.0029777889842700035, 0.00293389861597736, 0.0028849310851370357, 0.0028302083411646207, 0.0027690421384928593, 0.002700770344225369, 0.002624802717566582, 0.002540676565139378, 0.0024481227143825337, 0.002347142382177616, 0.0022380956969973533, 0.002121802713384021, 0.0019996573555658196, 0.0018737528894562257, 0.0017470120145358194, 0.001623300793925564, 0.001507475431634151, 0.0014052570825281968, 0.001322766293420066, 0.0012655550621954112, 0.001237204057208154, 0.0012380239980761879, 0.0012646639749954367, 0.0013109366660631558, 0.0013693077454902181, 0.0014322333388726565, 0.0014929514077721005, 0.001545784607598182, 0.0015861622926850473, 0.0016105270211955003, 0.0016162155213519064, 0.0016013561154505185, 0.0015648049180241545, 0.0015061401301906076, 0.001425740512820802, 0.0013249911483957893, 0.0012066956015271218, 0.0010758467537237382, 0.0009410313376111532, 0.0008167713562866886, 0.0007259888634484801, 0.0006967797557540098, 0.0007451247503570561], [0.0031569578664422102, 0.003131864184446338, 0.0031048568994721504, 0.003075726322871129, 0.003044196899022489, 0.0030099161897310135, 0.0029724468034890623, 0.002931262949960608, 0.002885753314865086, 0.0028352318312440646, 0.0027789576953844855, 0.0027161656929344225, 0.0026461076352139487, 0.002568105533684246, 0.0024816171260348754, 0.0023863145469290746, 0.0022821773020606164, 0.00216960116857797, 0.002049524947194501, 0.001923576444542718, 0.0017942359453525726, 0.0016650057047008144, 0.001540549315254452, 0.0014267121504298649, 0.0013302474819567804, 0.0012580004351380747, 0.0012154185035522299, 0.001204768767801506, 0.001224071718898946, 0.0012675810692550716, 0.0013274752278734417, 0.0013956375177538558, 0.0014647700764993785, 0.0015288074212232228, 0.0015829183727151155, 0.0016233538995717154, 0.0016472791141235845, 0.001652643302854129, 0.0016381035508052472, 0.001603007231872283, 0.001547441947845988, 0.0014723718980566515, 0.0013798962278747198, 0.001273688809498989, 0.0011597037163992164, 0.001047203549680112, 0.0009498669115693307, 0.0008856315950086328, 0.0008722658327685906, 0.0009181215911513114], [0.0031201058668255404, 0.0030921279675611662, 0.0030623182229383697, 0.003030517690313026, 0.0029964956022871456, 0.0029599333260681105, 0.0029204111822676115, 0.0028774003268480335, 0.0028302619483225964, 0.002778255870148261, 0.002720560308529013, 0.002656304102601476, 0.002584612329126525, 0.0025046659737163125, 0.0024157763806027656, 0.002317475637661015, 0.0022096249228294187, 0.0020925441187625545, 0.0019671674884459375, 0.0018352311444816667, 0.0016994961091579153, 0.0015639994859370718, 0.0014342900351095292, 0.00131751414263495, 0.0012220511093359433, 0.001156247223599396, 0.0011260670559565483, 0.0011325743609099206, 0.0011711352967666807, 0.001233145850402253, 0.0013088314115629407, 0.001389297276634399, 0.0014673399774385255, 0.0015374570171667182, 0.0015955567927662495, 0.0016386435927840484, 0.001664577445850054, 0.0016719271560870466, 0.0016599085170031795, 0.0016283976094328082, 0.0015780164508396705, 0.0015102991845698163, 0.0014279586229088775, 0.0013352797506337773, 0.0012386487590582637, 0.0011471220944493262, 0.0010726210819350884, 0.0010287557039945574, 0.0010271865615415654, 0.0010726281676273275], [0.003077449004228114, 0.003046040906772512, 0.0030129070345327248, 0.002977960943731326, 0.00294103958723714, 0.0029018804913348148, 0.0028601013558323157, 0.002815184988562761, 0.0027664726040331003, 0.0027131682936259002, 0.0026543569445225826, 0.0025890371715269873, 0.0025161701290224584, 0.0024347446224723913, 0.002343858965171554, 0.002242820719698805, 0.0021312669948697735, 0.002009310515685556, 0.0018777204209716688, 0.0017381515785957636, 0.0015934405849081198, 0.0014479834096312175, 0.0013081744985763558, 0.0011827548504658762, 0.0010825791872907421, 0.0010188420500954005, 0.0009991438734446904, 0.001023307515894449, 0.0010829982374225631, 0.001165741416074013, 0.0012593640941346409, 0.001354140288724809, 0.0014430189478017374, 0.0015211008909285888, 0.0015850349203977198, 0.0016325536199695235, 0.0016621775991050717, 0.001673061846932929, 0.0016649514225413917, 0.0016382214551763322, 0.0015939874591258758, 0.0015342824500622857, 0.001462303655502527, 0.0013827252272860572, 0.0013020331035840135, 0.0012287229450418068, 0.0011729789464834668, 0.0011452543348185304, 0.0011535483470220937, 0.0012005590626008788], [0.0030283684980347415, 0.002992877282291686, 0.002955787662231322, 0.002917114173557185, 0.0028767929891942382, 0.0028346502206779514, 0.002790371644227307, 0.0027434777419667626, 0.002693308227588271, 0.0026390199463342274, 0.002579601211234015, 0.002513904436148231, 0.0024406976671572053, 0.0023587346811883986, 0.0022668430827620916, 0.0021640305942514614, 0.0020496117885092585, 0.0019233612664425158, 0.001785705525857764, 0.0016379759543754197, 0.0014827614586734165, 0.0013244206480715222, 0.001169821223040324, 0.0010292693448414423, 0.0009170465789366264, 0.0008495464323411941, 0.0008383828183357707, 0.0008819173426447372, 0.000965726344077533, 0.0010716936341866503, 0.0011848919277573059, 0.0012950537013611116, 0.0013956139472445196, 0.0014824765304541356, 0.0015531014270676966, 0.0016059349328421048, 0.001640097167194154, 0.0016552485525185526, 0.0016515787573522416, 0.001629880166840188, 0.0015916824185744085, 0.001539434614836051, 0.0014767241756587456, 0.0014085071620532005, 0.0013412774565267254, 0.0012830028321293193, 0.0012425280924066898, 0.0012281567602207876, 0.0012455816754335044, 0.0012961685882919936], [0.002972291900910006, 0.002931942079277547, 0.0028901333876230387, 0.0028470172276957835, 0.002802670605655427, 0.00275705310171366, 0.002709963326308915, 0.002661000117368582, 0.0026095343761851804, 0.002554697174819546, 0.002495388520882239, 0.0024303091623194386, 0.002358015557674033, 0.002276996264737784, 0.0021857671012670116, 0.002082982921149387, 0.0019675660072606075, 0.0018388553083337506, 0.001696788114397426, 0.0015421390824912483, 0.0013768674308049982, 0.0012046757053355598, 0.0010319848840924508, 0.0008696612806746283, 0.0007355519302173578, 0.0006549955708620195, 0.0006496123007433908, 0.0007160185755080781, 0.0008280856622330396, 0.0009593368266465738, 0.001092446628156556, 0.0012175594747631596, 0.0013292413938260905, 0.0014244958102088378, 0.0015016626355190176, 0.0015598430423000838, 0.0015986351611650441, 0.0016180612348658352, 0.0016186146726360439, 0.001601381485149823, 0.0015682070259460368, 0.0015218883982285282, 0.0014663720315448894, 0.0014069164242709812, 0.0013501300063752343, 0.001303712450910334, 0.0012756699162979666, 0.0012729035249935106, 0.0012995342540788545, 0.0013558394269377974], [0.0029087421846492397, 0.0028626226942131327, 0.002815177918127877, 0.0027667395353707697, 0.002717578444020516, 0.0026678476203389726, 0.0026175209114213, 0.0025663348707288583, 0.002513742188369866, 0.00245888526661418, 0.002400596733834036, 0.0023374304220877915, 0.002267722371167253, 0.0021896778880169864, 0.0021014785944843996, 0.002001403300691141, 0.0018879585186537225, 0.0017600183788471795, 0.0016169800289022754, 0.001458951452231703, 0.0012870110470758582, 0.0011036330899642003, 0.0009135240895330671, 0.0007255576118534451, 0.0005576606968802527, 0.0004465603527628021, 0.0004408624588144126, 0.000537099270941911, 0.0006822809877907952, 0.0008388410822594789, 0.0009896551055068353, 0.0011271276039572407, 0.0012477442753906396, 0.0013498240094557197, 0.0014325319417242363, 0.0014954477664086091, 0.001538426253564434, 0.0015616283285951652, 0.0015656519823064876, 0.0015517175414391485, 0.0015218780437917497, 0.0014792335954080475, 0.0014281236164882989, 0.0013742439221366704, 0.0013245783405451451, 0.0012869611337209589, 0.0012690822139125647, 0.0012769786978510471, 0.0013135534209947853, 0.0013779659941596171], [0.0028374011680165115, 0.0027844591736489, 0.002730289141349027, 0.0026754530633671756, 0.0026204810503494256, 0.002565797240402062, 0.0025116352943693712, 0.002457952929038566, 0.0024043580708447425, 0.0023500601439795207, 0.0022938578087788914, 0.0022341692403112802, 0.0021691041302035062, 0.002096570131940584, 0.0020144024037281427, 0.0019205041673479553, 0.0018129884852559803, 0.0016903156595653723, 0.0015514256889506144, 0.0013958708940630489, 0.0012239621589971023, 0.0010369614603689724, 0.0008374150847871645, 0.0006299716259242147, 0.00042433928216393076, 0.000251190762284121, 0.00022283592312688893, 0.00036470281108818566, 0.0005449949713181719, 0.0007213512284847453, 0.0008835485022011325, 0.0010281992709579254, 0.001154028304853109, 0.0012604968849831235, 0.0013472696540848123, 0.0014140416384530578, 0.0014605746734116657, 0.0014868598957525924, 0.0014933473457928352, 0.001481203429183029, 0.0014525733778232197, 0.0014108325837758923, 0.0013607990830879577, 0.0013088379101966355, 0.0012627085881346289, 0.0012309211374571883, 0.0012214127463962754, 0.0012397480292251988, 0.0012876713548559628, 0.0013629451711807718], [0.002758186900594057, 0.0026972346188779833, 0.0026350690509786947, 0.0025725364325931673, 0.002510503298880625, 0.0024497633529963936, 0.002390922820140279, 0.002334276175937586, 0.0022796907019937175, 0.0022265218442856496, 0.0021735793407516193, 0.0021191558802264713, 0.0020611178158224733, 0.0019970454713073528, 0.00192440305672995, 0.001840717086274283, 0.0017437465079279675, 0.0016316347526305586, 0.0015030407315021364, 0.001357250623145894, 0.001194274490330858, 0.0010149315545885595, 0.0008209258570090032, 0.0006149106537732089, 0.00040053703390449343, 0.00018250331332369434, 3.491922154133706e-05, 0.0002423071734515461, 0.00043747419535589783, 0.0006167897992798218, 0.0007788518896139631, 0.0009231667822232563, 0.0010495591699427366, 0.0011577639504664413, 0.0012472447728526794, 0.0013172311331342782, 0.001366917104480759, 0.0013957491535649285, 0.0014037450734909686, 0.0013918134296931313, 0.0013620659185465585, 0.0013181219047623722, 0.0012653835251139889, 0.0012111916941006785, 0.0011646388335611055, 0.0011356631418465994, 0.0011331460824898832, 0.001162463349922666, 0.0012239262498954045, 0.001313295760240231], [0.002671341789870462, 0.0026010850958896265, 0.0025294823763220677, 0.0024577159881178866, 0.002387075000433749, 0.0023188436788297755, 0.002254149623882122, 0.0021937844944672374, 0.002138023483547182, 0.0020864797962964208, 0.002038030986331972, 0.0019908415704838205, 0.0019424838348477119, 0.0018901353048391527, 0.0018308169019863468, 0.0017616348772307641, 0.0016799995538861964, 0.001583808201801902, 0.0014715922038094629, 0.0013426375982707474, 0.0011970942620524367, 0.0010360976526817432, 0.0008619530285812214, 0.0006785299651952651, 0.0004924475548188976, 0.0003180382615743144, 0.00020277847191377035, 0.00024255040312095511, 0.00037895531175449374, 0.0005304208914851008, 0.0006765117359762708, 0.0008118848155800149, 0.0009343904710239073, 0.001042387258008936, 0.0011340531591464574, 0.0012073784466035001, 0.0012604372563594307, 0.001291746345488854, 0.0013006231011742824, 0.001287523993364464, 0.0012543838826305498, 0.0012049870005189183, 0.0011453736974391124, 0.0010841847561573565, 0.0010325949500333998, 0.0010031160354551489, 0.0010066164224532056, 0.001048455595449714, 0.001126676934432257, 0.0012339292123305665], [0.0025775236799134914, 0.0024966242229414867, 0.00241401355753665, 0.002331248673681768, 0.0022501277178157315, 0.002172567790782052, 0.0021004120980851176, 0.0020351748060191753, 0.0019777572011807684, 0.0019281945965997894, 0.0018855046836998828, 0.0018476911608722502, 0.0018119129478969, 0.001774779635200238, 0.001732703836919686, 0.0016822423661267212, 0.0016203822587209193, 0.0015447573635665813, 0.001453803763461358, 0.0013468743913615606, 0.001224338531077407, 0.0010876978948333963, 0.0009397700718366426, 0.0007850506206083719, 0.0006305451841496033, 0.00048785061153182655, 0.00037784679731664623, 0.0003330922718101756, 0.000369878370598134, 0.0004608355961839564, 0.0005738731509704045, 0.0006923366999843729, 0.0008080210466980517, 0.0009155481151644813, 0.0010103529223339691, 0.0010882857802358603, 0.0011457765063630871, 0.0011801247625690965, 0.0011897785719659794, 0.001174600881074785, 0.0011361805984580248, 0.001078265180908646, 0.0010073855980161494, 0.000933645454650214, 0.0008712267535329043, 0.0008371417958922377, 0.0008461748341245945, 0.00090362366311236, 0.0010032149866697586, 0.0011325747174812878], [0.0024778851259924344, 0.0023850704108969913, 0.0022898459011355702, 0.002194148916348068, 0.002100354638749211, 0.002011166049262359, 0.0019293891399422788, 0.0018575813683203415, 0.0017976045770307708, 0.0017501752649108113, 0.0017145523108022663, 0.0016884887231623825, 0.001668484858781241, 0.0016502641837466418, 0.0016293249161338644, 0.0016014341150660993, 0.0015629941557702832, 0.0015112747948503168, 0.001444539957074586, 0.0013621073681912433, 0.001264373205182728, 0.0011528240994361954, 0.0010300524697770513, 0.0008997955084862246, 0.0007670485398689436, 0.0006383972432858235, 0.0005229148918564517, 0.0004339612818725695, 0.00038963037302119035, 0.0004030452281562192, 0.00046729889491812403, 0.0005625334903324433, 0.0006710691328832453, 0.000780326446945611, 0.0008810173322389735, 0.0009659515963451192, 0.0010296253494232177, 0.0010681076063232273, 0.001079023909342439, 0.0010616186479458993, 0.0010169515400918073, 0.0009483344175968154, 0.0008621920280900553, 0.0007696064295343534, 0.0006884656323052309, 0.0006437361750011646, 0.0006586078994900391, 0.0007375495405748363, 0.0008648453974958597, 0.0010202593974930983], [0.0023741163840429068, 0.0022683529385306997, 0.0021590454236782145, 0.0020484547627233405, 0.001939545357102427, 0.0018359375300445934, 0.0017416943499921796, 0.001660874299464525, 0.0015968373986951037, 0.0015514263878192284, 0.0015243052871015776, 0.0015127761792773904, 0.0015122011886029814, 0.0015168476795480862, 0.0015208092164937285, 0.001518729644015783, 0.0015062397152698682, 0.0014801494241194143, 0.001438482320727945, 0.0013804247222211463, 0.0013062326523726835, 0.0012171127831247914, 0.0011150769310431113, 0.0010027664521454255, 0.0008832635549258476, 0.0007599772625482596, 0.0006368639568539803, 0.000519597268797543, 0.0004188309002283176, 0.0003555786895574939, 0.000356465228984344, 0.00042295959944216115, 0.0005274560128536287, 0.0006435011693576117, 0.0007542199238439844, 0.0008489181095797164, 0.0009205044121214401, 0.0009642919505350148, 0.0009774431317976903, 0.0009587397329538187, 0.0009085961083466251, 0.0008293671477748015, 0.000726194988885754, 0.000609112213174275, 0.0004981261146176478, 0.0004314840235703046, 0.0004543322163879399, 0.000566265286833549, 0.0007285319076039037, 0.000911380908807275], [0.0022684159680085984, 0.002149155341632774, 0.0020247108437745575, 0.0018975111348814796, 0.0017710037133109808, 0.0016497588991685368, 0.001539386278393427, 0.0014460772064428839, 0.0013755913593427368, 0.0013317375536828343, 0.0013148982942531068, 0.0013214856469167511, 0.001344772853838259, 0.0013765890789126463, 0.0014089433680991735, 0.0014350361026559434, 0.0014496583654689688, 0.0014492103618003718, 0.0014315478965997847, 0.0013957743369908517, 0.0013420235012509922, 0.0012712397397584912, 0.00118494655417658, 0.0010849983040166448, 0.0009733319508512895, 0.0008517841117976441, 0.0007221249468687338, 0.0005866267053145652, 0.00044996216373596927, 0.00032510440037410165, 0.00024972763151774607, 0.0002786473388613798, 0.0003868702979690028, 0.0005170489922480537, 0.0006414403259776815, 0.0007472124508798193, 0.0008271396871560027, 0.0008767526034368295, 0.0008933403807871842, 0.0008755542991163171, 0.0008232862390587591, 0.000737749941799919, 0.0006218523139425844, 0.00048137120528206264, 0.00032972355037995534, 0.00021361818126086306, 0.00025328174569211673, 0.00041933546646701764, 0.0006179620260257457, 0.0008220375605039521], [0.002163342913256223, 0.002030832245587101, 0.0018910156565789269, 0.0017462079820847916, 0.0016000341990538656, 0.0014577981664556131, 0.001326764243132887, 0.0012160152966804773, 0.001135253877293605, 0.0010920098631922199, 0.001088085539167659, 0.0011179490843229297, 0.0011707934469271776, 0.001234397728464872, 0.0012979794732136123, 0.0013532707028098647, 0.0013944954187822608, 0.0014179636750277357, 0.001421629513574746, 0.0014047142086663588, 0.0013673967487341319, 0.0013105466214477922, 0.001235475170755756, 0.0011436949957281959, 0.0010366985356663196, 0.0009157960350527363, 0.0007820864499310546, 0.0006366747635852196, 0.0004813579052343048, 0.00032067454657673435, 0.00017262365816535723, 0.0001403531742564033, 0.00026753338692660103, 0.00041716878823624124, 0.0005542467618518002, 0.0006686389072736414, 0.0007549430864472055, 0.0008097451912344306, 0.0008309089623608802, 0.0008173147775124449, 0.0007687751175537896, 0.0006860479042186409, 0.0005709079289996801, 0.00042625143241485956, 0.00025624083038665297, 6.71818046053538e-05, 0.00013868116758374992, 0.00034789798278322514, 0.0005579561598604211, 0.0007646131394804486], [0.002061506515088178, 0.0019171179352795071, 0.001763019137092155, 0.0016010295232766903, 0.0014344008855606718, 0.0012684968633517148, 0.00111173078250678, 0.0009765283079651739, 0.0008790404147242776, 0.0008346286434495022, 0.0008483822317681975, 0.0009098169344333109, 0.0009995942020604852, 0.0010992579128421983, 0.0011952336510077696, 0.001278594739071489, 0.0013438081588142583, 0.0013876776442411974, 0.0014086311623390906, 0.0014062530224776386, 0.0013809583707472645, 0.001333742200920554, 0.0012659643216564886, 0.0011791546724546327, 0.001074843986285789, 0.0009544443365955026, 0.0008192194169146043, 0.0006703889669411588, 0.0005094006419304294, 0.0003383845929388886, 0.0001609010737421703, 2.64900524275656e-05, 0.00019470299757835826, 0.0003552058168197689, 0.0004963720589828732, 0.0006132071579505489, 0.0007021447535096248, 0.0007607217076053891, 0.0007873950863547082, 0.0007814689508419801, 0.0007431481348036777, 0.0006737445100119522, 0.0005761427708437373, 0.00045601025606949197, 0.0003260896940479909, 0.00022517616911682056, 0.0002446605346312279, 0.00038038243447582876, 0.0005550563949795838, 0.0007397517851445585], [0.0019650774271647038, 0.0018115559238994594, 0.0016460846942970059, 0.0014696406016408575, 0.0012844366012845407, 0.0010947154805798127, 0.0009082623777761208, 0.0007393634232380085, 0.0006132634386501515, 0.0005639707867661526, 0.00060614951450592, 0.0007133322057563328, 0.000847995298178039, 0.0009851131662290092, 0.0011109187913634214, 0.001217904145810343, 0.0013019451468794555, 0.0013609116527758722, 0.001393970891977646, 0.001401200913053648, 0.0013833452488172385, 0.0013416321914779558, 0.0012776230524767678, 0.0011930755732901673, 0.0010898243446529816, 0.0009696944749734236, 0.000834478430149278, 0.000686017746686243, 0.0005264444476983755, 0.0003586995849868958, 0.00018815311669678162, 5.3673802784919594e-05, 0.00017088422070219719, 0.0003221244397858249, 0.0004576217471110481, 0.000571172145862977, 0.0006595022387792166, 0.0007206446481028806, 0.0007535294715236795, 0.0007578883781110951, 0.0007344025734253996, 0.0006851002916338351, 0.0006141097764154286, 0.0005291561557896295, 0.00044472125421427395, 0.00038700634971066273, 0.000389755059004792, 0.00046335735601187066, 0.0005858311815704122, 0.0007337422716826204], [0.0018751712289353962, 0.0017166565854824089, 0.0015447897093685042, 0.0013596349778391456, 0.0011620351868687384, 0.0009541043912855732, 0.0007402990579593654, 0.0005305887455744737, 0.0003527961410124251, 0.00028790353742806575, 0.0003899983050309196, 0.0005623000433622261, 0.0007421733283762927, 0.0009095055437653162, 0.0010562069997570927, 0.00117820962350601, 0.0012733402978332548, 0.001340585676375972, 0.0013797649105203316, 0.0013913484139422485, 0.0013763371409036354, 0.0013361681330622955, 0.0012726297175669036, 0.0011877777705889005, 0.001083850736582296, 0.0009631892495908695, 0.0008281791384422008, 0.0006812581622451502, 0.000525067355988977, 0.000362953203889418, 0.00020096298713179108, 7.331653903580303e-05, 0.00015500452518644407, 0.00029397257677049864, 0.0004211300075636969, 0.0005290508742450333, 0.000615096436522022, 0.0006780663258385888, 0.000717442274895014, 0.0007332445337598428, 0.0007262676049021282, 0.000698569711109015, 0.0006541383258200242, 0.0005997426984882866, 0.0005459644414485921, 0.0005077278409768878, 0.0005017247148939714, 0.0005385044203079023, 0.0006163757370297448, 0.0007258068867729946], [0.0017912508753993106, 0.001632952998508012, 0.0014614481281985353, 0.0012762776878690364, 0.001077454438636426, 0.0008656521357703834, 0.00064240613085363, 0.00041031919974154934, 0.00017330458850252863, 6.4285256866656e-05, 0.00029391426888591304, 0.0005108884804495083, 0.0007098429303017569, 0.0008868301828619908, 0.0010389070274184641, 0.0011640097753918164, 0.0012608483596126862, 0.0013288147312794465, 0.0013679069204399006, 0.0013786688442659369, 0.0013621438185398593, 0.0013198374061319646, 0.001253682801535339, 0.0011659995125964406, 0.0010594342182489631, 0.0009368730963851701, 0.0008013217065302038, 0.0006557691705287972, 0.0005030984693592717, 0.0003461910005798795, 0.00018866758973632458, 4.532177420381108e-05, 0.00012570138650152597, 0.00025911903570327306, 0.0003775225788950581, 0.0004779371674289311, 0.0005599190358855275, 0.0006235929928649071, 0.0006689705199960863, 0.000695938972081051, 0.0007047325994502903, 0.000696584484054284, 0.0006742881735523076, 0.0006425346196302715, 0.0006080197609181005, 0.0005793206345691821, 0.000566285681766081, 0.0005783399586609077, 0.0006216985866715569, 0.0006973701662473596], [0.0017107638570569826, 0.0015583041477095782, 0.001394781129102512, 0.001219918143788645, 0.0010341385225267762, 0.0008391335037951971, 0.0006391379125693933, 0.00044499977699301925, 0.0002914324293696376, 0.00027355743463914847, 0.0004045407923337687, 0.0005804395888794549, 0.0007564469763700736, 0.0009180458892955931, 0.0010587137241296403, 0.0011748292597275067, 0.0012642650041192625, 0.001325874274765877, 0.0013592603721790828, 0.0013646608688910027, 0.0013428909405051343, 0.0012953210617652126, 0.0012238726993351547, 0.0011310155763081518, 0.0010197461377457787, 0.0008935214631045198, 0.0007561204772786796, 0.0006114157793775654, 0.0004630875602366443, 0.000314435377508426, 0.00016878768392986697, 3.8358586086885466e-05, 0.00011121254495642332, 0.00022712075597098273, 0.00032872832553988604, 0.00041570513617708154, 0.000489679643522424, 0.0005518250181537122, 0.0006019629111312358, 0.000638864033109408, 0.0006612656343119856, 0.0006689035783758751, 0.0006630790171215024, 0.0006466484433368017, 0.0006236556229369403, 0.0005990782892645656, 0.0005791686197102414, 0.0005722313363037496, 0.0005883697333570513, 0.0006364372523507049], [0.0016291990513028793, 0.001487818107516415, 0.0013395138354869314, 0.0011847463788926778, 0.001025193630936141, 0.0008648554522572066, 0.0007121796904238672, 0.0005839878060542928, 0.0005090161353798439, 0.0005151600173040693, 0.0005966424322499727, 0.0007199827994581782, 0.0008562210361679207, 0.0009882170113989944, 0.0011062667050354756, 0.0012046304668096822, 0.001279802218973563, 0.0013296796672446175, 0.0013531519689360593, 0.001349892947706853, 0.0013202672253023642, 0.0012653046701902443, 0.001186716962690877, 0.001086935592121635, 0.0009691496762024688, 0.0008373174627641387, 0.0006961206614633075, 0.0005508372166911485, 0.00040717136602867407, 0.0002714155361174349, 0.00015341007266495363, 8.998051399491674e-05, 0.0001343979186392885, 0.00020942602552344677, 0.0002795702656192946, 0.0003431769079519069, 0.00040331803628270856, 0.0004612844324075527, 0.0005150118239470547, 0.0005603911912989168, 0.0005935143977057307, 0.00061227856467979, 0.0006168500493012601, 0.000609154133675961, 0.0005918899948563839, 0.0005679056654616679, 0.0005409207236017601, 0.0005179318123105059, 0.0005116190975833729, 0.0005382014415811333], [0.0015405991512064314, 0.0014145239831265136, 0.0012873010195995115, 0.001160140202836751, 0.0010356190108170246, 0.0009186437309197681, 0.0008175455275030275, 0.000744435242124774, 0.0007124955920078046, 0.0007286794389811572, 0.0007876618355819325, 0.0008750448947036527, 0.0009751865089773225, 0.001075512724025754, 0.0011670259416601627, 0.0012435209998265828, 0.0013007689055355807, 0.0013359411962636516, 0.0013472521206675634, 0.0013337568898226313, 0.0012952585631990001, 0.0012322917447736847, 0.0011461607460320285, 0.0010390147121138932, 0.0009139447389911877, 0.0007750909698935155, 0.0006277573221174469, 0.00047857041584046107, 0.00033588908272390636, 0.0002115176483053603, 0.00012844986923807214, 0.00012187610839773484, 0.00016126406988898492, 0.00019984408569267945, 0.00023033129733649723, 0.0002610751060192579, 0.00030193600731547607, 0.0003547178813770003, 0.000412388174190826, 0.0004651626067196025, 0.0005054627444897994, 0.000529643997036319, 0.0005377411245886311, 0.0005321143107541751, 0.0005155257612574168, 0.0004896551703099297, 0.00045572853799989753, 0.0004185595150500233, 0.00039297429331598346, 0.0004049812313915214], [0.0014383846069853632, 0.0013305595092548573, 0.0012285848828031479, 0.001133848880776615, 0.0010485305676367874, 0.0009760409259461317, 0.0009211182361835187, 0.0008890963165774105, 0.0008840812523578016, 0.0009067331328264772, 0.000953276272004822, 0.0010165714788254198, 0.0010882306613481916, 0.001160316654685197, 0.0012261344869215725, 0.0012803712652220114, 0.00131894998057217, 0.0013388207797490521, 0.0013377867491762032, 0.0013143950929952965, 0.0012678965010830474, 0.0011982646464419502, 0.001106263869833361, 0.0009935522574141397, 0.0008628084015638289, 0.0007178741647969528, 0.000563919266536386, 0.00040768924610925714, 0.0002582035000990632, 0.00013080186727598375, 7.820520496824287e-05, 0.00012634461903476902, 0.00017069601830029126, 0.00018716931470445016, 0.0001810445338688592, 0.00017249017311280062, 0.0001905104733401522, 0.00024197352438453973, 0.0003068879560449104, 0.00036590038245054357, 0.00040826854782363394, 0.00043024185666221376, 0.0004332027173930214, 0.00042163407032840173, 0.00040021177545548155, 0.0003706325753191228, 0.00033102868810329784, 0.000281642157336828, 0.0002390218844534389, 0.0002493662286248175], [0.0013162568042152359, 0.001228460431596435, 0.001154566517432242, 0.0010951244788632059, 0.0010502690608075397, 0.001020047364768996, 0.0010046123532053437, 0.001004110853330801, 0.0010182665751058435, 0.0010458747155721942, 0.0010845153694822422, 0.0011306569605599624, 0.0011800696885065443, 0.0012283230774168912, 0.0012711800973198252, 0.0013048231927685475, 0.0013259413940756796, 0.0013317411458967654, 0.0013199377539875206, 0.0012887649235800807, 0.0012370204281567574, 0.0011641512526470532, 0.0010703723519565214, 0.0009568086406018611, 0.0008256484685334124, 0.0006802969218126605, 0.0005255174751083723, 0.00036755179563841966, 0.00021423156005567122, 7.560468038159125e-05, 4.61267270055567e-05, 0.00012597797614943615, 0.00016821145569088981, 0.00017080154328466006, 0.00013882359274670184, 8.897729267572175e-05, 8.294233924710525e-05, 0.00014970364461745796, 0.0002256924442020011, 0.0002861379164246647, 0.00032223775314047524, 0.00033191565096048615, 0.0003184556171341261, 0.0002895655191095018, 0.00025473992752373444, 0.00021931937160819253, 0.00017837964437696535, 0.00012103636781416488, 6.202052862127791e-05, 0.00013126163114280027], [0.0011689900227372435, 0.0011022487596037385, 0.0010587676506463835, 0.0010367787825403527, 0.001032593581131949, 0.0010417879915230878, 0.0010603070156195086, 0.0010850431406410712, 0.0011138576840110555, 0.0011452635253515297, 0.001178021418562156, 0.0012108237781500474, 0.0012421335657057176, 0.0012701596050815843, 0.0012929089735407714, 0.00130826163482817, 0.0013140407562426282, 0.0013080802029101992, 0.0012883054172292306, 0.0012528440708811951, 0.0012001741343050747, 0.0011293065959093903, 0.0010399934690382621, 0.0009329514152761754, 0.0008100979606053486, 0.0006748141078063251, 0.0005322919842753895, 0.00039017794479537433, 0.0002603282857025796, 0.00016443065343764958, 0.00013530348714705127, 0.0001554866127468103, 0.00016921627666757714, 0.00015447196728658163, 0.00010935325184958838, 4.028483743721249e-05, 4.7190917993904566e-05, 0.00013161921229738445, 0.00020422465813923934, 0.00025435495272674964, 0.00027561523714626904, 0.00026583678799764037, 0.0002274050623626765, 0.00016758065307066554, 9.924915512579583e-05, 4.71641364097038e-05, 5.283465976581927e-05, 8.210539642790251e-05, 0.00013066086494793933, 0.0002192202928817767], [0.000993030081711572, 0.0009482816350567239, 0.0009382581065346251, 0.0009564479877103009, 0.0009932382204346148, 0.0010392499851090465, 0.0010872618580246049, 0.0011325899690093721, 0.0011726722229651247, 0.0012064409734552836, 0.0012337437187330763, 0.0012548875494028146, 0.0012703080285738338, 0.0012803364617378146, 0.0012850354254421688, 0.001284083132735279, 0.001276705837370471, 0.001261673844804581, 0.0012373812206189052, 0.0012020188344135715, 0.001153830918692631, 0.0010914283263169721, 0.0010141263449510009, 0.0009222828388749544, 0.0008176286831720436, 0.0007035997534726618, 0.0005856864089580958, 0.00047176319760849347, 0.00037202125080570877, 0.0002968694288243231, 0.0002498587567974705, 0.0002200490793134326, 0.00018846165968715867, 0.00014225664137010698, 8.076307657369449e-05, 3.787822528744457e-05, 9.71364408799448e-05, 0.00017084573326715905, 0.00023181577720801096, 0.0002707426242524975, 0.00028208771588952186, 0.00026413673378973676, 0.0002201739590485721, 0.00016148621294605157, 0.00011781320272633868, 0.00013447916871369824, 0.00019128909318985392, 0.0002517430559933756, 0.0003130613006933504, 0.00038767187008217755], [0.0007869109391414837, 0.0007661446348013966, 0.0007952201560010194, 0.0008579685600682149, 0.0009362936606930491, 0.0010163999918091347, 0.0010896315644172679, 0.0011512715523895368, 0.001199271393763306, 0.0012333376184867986, 0.0012543240156403256, 0.0012638174242147562, 0.0012638281226696837, 0.0012565196953826135, 0.0012439351918867682, 0.0012277062635402576, 0.0012087728608565452, 0.0011871810645958665, 0.0011620409599671431, 0.0011316959138718038, 0.0010940890291635792, 0.0010472507586793169, 0.0009898089490596902, 0.0009214403140542182, 0.0008432118923987043, 0.0007577675249211417, 0.0006692692838247567, 0.0005828913107021127, 0.0005035425245526489, 0.00043368738494067643, 0.00037118333259969125, 0.00030933609668203413, 0.00024023362065943982, 0.0001591345849331135, 6.705294938289776e-05, 2.9653807045520946e-05, 0.00012062566800176744, 0.00019918144232547534, 0.0002604163599550968, 0.00030062872197468354, 0.0003177321204310857, 0.0003129990827170348, 0.0002934541645219604, 0.0002740198681051205, 0.000274572478717033, 0.0003050787981032861, 0.0003564440020120857, 0.0004151743614371942, 0.00047689164310068025, 0.0005464944110596684], [0.0005515440089185491, 0.000560687310925453, 0.0006405629009334204, 0.0007539200707545141, 0.0008730352426977206, 0.0009828816894023238, 0.0010759970964281473, 0.00114901631950763, 0.001200962124155504, 0.0012324112251362862, 0.0012450628146494036, 0.001241493306203216, 0.0012249830720750575, 0.0011993319879989386, 0.0011685881828045201, 0.0011366324338174258, 0.001106620248581694, 0.0010803945147743075, 0.0010580916113364076, 0.0010381625486413763, 0.0010178625275439413, 0.0009940372872063814, 0.0009639304402166843, 0.0009257953346559969, 0.0008792124249085413, 0.0008250848503783631, 0.0007652947675367441, 0.0007020065368885158, 0.0006366911063938103, 0.0005691826306981888, 0.0004973515183399201, 0.000417927218276902, 0.0003284225302702973, 0.0002295553306169835, 0.00012870838564743234, 6.350909023549138e-05, 0.00011538889102594582, 0.00019388898135263386, 0.00026218071274213076, 0.00031492403828276835, 0.00035078218568528334, 0.00037150181758446215, 0.0003829371996185538, 0.00039464021323138375, 0.00041627729356679815, 0.0004521385705826965, 0.0004994690833029224, 0.0005530682269873023, 0.0006108666847982985, 0.0006756651075602079], [0.00029043760572292006, 0.0003514252228769935, 0.0005038942127283966, 0.0006695889294110688, 0.0008225403447110778, 0.0009535581053071202, 0.0010588034420201877, 0.001136860975667395, 0.00118780487460669, 0.0012128429742544735, 0.0012141815931028357, 0.0011949985056650134, 0.001159467747833679, 0.0011127735423046496, 0.0010610082017888658, 0.0010107885302921777, 0.0009684121940052485, 0.0009385522628006312, 0.0009229312196406026, 0.0009197839467192231, 0.0009245887186522048, 0.0009316479044227237, 0.000935632055810099, 0.0009325253326631178, 0.0009199215056030804, 0.0008968512954602081, 0.0008633232074404964, 0.0008197206892412211, 0.0007662123340334828, 0.000702387740988372, 0.000627347336176031, 0.0005403563472686398, 0.0004419223895207669, 0.00033493633618733484, 0.0002257102478861564, 0.00012755535173887867, 8.808558335055523e-05, 0.00014646139818010883, 0.00022743374441011903, 0.00030286204747055715, 0.0003664305879191356, 0.00041714780482522945, 0.00045752784634400773, 0.0004925026248029597, 0.0005274068599124803, 0.0005657267024164368, 0.000608309819832608, 0.0006548078154818182, 0.000706004928320647, 0.0007649842409169383], [9.90880366359673e-06, 0.00023318142990600587, 0.00044905950503838765, 0.000642266278512006, 0.0008089072518210021, 0.0009463241533966725, 0.001052940309810154, 0.0011281595350608002, 0.001172302183451415, 0.0011865871600838637, 0.0011731731773475345, 0.0011352749857347338, 0.0010773696969709635, 0.0010054942400803757, 0.0009275740005802969, 0.0008535367270711713, 0.000794578555938314, 0.00076067295468935, 0.000756523772433114, 0.0007789583589476337, 0.0008187348655756732, 0.00086497834309222, 0.0009084727602161385, 0.0009427478625593284, 0.000963871075530122, 0.0009698149881937038, 0.0009597840754789128, 0.000933630842939232, 0.0008914317174028837, 0.0008332952689722837, 0.0007594547787659351, 0.0006706124959511778, 0.0005683625687236639, 0.0004553906452339167, 0.0003351643953990718, 0.00021124078709124373, 8.815521703180866e-05, 5.2880292333536754e-05, 0.0001659423686835768, 0.0002742888456515711, 0.00036885416765339735, 0.00044750037986553826, 0.0005108588383780312, 0.0005616404986324238, 0.0006036499728458234, 0.0006407277824074033, 0.0006762142906237922, 0.0007132568559535858, 0.0007555550453823466, 0.0008076529174899156], [0.00028103070642239794, 0.0003677544062426419, 0.0005310272893749889, 0.0006995650586420931, 0.0008509986953089623, 0.0009767247766055073, 0.0010726183129957608, 0.0011366744633472328, 0.0011682504795341715, 0.001167790606230179, 0.0011367612085975674, 0.0010777349055871247, 0.0009946439997208462, 0.0008932906183443014, 0.0007822849125601668, 0.0006745880262700346, 0.0005890604184068139, 0.0005479275276922264, 0.0005636213799065909, 0.0006263816227090325, 0.0007138384932692497, 0.0008064265126964948, 0.0008915512437898257, 0.0009619644413160894, 0.0010137805128455717, 0.0010451571063499186, 0.0010554709140302384, 0.001044792904607201, 0.0010135742745610737, 0.0009625153765232133, 0.000892594328024623, 0.0008051926315814633, 0.0007022035710433961, 0.0005860093669337418, 0.0004593667461425077, 0.00032571253587524503, 0.0001921728779337588, 9.616018296160954e-05, 0.00015340556075401276, 0.00026988407949697207, 0.00038027510695403906, 0.0004740652477827123, 0.0005488777730549869, 0.0006055262772815531, 0.0006468163454459866, 0.000676884640866275, 0.0007008479377478525, 0.0007247172293077448, 0.0007552631364891194, 0.0007993306315796814], [0.0005727845484767566, 0.000612807289243895, 0.000712107540966201, 0.0008330993584730335, 0.0009508481126828448, 0.0010514199701627648, 0.0011270635792896098, 0.0011734432541448325, 0.0011883087616217395, 0.0011708632053577424, 0.0011214757423426425, 0.001041598308934485, 0.000933856836713444, 0.000802393274977843, 0.0006537745006149952, 0.0004996018852650318, 0.0003647497860794022, 0.00030417058864841065, 0.00036288213156893096, 0.0004922215598834718, 0.0006378638356706324, 0.0007765150184802752, 0.0008983182678338133, 0.000998555884281655, 0.0010749421579946282, 0.0011265681179003647, 0.0011533761696286078, 0.001155852208058052, 0.001134846351713651, 0.0010914951706842363, 0.0010272252353085022, 0.0009438079424833745, 0.0008434421808951688, 0.0007289108191674643, 0.000604052913311265, 0.00047523435687675276, 0.0003555331873575175, 0.0002740884872570078, 0.0002715410461667329, 0.00033925977194781146, 0.0004299667266620599, 0.0005155087889141922, 0.0005847101966720277, 0.0006341178640168485, 0.0006644183132318459, 0.0006792056077988725, 0.0006846292907524077, 0.0006892886338565368, 0.0007036332418829481, 0.00073801961522437], [0.0008578774859524856, 0.0008757243495599229, 0.0009342703626918008, 0.0010134823854323907, 0.0010952657845991704, 0.0011663320534410588, 0.0012177359957800432, 0.0012437165562064806, 0.001240762992405028, 0.0012070082809034358, 0.0011418675358145826, 0.0010458398948047056, 0.0009204200356836171, 0.000768087691014663, 0.0005923622924112982, 0.0003979564344294421, 0.00019151255798086693, 4.412934711316307e-05, 0.0002414554535148335, 0.00044335387237372123, 0.0006304882374961015, 0.0007977557293832148, 0.0009418173973205246, 0.0010605529553215653, 0.0011528134731152754, 0.001218222130294944, 0.0012570022074483956, 0.0012698384715209333, 0.001257782028684236, 0.001222205903749425, 0.0011648142157283262, 0.0010877104178029621, 0.0009935538191426004, 0.0008858935017656166, 0.0007698656866028177, 0.0006535197559397046, 0.0005497984334889943, 0.000477364434387871, 0.00045361845942096485, 0.0004781175447379529, 0.0005303465880269233, 0.000587323821735376, 0.0006338059881149115, 0.0006620771295873731, 0.0006698585179414584, 0.0006591683121274115, 0.0006362417166155655, 0.0006120956712347954, 0.0006024383979806719, 0.000624120933778785], [0.001130834202635598, 0.0011351941565996356, 0.0011674810433272259, 0.0012155730193248412, 0.0012669706996151792, 0.0013109651651231644, 0.001339308697583467, 0.0013460863377356468, 0.0013273513356814193, 0.0012807824232160478, 0.0012054443538080763, 0.001101670773514502, 0.0009710903216986141, 0.0008168816193969406, 0.0006445912576108256, 0.0004649632303531613, 0.0003061695754063618, 0.00025336734077935276, 0.00036271382140008626, 0.0005354045994675513, 0.0007141078445486053, 0.0008808598518587491, 0.0010281539819072278, 0.001152125578980941, 0.0012507330004670493, 0.001323078515538561, 0.0013690689849949343, 0.0013892146875191535, 0.0013845086622889628, 0.0013563704772339186, 0.0013066539549199218, 0.0012377307858790726, 0.0011526792525305518, 0.0010556250107629102, 0.0009522691406415997, 0.0008505157314079515, 0.00076071763713625, 0.0006943148444930627, 0.0006594921055866705, 0.0006555547743060971, 0.0006719952245003428, 0.0006939716405442761, 0.0007082568845844863, 0.0007058048718615505, 0.0006820237585963356, 0.0006366550173097104, 0.0005744167235461686, 0.0005073072904728348, 0.00045854252836579484, 0.0004605579256550722], [0.001387894744140929, 0.0013832480643599558, 0.001397856903658444, 0.00142361231238619, 0.0014516686642909189, 0.0014737938330583581, 0.001483106422802885, 0.0014743279450958131, 0.0014437804668242316, 0.0013893090958627338, 0.0013102403985945194, 0.0012074556589109526, 0.0010836774334372168, 0.000944166433352811, 0.0007982698156749504, 0.0006626223070637974, 0.0005656582280630745, 0.0005429190714940442, 0.0006057870763435258, 0.0007266703587489596, 0.0008714381991834452, 0.001017941708781888, 0.0011537796306476016, 0.0012720078282782861, 0.0013687320353867178, 0.0014419085519273929, 0.0014907177230945358, 0.0015152138555114558, 0.0015161266129113833, 0.0014947627598756554, 0.001452989916391613, 0.0013933000192220598, 0.001318955656400813, 0.001234209826876613, 0.0011445373320165947, 0.0010566951939562613, 0.0009782478013126777, 0.0009161163845241392, 0.0008741659985260398, 0.0008510038719317497, 0.0008398044640933552, 0.0008305335836755818, 0.0008129164345898101, 0.0007785128423420844, 0.0007216283375476397, 0.0006396405232966197, 0.0005335585386368802, 0.0004103982966386018, 0.0002934504063226976, 0.0002529629215075332], [0.001626704613921908, 0.0016159166844862635, 0.00161838722344669, 0.001628334873393326, 0.0016393190269472651, 0.0016450884085841468, 0.0016401797630694027, 0.0016202612302485767, 0.0015823027478219594, 0.0015246728039694168, 0.0014472490772219901, 0.0013516210659687406, 0.0012414682277005033, 0.0011232082793855049, 0.0010069539167073499, 0.0009074086311292065, 0.0008429870028838199, 0.0008298944004612373, 0.0008721472175364582, 0.0009584548093333885, 0.0010704277764183212, 0.0011912697739615286, 0.0013087143032944743, 0.0014146050034107554, 0.001503790042615741, 0.0015732153477593482, 0.0016213109810503154, 0.0016475978424760037, 0.0016524451851304758, 0.0016369356285021433, 0.0016028133135571193, 0.0015524992097911419, 0.001489153727668081, 0.0014167457871505067, 0.0013400440436562254, 0.0012643870540784505, 0.0011950591802351988, 0.0011361969316740544, 0.00108946105802006, 0.001053093151703174, 0.001021990476555302, 0.0009888517384720298, 0.0009457859822586508, 0.0008856857227940979, 0.0008030562549088177, 0.0006943673968924825, 0.0005581278722133118, 0.0003948560161352704, 0.00020707491919705166, 9.950312393797435e-06], [0.0018460229728870707, 0.00183115067177187, 0.0018253350015801323, 0.0018243013355091053, 0.0018232719864953837, 0.001817525329578933, 0.0018028553652719777, 0.001775904155926468, 0.0017343922198073286, 0.0016772956875733655, 0.0016050224713656039, 0.0015196325886240975, 0.0014251296397420163, 0.001327800686530569, 0.0012364469679388668, 0.0011620592711749467, 0.001116155922634846, 0.0011073384119050993, 0.0011375116587854525, 0.0012008999996260888, 0.0012868416686055483, 0.0013837161794841232, 0.0014814564153747174, 0.0015723644928441808, 0.0016510082441843093, 0.0017138291537507875, 0.0017587454602423491, 0.0017848359823410065, 0.0017921147805643734, 0.0017813854849603181, 0.0017541595427018476, 0.001712619150927805, 0.0016595966168876815, 0.0015985247585623191, 0.001533290698579617, 0.0014679123288211635, 0.0014059825541504903, 0.0013499231692161938, 0.0013002467739527174, 0.00125514020655275, 0.0012106160239643718, 0.001161221146700615, 0.0011010382513147782, 0.0010246635303544232, 0.0009279895257156168, 0.0008088352026895916, 0.0006677243512591719, 0.0005098076000835156, 0.0003523772844526711, 0.0002568902256677572], [0.0020454626617083765, 0.0020280657119223946, 0.002016768709245495, 0.00200835218935611, 0.001999241226539519, 0.001985892094786669, 0.0019651429690316336, 0.0019345031432382491, 0.0018923837353292778, 0.0018382891812213137, 0.0017729919588748346, 0.0016987034677937935, 0.0016192284269262044, 0.0015400389225358757, 0.001468118558462498, 0.0014113321695269764, 0.0013770971384306357, 0.0013704851930190544, 0.0013925416187071586, 0.0014398815338378995, 0.0015058523682653822, 0.0015824458331679513, 0.0016619293105378389, 0.001737760946715152, 0.0018048960554135469, 0.0018597513574126203, 0.0019000336261305816, 0.0019245449264462438, 0.0019330123811604238, 0.001925956405402011, 0.0019045940775187806, 0.0018707632526544823, 0.0018268426534106162, 0.0017756325430099643, 0.00172015391456621, 0.0016633314027979995, 0.0016075588396193537, 0.0015542099323606721, 0.0015032275230074175, 0.0014529533750942739, 0.0014003047502767834, 0.0013412827643127319, 0.0012716906213886211, 0.0011879204876265703, 0.0010877466106255637, 0.0009712144236528223, 0.0008419593994760052, 0.0007097327450469128, 0.0005953256002590898, 0.0005352601329062302]]}, {\"hoverinfo\": \"text\", \"legendgroup\": \"In-sample\", \"marker\": {\"color\": \"black\", \"opacity\": 0.5, \"symbol\": 1}, \"mode\": \"markers\", \"name\": \"In-sample\", \"text\": [\"0_0\", \"10_0\", \"11_0\", \"12_0\", \"13_0\", \"14_0\", \"15_0\", \"16_0\", \"17_0\", \"18_0\", \"1_0\", \"2_0\", \"3_0\", \"4_0\", \"5_0\", \"6_0\", \"7_0\", \"8_0\", \"9_0\"], \"type\": \"scatter\", \"x\": [0.9576234817504883, 0.5890345645992144, 0.8539737755406006, 0.818292231969213, 0.9999999999999999, 1.0, 0.9625014449243648, 0.6721043424289437, 0.8952039641884264, 0.5, 0.9876848459243774, 0.7635686099529266, 0.8155372440814972, 0.9945846796035767, 0.8021952290748985, 1.0, 0.8625203989490371, 0.8757633292431056, 0.8119272341310552], \"xaxis\": \"x\", \"y\": [7.406074404716492e-05, 6.128584634637274e-05, 7.743632313528645e-05, 6.238590742181703e-05, 9.550684071801788e-06, 9.599704869412188e-05, 5.29224711057863e-05, 9.005469299512393e-05, 3.827133172620887e-21, 8.37436283129657e-05, 7.218923568725587e-05, 4.073542058467865e-05, 5.550193786621094e-05, 1.5695862472057343e-05, 7.110095889666104e-05, 3.3072907935079673e-22, 7.313388371934669e-05, 8.427547632154883e-05, 8.670315234608186e-06], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"legendgroup\": \"In-sample\", \"marker\": {\"color\": \"black\", \"opacity\": 0.5, \"symbol\": 1}, \"mode\": \"markers\", \"name\": \"In-sample\", \"showlegend\": false, \"text\": [\"0_0\", \"10_0\", \"11_0\", \"12_0\", \"13_0\", \"14_0\", \"15_0\", \"16_0\", \"17_0\", \"18_0\", \"1_0\", \"2_0\", \"3_0\", \"4_0\", \"5_0\", \"6_0\", \"7_0\", \"8_0\", \"9_0\"], \"type\": \"scatter\", \"x\": [0.9576234817504883, 0.5890345645992144, 0.8539737755406006, 0.818292231969213, 0.9999999999999999, 1.0, 0.9625014449243648, 0.6721043424289437, 0.8952039641884264, 0.5, 0.9876848459243774, 0.7635686099529266, 0.8155372440814972, 0.9945846796035767, 0.8021952290748985, 1.0, 0.8625203989490371, 0.8757633292431056, 0.8119272341310552], \"xaxis\": \"x2\", \"y\": [7.406074404716492e-05, 6.128584634637274e-05, 7.743632313528645e-05, 6.238590742181703e-05, 9.550684071801788e-06, 9.599704869412188e-05, 5.29224711057863e-05, 9.005469299512393e-05, 3.827133172620887e-21, 8.37436283129657e-05, 7.218923568725587e-05, 4.073542058467865e-05, 5.550193786621094e-05, 1.5695862472057343e-05, 7.110095889666104e-05, 3.3072907935079673e-22, 7.313388371934669e-05, 8.427547632154883e-05, 8.670315234608186e-06], \"yaxis\": \"y2\"}],\n",
              "                        {\"annotations\": [{\"font\": {\"size\": 14}, \"showarrow\": false, \"text\": \"Mean\", \"x\": 0.25, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 14}, \"showarrow\": false, \"text\": \"Standard Error\", \"x\": 0.8, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"autosize\": false, \"height\": 450, \"hovermode\": \"closest\", \"legend\": {\"orientation\": \"h\", \"x\": 0, \"y\": -0.25}, \"margin\": {\"b\": 100, \"l\": 35, \"pad\": 0, \"r\": 35, \"t\": 35}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 950, \"xaxis\": {\"anchor\": \"y\", \"autorange\": false, \"domain\": [0.05, 0.45], \"exponentformat\": \"e\", \"range\": [0.5, 1.0], \"tickfont\": {\"size\": 11}, \"tickmode\": \"auto\", \"title\": {\"text\": \"learning_rate_factor\"}, \"type\": \"linear\"}, \"xaxis2\": {\"anchor\": \"y2\", \"autorange\": false, \"domain\": [0.6, 1], \"exponentformat\": \"e\", \"range\": [0.5, 1.0], \"tickfont\": {\"size\": 11}, \"tickmode\": \"auto\", \"title\": {\"text\": \"learning_rate_factor\"}, \"type\": \"linear\"}, \"yaxis\": {\"anchor\": \"x\", \"autorange\": false, \"domain\": [0, 1], \"exponentformat\": \"e\", \"range\": [0.0, 0.0001], \"tickfont\": {\"size\": 11}, \"tickmode\": \"auto\", \"title\": {\"text\": \"learning_rate_abs\"}, \"type\": \"linear\"}, \"yaxis2\": {\"anchor\": \"x2\", \"autorange\": false, \"domain\": [0, 1], \"exponentformat\": \"e\", \"range\": [0.0, 0.0001], \"tickfont\": {\"size\": 11}, \"tickmode\": \"auto\", \"type\": \"linear\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ecf6d648-1a97-4818-8388-df8819b0348b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_jn9Wxmabpb",
        "colab_type": "text"
      },
      "source": [
        "Use the best parameters found by the bayesion optimization to train a network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "89135136-b08c-4673-de4e-8ad37102a04a",
        "id": "y7Agm0uKZdmn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "net = SuperResolutionNet(r, activation=nn.ReLU())\n",
        "train(net, use_gpu, train_loader, r,\n",
        "                 max_epochs=1000,\n",
        "                 max_epochs_without_improvement=100, \n",
        "                 learning_rate=best_parameters['lr'],\n",
        "                 beta1=best_parameters['beta1'],\n",
        "                 beta2=best_parameters['beta2'],\n",
        "                 )\n",
        "evaluate(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on gpu\n",
            "Epoch:   0 in 0.39s, best epoch so far: Epoch:   0 Training Loss: 0.088246 Mean PSNR: 10.54\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning:\n",
            "\n",
            "Couldn't retrieve source code for container of type SuperResolutionNet. It won't be checked for correctness upon loading.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100 in 32.96s, best epoch so far: Epoch: 100 Training Loss: 0.002135 Mean PSNR: 26.71\n",
            "Epoch: 200 in 65.27s, best epoch so far: Epoch: 185 Training Loss: 0.001792 Mean PSNR: 27.47\n",
            "Epoch: 300 in 97.24s, best epoch so far: Epoch: 288 Training Loss: 0.001633 Mean PSNR: 27.87\n",
            "Epoch: 400 in 129.17s, best epoch so far: Epoch: 394 Training Loss: 0.001551 Mean PSNR: 28.10\n",
            "Epoch: 500 in 160.99s, best epoch so far: Epoch: 481 Training Loss: 0.001466 Mean PSNR: 28.34\n",
            "Epoch: 600 in 193.08s, best epoch so far: Epoch: 598 Training Loss: 0.001384 Mean PSNR: 28.59\n",
            "Epoch: 700 in 224.81s, best epoch so far: Epoch: 690 Training Loss: 0.001367 Mean PSNR: 28.64\n",
            "Epoch: 800 in 256.64s, best epoch so far: Epoch: 777 Training Loss: 0.001326 Mean PSNR: 28.77\n",
            "Epoch: 900 in 288.72s, best epoch so far: Epoch: 889 Training Loss: 0.001308 Mean PSNR: 28.84\n",
            "Saving best epoch (994) with loss: 0.0012854222453745972 and psnr: 28.9095418850852 as:\n",
            "SuperResulutionNet_r-3_psnr-2891__mse-13-unknown\n",
            "r: 3\n",
            "test_data/Set5 psnr: 30.021906725381985\n",
            "test_data/Set14 psnr: 26.845566130359053\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}